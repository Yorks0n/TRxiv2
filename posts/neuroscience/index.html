<!DOCTYPE html>
<html lang="en" dir="auto">

<head>
<head>
    <title>neuroscience</title>
    <meta charset="utf-8">
    <meta name="description"
        content="Website meta description for google search results go here" />
    <meta name="dc.relation" content="https://yorks0n.github.io/TRxiv2" />
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta name="theme-color" content="#1A94D2" />

    

    
    
    
    <link rel="stylesheet" href="/TRxiv2/css/main.min.css" media="screen">

</head>


<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>neuroscience | TRxiv2</title>
<meta name="keywords" content="">
<meta name="description" content="A window to the brain: ultrasound imaging of human neural activity through a permanent acoustic window
Authors: Rabut, C.; Norman, S. L.; Griggs, W. S.; Russin, J. J.; Jann, K.; Christopoulos, V.; Liu, C.; Andersen, R. A.; Shapiro, M. G.
Score: 424.1, Published: 2023-06-15 DOI: 10.1101/2023.06.14.544094
Recording human brain activity is crucial for understanding normal and aberrant brain function. However, available recording methods are either highly invasive or have relatively low sensitivity.">
<meta name="author" content="">
<link rel="canonical" href="https://yorks0n.github.io/TRxiv2/posts/neuroscience/">
<link crossorigin="anonymous" href="/TRxiv2/assets/css/stylesheet.904bd1e751cdd2a584fa6bed3fa1166dfd8ec9949ebfd0c4d69c5add5e17c23d.css" integrity="sha256-kEvR51HN0qWE&#43;mvtP6EWbf2OyZSev9DE1pxa3V4Xwj0=" rel="preload stylesheet" as="style">
<script defer crossorigin="anonymous" src="/TRxiv2/assets/js/highlight.f413e19d0714851f6474e7ee9632408e58ac146fbdbe62747134bea2fa3415e0.js" integrity="sha256-9BPhnQcUhR9kdOfuljJAjlisFG&#43;9vmJ0cTS&#43;ovo0FeA="
    onload="hljs.initHighlightingOnLoad();"></script>
<link rel="icon" href="https://yorks0n.github.io/TRxiv2/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="https://yorks0n.github.io/TRxiv2/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://yorks0n.github.io/TRxiv2/favicon-32x32.png">
<link rel="apple-touch-icon" href="https://yorks0n.github.io/TRxiv2/apple-touch-icon.png">
<link rel="mask-icon" href="https://yorks0n.github.io/TRxiv2/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --hljs-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript><meta property="og:title" content="neuroscience" />
<meta property="og:description" content="A window to the brain: ultrasound imaging of human neural activity through a permanent acoustic window
Authors: Rabut, C.; Norman, S. L.; Griggs, W. S.; Russin, J. J.; Jann, K.; Christopoulos, V.; Liu, C.; Andersen, R. A.; Shapiro, M. G.
Score: 424.1, Published: 2023-06-15 DOI: 10.1101/2023.06.14.544094
Recording human brain activity is crucial for understanding normal and aberrant brain function. However, available recording methods are either highly invasive or have relatively low sensitivity." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://yorks0n.github.io/TRxiv2/posts/neuroscience/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-06-28T09:51:07+00:00" />
<meta property="article:modified_time" content="2023-06-28T09:51:07+00:00" />

<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="neuroscience"/>
<meta name="twitter:description" content="A window to the brain: ultrasound imaging of human neural activity through a permanent acoustic window
Authors: Rabut, C.; Norman, S. L.; Griggs, W. S.; Russin, J. J.; Jann, K.; Christopoulos, V.; Liu, C.; Andersen, R. A.; Shapiro, M. G.
Score: 424.1, Published: 2023-06-15 DOI: 10.1101/2023.06.14.544094
Recording human brain activity is crucial for understanding normal and aberrant brain function. However, available recording methods are either highly invasive or have relatively low sensitivity."/>


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "Posts",
      "item": "https://yorks0n.github.io/TRxiv2/posts/"
    }, 
    {
      "@type": "ListItem",
      "position":  3 ,
      "name": "neuroscience",
      "item": "https://yorks0n.github.io/TRxiv2/posts/neuroscience/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "neuroscience",
  "name": "neuroscience",
  "description": "A window to the brain: ultrasound imaging of human neural activity through a permanent acoustic window\nAuthors: Rabut, C.; Norman, S. L.; Griggs, W. S.; Russin, J. J.; Jann, K.; Christopoulos, V.; Liu, C.; Andersen, R. A.; Shapiro, M. G.\nScore: 424.1, Published: 2023-06-15 DOI: 10.1101/2023.06.14.544094\nRecording human brain activity is crucial for understanding normal and aberrant brain function. However, available recording methods are either highly invasive or have relatively low sensitivity.",
  "keywords": [
    
  ],
  "articleBody": " A window to the brain: ultrasound imaging of human neural activity through a permanent acoustic window\nAuthors: Rabut, C.; Norman, S. L.; Griggs, W. S.; Russin, J. J.; Jann, K.; Christopoulos, V.; Liu, C.; Andersen, R. A.; Shapiro, M. G.\nScore: 424.1, Published: 2023-06-15 DOI: 10.1101/2023.06.14.544094\nRecording human brain activity is crucial for understanding normal and aberrant brain function. However, available recording methods are either highly invasive or have relatively low sensitivity. Functional ultrasound imaging (fUSI) is an emerging technique that offers sensitive, large-scale, high-resolution neural imaging. However, fUSI cannot be performed through adult human skull. Here, we use a polymeric skull replacement material to create an acoustic window allowing ultrasound to monitor brain activity in fully intact adult humans. We design the window through experiments in phantoms and rodents, then implement it in a participant undergoing reconstructive skull surgery. Subsequently, we demonstrate fully non-invasive mapping and decoding of cortical responses to finger movement, marking the first instance of high-resolution (200 m) and large-scale (50 mmx38 mm) brain imaging through a permanent acoustic window.\nThe Benchtop mesoSPIM: a next-generation open-source light-sheet microscope for large cleared samples\nAuthors: Vladimirov, N.; Voigt, F.; Naert, T.; Araujo, G. R.; Cai, R.; Reuss, A. M.; Zhao, S.; Schmid, P.; Hildebrand, S.; Schaettin, M.; Groos, D.; Mateos, J. M.; Bethge, P.; Yamamoto, T.; Aerne, V.; Roebroeck, A.; ErtuÌˆrk, A.; Aguzzi, A.; Ziegler, U.; Stoeckli, E. T.; Baudis, L.; Lienkamp, S. S.; Helmchen, F.\nScore: 41.5, Published: 2023-06-21 DOI: 10.1101/2023.06.16.545256\nIn 2015, we launched the mesoSPIM initiative (www.mesospim.org), an open-source project aimed at making light-sheet microscopes for large cleared tissues more accessible. Since then, the demand for imaging larger samples at higher speed and resolution has increased, requiring major improvements in the capabilities of light-sheet microscopy. Here, we introduce the next-generation mesoSPIM (\"Benchtop\") with significantly increased field of view, improved resolution, and higher throughput compared to the original version. To this end, we developed a new method for testing objective lenses, enabling us to select detection objectives that are most suitable for light-sheet imaging with modern large-sensor sCMOS cameras (sensor diagonal up to 30 mm). The new mesoSPIM has a spatial resolution down to 1.5 {micro}m laterally and 3.3 {micro}m axially across the entire field of view, a magnification up to 20x, and sample sizes ranging from sub-mm up to multiple centimetres (e.g., a whole mouse), while being compatible with all clearing techniques. The microscope is designed as an open-source high-throughput system with a compact footprint, affordable cost, and assembly instructions aimed at non-experts. The user-friendly control software allows for acquisitions with multiple tiles, channels, and angles at high speed. We demonstrate several applications from neuroscience and developmental biology, as well as a novel use in physics, namely imaging particle tracks in transparent crystals that work as particle detectors.\nReconstructing visual illusory experiences from human brain activity\nAuthors: Cheng, F.; Horikawa, T.; Majima, K.; Tanaka, M.; Abdelhack, M.; Aoki, S. C.; Hirano, J.; Kamitani, Y.\nScore: 63.2, Published: 2023-06-15 DOI: 10.1101/2023.06.15.545037\nVisual illusions provide significant insights into the brains interpretation of the world given sensory inputs. However, the precise manner in which brain activity translates into illusory experiences remains largely unknown. Here we leverage a brain decoding technique combined with deep neural network (DNN) representations to reconstruct illusory percepts as images from brain activity. The reconstruction model was trained on natural images to establish a link between brain activity and perceptual features and then tested on two types of illusions: illusory lines and neon color spreading. Reconstructions revealed lines and colors consistent with illusory experiences, which varied across the source visual cortical areas. This framework offers a way to materialize subjective experiences, shedding new light on the brains internal representations of the world.\nAn adversarial collaboration to critically evaluate theories of consciousness\nAuthors: Cogitate Consortium, ; Ferrante, O.; Gorska-Klimowska, U.; Henin, S.; Hirschhorn, R.; Khalaf, A.; Lepauvre, A.; Liu, L.; Richter, D.; Vidal, Y.; Bonacchi, N.; Brown, T.; Sripad, P.; Armendariz, M.; Bendtz, K.; Ghafari, T.; Hetenyi, D.; Jeschke, J.; Kozma, C.; Mazumder, D. R.; Montenegro, S.; Seedat, A.; Sharafeldin, A.; Yang, S.; Baillet, S.; Chalmers, D. J.; Cichy, R. M.; Fallon, F.; Panagiotaropoulos, T. I.; Blumenfeld, H.; Devore, S.; Jensen, O.; Kreiman, G.; de Lange, F. P.; Luo, H.; Boly, M.; Dehaene, S.; Koch, C.; Tononi, G.; Pitts, M.; Mudrik, L.; Melloni, L.\nScore: 34.2, Published: 2023-06-26 DOI: 10.1101/2023.06.23.546249\nDifferent theories explain how subjective experience arises from brain activity. These theories have independently accrued evidence, yet, confirmation bias and dependence on design choices hamper progress in the field. Here, we present an open science adversarial collaboration which directly juxtaposes Integrated Information Theory (IIT) and Global Neuronal Workspace Theory (GNWT), employing a theory-neutral consortium approach. We investigate neural correlates of the content and duration of visual experience. The theory proponents and the consortium developed and preregistered the experimental design, divergent predictions, expected outcomes, and their interpretation. 256 human subjects viewed suprathreshold stimuli for variable durations while neural activity was measured with functional magnetic resonance imaging, magnetoencephalography, and electrocorticography. We find information about conscious content in visual, ventro-temporal and inferior frontal cortex, with sustained responses in occipital and lateral temporal cortex reflecting stimulus duration, and content-specific synchronization between frontal and early visual areas. These results confirm some predictions of IIT and GNWT, while substantially challenging both theories: for IIT, a lack of sustained synchronization within posterior cortex contradicts the claim that network connectivity specifies consciousness. GNWT is challenged by the general lack of ignition at stimulus offset and limited representation of certain conscious dimensions in prefrontal cortex. Beyond challenging the theories themselves, we present an alternative approach to advance cognitive neuroscience through a principled, theory-driven, collaborative effort. We highlight the challenges to change people's mind and the need for a quantitative framework integrating evidence for systematic theory testing and building.\nA weighted generative model of the human connectome\nAuthors: Akarca, D.; Schiavi, S.; Achterberg, J.; Genc, S.; Jones, D.; Astle, D.\nScore: 32.7, Published: 2023-06-25 DOI: 10.1101/2023.06.23.546237\nProbabilistic generative network models have offered an exciting window into the constraints governing the human connectome's organization. In particular, they have highlighted the economic context of network formation and the special roles that physical geometry and self-similarity likely play in determining the connectome's topology. However, a critical limitation of these models is that they do not consider the strength of anatomical connectivity between regions. This significantly limits their scope to answer neurobiological questions. The current work draws inspiration from the principle of redundancy reduction to develop a novel weighted generative network model. This weighted generative network model is a significant advance because it not only incorporates the theoretical advancements of previous models, but also has the ability to capture the dynamic strengthening or weakening of connections over time. Using a state-of-the-art Convex Optimization Modelling for Microstructure-Informed Tractography (COMMIT) approach, in a sample of children and adolescents (n = 88, aged 8 to 18 years), we show that this model can accurately approximate simultaneously the topology and edge-weights of the connectome (specifically, the MRI signal fraction attributed to axonal projections). We achieve this at both sparse and dense connectome densities. Generative model fits are comparable to, and in many cases better than, published findings simulating topology in the absence of weights. Our findings have implications for future research by providing new avenues for exploring normative developmental trends, models of neural computation and wider conceptual implications of the economics of connectomics supporting human functioning.\nHuman iPSC 4R tauopathy model uncovers modifiers of tau propagation\nAuthors: Parra Bravo, C.; Giani, A. M.; Madero-Perez, J.; Zhao, Z.; Samelson, A. J.; Wong, M. Y.; Evangelisti, A.; Fan, L.; Pozner, T.; Mercedes, M.; Ye, P.; Patel, T.; Yarahmady, A.; Carling, G.; Lee, V. M. Y.; Sharma, M.; Mok, S.-A.; Luo, W.; Zhao, M.; Kampmann, M.; Gong, S.; Gan, L.\nScore: 28.5, Published: 2023-06-22 DOI: 10.1101/2023.06.19.544278\nTauopathies are age-associated neurodegenerative diseases whose mechanistic underpinnings remain elusive, partially due to lack of appropriate human models. Current human induced pluripotent stem cell (hiPSC)-derived neurons express very low levels of 4-repeat (4R)-tau isoforms that are normally expressed in adult brain. Here, we engineered new iPSC lines to express 4R-tau and 4R-tau carrying the P301S MAPT mutation when differentiated into neurons. 4R-P301S neurons display progressive Tau inclusions upon seeding with Tau fibrils and recapitulate features of tauopathy phenotypes, including shared transcriptomic signatures, autophagic body accumulation, and impaired neuronal activity. A CRISPRi screen of genes associated with Tau pathobiology identified over 500 genetic modifiers of Tau-seeding-induced Tau propagation, including retromer VPS29 and the UFMylation cascade as top modifiers. In AD brains, the UFMylation cascade is altered in neurofibrillary-tangle-bearing neurons. Inhibiting the UFMylation cascade suppressed seeding-induced Tau propagation. This model provides a powerful platform to identify novel therapeutic strategies for 4R tauopathy.\nSynaptic architecture of leg and wing motor control networks in Drosophila\nAuthors: Lesser, E.; Azevedo, A. W.; Phelps, J. S.; Elabbady, L.; Cook, A. P.; Mark, B.; Kuroda, S.; Sustar, A.; Moussa, A. J.; Dallmann, C. J.; Agrawal, S.; Lee, S.-Y. J.; Pratt, B. G.; Skutt-Kakari, K.; Gerhard, S.; Lu, R.; Kemnitz, N.; Lee, K.; Halageri, A.; Castro, M.; Ih, D.; Gager, J.; Tammam, M.; Dorkenwald, S.; Collman, F. C.; Schneider-Mizell, C. M.; Brittain, D.; Jordan, C. S.; Seung, H. S.; Macrina, T.; Dickinson, M. H.; Lee, W.-C. A.; Tuthill, J. C.\nScore: 28.6, Published: 2023-05-31 DOI: 10.1101/2023.05.30.542725\nAnimal movement is controlled by motor neurons (MNs), which project out of the central nervous system to activate muscles. Because individual muscles may be used in many different behaviors, MN activity must be flexibly coordinated by dedicated premotor circuitry, the organization of which remains largely unknown. Here, we use comprehensive reconstruction of neuron anatomy and synaptic connectivity from volumetric electron microscopy (i.e., connectomics) to analyze the wiring logic of motor circuits controlling the Drosophila leg and wing. We find that both leg and wing premotor networks are organized into modules that link MNs innervating muscles with related functions. However, the connectivity patterns within leg and wing motor modules are distinct. Leg premotor neurons exhibit proportional gradients of synaptic input onto MNs within each module, revealing a novel circuit basis for hierarchical MN recruitment. In comparison, wing premotor neurons lack proportional synaptic connectivity, which may allow muscles to be recruited in different combinations or with different relative timing. By comparing the architecture of distinct limb motor control systems within the same animal, we identify common principles of premotor network organization and specializations that reflect the unique biomechanical constraints and evolutionary origins of leg and wing motor control.\nSmall-field visual projection neurons detect translational optic flow and support walking control\nAuthors: Isaacson, M. D.; Eliason, J. L.; Nern, A.; Rogers, E. M.; Lott, G. K.; Tabachnik, T.; Rowell, W. J.; Edwards, A. W.; Korff, W. L.; Rubin, G. M.; Branson, K.; Reiser, M. B.\nScore: 28.2, Published: 2023-06-22 DOI: 10.1101/2023.06.21.546024\nAnimals rely on visual motion for navigating the world, and research in flies has clarified how neural circuits extract information from moving visual scenes. However, the major pathways connecting these patterns of optic flow to behavior remain poorly understood. Using a high-throughput quantitative assay of visually guided behaviors and genetic neuronal silencing, we discovered a region in Drosophilas protocerebrum critical for visual motion following. We used neuronal silencing, calcium imaging, and optogenetics to identify a single cell type, LPC1, that innervates this region, detects translational optic flow, and plays a key role in regulating forward walking. Moreover, the population of LPC1s can estimate the travelling direction, such as when gaze direction diverges from body heading. By linking specific cell types and their visual computations to specific behaviors, our findings establish a foundation for understanding how the nervous system uses vision to guide navigation.\nNot everything, not everywhere, not all at once: a study of brain-wide encoding of movement\nAuthors: Wang, Z. A.; Chen, S.; Liu, Y.; Liu, D.; Svoboda, K.; Li, N.; Druckmann, S.\nScore: 47.2, Published: 2023-06-14 DOI: 10.1101/2023.06.08.544257\nActivity related to movement is found throughout sensory and motor regions of the brain. However, it remains unclear how movement-related activity is distributed across the brain and whether systematic differences exist between brain areas. Here, we analyzed movement related activity in brain-wide recordings containing more than 50,000 neurons in mice performing a decision-making task. Using multiple techniques, from markers to deep neural networks, we find that movement-related signals were pervasive across the brain, but systematically differed across areas. Movement-related activity was stronger in areas closer to the motor or sensory periphery. Delineating activity in terms of sensory- and motor-related components revealed finer scale structures of their encodings within brain areas. We further identified activity modulation that correlates with decision-making and uninstructed movement. Our work charts out a largescale map of movement encoding and provides a roadmap for dissecting different forms of movement and decision-making related encoding across multi-regional neural circuits.\nExpansion-assisted selective plane illumination microscopy for nanoscale imaging of centimeter-scale tissues\nAuthors: Glaser, A.; Chandrashekar, J.; Vasquez, J.; Arshadi, C.; Ouellette, N.; Jiang, X.; Baka, J.; Kovacs, G.; Woodard, M.; Seshamani, S.; Cao, K.; Clack, N.; Recknagel, A.; Grim, A.; Balaram, P.; Turschak, E.; Liddell, A.; Rohde, J.; Hellevik, A.; Takasaki, K.; Erion Barner, L.; Logsdon, M.; Chronopoulos, C.; de Vries, S.; Ting, J.; Perlmutter, S.; Kalmbach, B.; Dembrow, N.; Reid, R. C.; Feng, D.; Svoboda, K.\nScore: 361.4, Published: 2023-06-27 DOI: 10.1101/2023.06.08.544277\nRecent advances in tissue processing, labeling, and fluorescence microscopy are providing unprecedented views of the structure of cells and tissues at sub-diffraction resolutions and near single molecule sensitivity, driving discoveries in diverse fields of biology, including neuroscience. Biological tissue is organized over scales of nanometers to centimeters. Harnessing molecular imaging across three-dimensional samples on this scale requires new types of microscopes with larger fields of view and working distance, as well as higher imaging throughput. We present a new expansion-assisted selective plane illumination microscope (ExA-SPIM) with diffraction-limited and aberration-free performance over a large field of view (85 mm2) and working distance (35 mm). Combined with new tissue clearing and expansion methods, the microscope allows nanoscale imaging of centimeter-scale samples, including entire mouse brains, with diffraction-limited resolutions and high contrast without sectioning. We illustrate ExA-SPIM by reconstructing individual neurons across the mouse brain, imaging cortico-spinal neurons in the macaque motor cortex, and tracing axons in human white matter.\n",
  "wordCount" : "2365",
  "inLanguage": "en",
  "datePublished": "2023-06-28T09:51:07Z",
  "dateModified": "2023-06-28T09:51:07Z",
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://yorks0n.github.io/TRxiv2/posts/neuroscience/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "TRxiv2",
    "logo": {
      "@type": "ImageObject",
      "url": "https://yorks0n.github.io/TRxiv2/favicon.ico"
    }
  }
}
</script>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://yorks0n.github.io/TRxiv2" accesskey="h" title="TRxiv2 (Alt + H)">TRxiv2</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
        </ul>
    </nav>
</header>
<main class="main">
<article class="post-single">
  <header class="post-header">
    
    <h1 class="post-title">
      neuroscience
    </h1>
    <div class="post-meta"><span>updated on June 28, 2023</span>

</div>
  </header> 
  <div class="post-content"><div class="accordion accordion-flush" id="accordionFlushExample"><div class="accordion-item">
    <h3 class="accordion-header" id="flush-heading10.1101/2023.06.14.544094">
      <button class="accordion-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#flush-collapse10.1101/2023.06.14.544094" aria-expanded="false" aria-controls="flush-collapse10.1101/2023.06.14.544094">
        <p class="paperTitle">A window to the brain: ultrasound imaging of human neural activity through a permanent acoustic window</p>
      </button>
    </h3>
    <div id="flush-collapse10.1101/2023.06.14.544094" class="accordion-collapse collapse" aria-labelledby="flush-heading10.1101/2023.06.14.544094" data-bs-parent="#accordionFlushExample">
      <div class="accordion-body">
        <p class="author">Authors: Rabut, C.; Norman, S. L.; Griggs, W. S.; Russin, J. J.; Jann, K.; Christopoulos, V.; Liu, C.; Andersen, R. A.; Shapiro, M. G.</p>
        <p class="info">Score: 424.1, Published: 2023-06-15 </p>
        <p class="info">DOI: <a href='https://doi.org/10.1101/2023.06.14.544094' target='https://doi.org/10.1101/2023.06.14.544094'> 10.1101/2023.06.14.544094</a></p>
        <p class="abstract">Recording human brain activity is crucial for understanding normal and aberrant brain function. However, available recording methods are either highly invasive or have relatively low sensitivity. Functional ultrasound imaging (fUSI) is an emerging technique that offers sensitive, large-scale, high-resolution neural imaging. However, fUSI cannot be performed through adult human skull. Here, we use a polymeric skull replacement material to create an acoustic window allowing ultrasound to monitor brain activity in fully intact adult humans. We design the window through experiments in phantoms and rodents, then implement it in a participant undergoing reconstructive skull surgery. Subsequently, we demonstrate fully non-invasive mapping and decoding of cortical responses to finger movement, marking the first instance of high-resolution (200 m) and large-scale (50 mmx38 mm) brain imaging through a permanent acoustic window.</p>
      </div>
    </div>
  </div><div class="accordion-item">
    <h3 class="accordion-header" id="flush-heading10.1101/2023.06.16.545256">
      <button class="accordion-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#flush-collapse10.1101/2023.06.16.545256" aria-expanded="false" aria-controls="flush-collapse10.1101/2023.06.16.545256">
        <p class="paperTitle">The Benchtop mesoSPIM: a next-generation open-source light-sheet microscope for large cleared samples</p>
      </button>
    </h3>
    <div id="flush-collapse10.1101/2023.06.16.545256" class="accordion-collapse collapse" aria-labelledby="flush-heading10.1101/2023.06.16.545256" data-bs-parent="#accordionFlushExample">
      <div class="accordion-body">
        <p class="author">Authors: Vladimirov, N.; Voigt, F.; Naert, T.; Araujo, G. R.; Cai, R.; Reuss, A. M.; Zhao, S.; Schmid, P.; Hildebrand, S.; Schaettin, M.; Groos, D.; Mateos, J. M.; Bethge, P.; Yamamoto, T.; Aerne, V.; Roebroeck, A.; ErtuÌˆrk, A.; Aguzzi, A.; Ziegler, U.; Stoeckli, E. T.; Baudis, L.; Lienkamp, S. S.; Helmchen, F.</p>
        <p class="info">Score: 41.5, Published: 2023-06-21 </p>
        <p class="info">DOI: <a href='https://doi.org/10.1101/2023.06.16.545256' target='https://doi.org/10.1101/2023.06.16.545256'> 10.1101/2023.06.16.545256</a></p>
        <p class="abstract">In 2015, we launched the mesoSPIM initiative (www.mesospim.org), an open-source project aimed at making light-sheet microscopes for large cleared tissues more accessible. Since then, the demand for imaging larger samples at higher speed and resolution has increased, requiring major improvements in the capabilities of light-sheet microscopy.

Here, we introduce the next-generation mesoSPIM (&#34;Benchtop&#34;) with significantly increased field of view, improved resolution, and higher throughput compared to the original version. To this end, we developed a new method for testing objective lenses, enabling us to select detection objectives that are most suitable for light-sheet imaging with modern large-sensor sCMOS cameras (sensor diagonal up to 30 mm). The new mesoSPIM has a spatial resolution down to 1.5 {micro}m laterally and 3.3 {micro}m axially across the entire field of view, a magnification up to 20x, and sample sizes ranging from sub-mm up to multiple centimetres (e.g., a whole mouse), while being compatible with all clearing techniques.

The microscope is designed as an open-source high-throughput system with a compact footprint, affordable cost, and assembly instructions aimed at non-experts. The user-friendly control software allows for acquisitions with multiple tiles, channels, and angles at high speed. We demonstrate several applications from neuroscience and developmental biology, as well as a novel use in physics, namely imaging particle tracks in transparent crystals that work as particle detectors.</p>
      </div>
    </div>
  </div><div class="accordion-item">
    <h3 class="accordion-header" id="flush-heading10.1101/2023.06.15.545037">
      <button class="accordion-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#flush-collapse10.1101/2023.06.15.545037" aria-expanded="false" aria-controls="flush-collapse10.1101/2023.06.15.545037">
        <p class="paperTitle">Reconstructing visual illusory experiences from human brain activity</p>
      </button>
    </h3>
    <div id="flush-collapse10.1101/2023.06.15.545037" class="accordion-collapse collapse" aria-labelledby="flush-heading10.1101/2023.06.15.545037" data-bs-parent="#accordionFlushExample">
      <div class="accordion-body">
        <p class="author">Authors: Cheng, F.; Horikawa, T.; Majima, K.; Tanaka, M.; Abdelhack, M.; Aoki, S. C.; Hirano, J.; Kamitani, Y.</p>
        <p class="info">Score: 63.2, Published: 2023-06-15 </p>
        <p class="info">DOI: <a href='https://doi.org/10.1101/2023.06.15.545037' target='https://doi.org/10.1101/2023.06.15.545037'> 10.1101/2023.06.15.545037</a></p>
        <p class="abstract">Visual illusions provide significant insights into the brains interpretation of the world given sensory inputs. However, the precise manner in which brain activity translates into illusory experiences remains largely unknown. Here we leverage a brain decoding technique combined with deep neural network (DNN) representations to reconstruct illusory percepts as images from brain activity. The reconstruction model was trained on natural images to establish a link between brain activity and perceptual features and then tested on two types of illusions: illusory lines and neon color spreading. Reconstructions revealed lines and colors consistent with illusory experiences, which varied across the source visual cortical areas. This framework offers a way to materialize subjective experiences, shedding new light on the brains internal representations of the world.</p>
      </div>
    </div>
  </div><div class="accordion-item">
    <h3 class="accordion-header" id="flush-heading10.1101/2023.06.23.546249">
      <button class="accordion-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#flush-collapse10.1101/2023.06.23.546249" aria-expanded="false" aria-controls="flush-collapse10.1101/2023.06.23.546249">
        <p class="paperTitle">An adversarial collaboration to critically evaluate theories of consciousness</p>
      </button>
    </h3>
    <div id="flush-collapse10.1101/2023.06.23.546249" class="accordion-collapse collapse" aria-labelledby="flush-heading10.1101/2023.06.23.546249" data-bs-parent="#accordionFlushExample">
      <div class="accordion-body">
        <p class="author">Authors: Cogitate Consortium,  ; Ferrante, O.; Gorska-Klimowska, U.; Henin, S.; Hirschhorn, R.; Khalaf, A.; Lepauvre, A.; Liu, L.; Richter, D.; Vidal, Y.; Bonacchi, N.; Brown, T.; Sripad, P.; Armendariz, M.; Bendtz, K.; Ghafari, T.; Hetenyi, D.; Jeschke, J.; Kozma, C.; Mazumder, D. R.; Montenegro, S.; Seedat, A.; Sharafeldin, A.; Yang, S.; Baillet, S.; Chalmers, D. J.; Cichy, R. M.; Fallon, F.; Panagiotaropoulos, T. I.; Blumenfeld, H.; Devore, S.; Jensen, O.; Kreiman, G.; de Lange, F. P.; Luo, H.; Boly, M.; Dehaene, S.; Koch, C.; Tononi, G.; Pitts, M.; Mudrik, L.; Melloni, L.</p>
        <p class="info">Score: 34.2, Published: 2023-06-26 </p>
        <p class="info">DOI: <a href='https://doi.org/10.1101/2023.06.23.546249' target='https://doi.org/10.1101/2023.06.23.546249'> 10.1101/2023.06.23.546249</a></p>
        <p class="abstract">Different theories explain how subjective experience arises from brain activity. These theories have independently accrued evidence, yet, confirmation bias and dependence on design choices hamper progress in the field. Here, we present an open science adversarial collaboration which directly juxtaposes Integrated Information Theory (IIT) and Global Neuronal Workspace Theory (GNWT), employing a theory-neutral consortium approach. We investigate neural correlates of the content and duration of visual experience. The theory proponents and the consortium developed and preregistered the experimental design, divergent predictions, expected outcomes, and their interpretation. 256 human subjects viewed suprathreshold stimuli for variable durations while neural activity was measured with functional magnetic resonance imaging, magnetoencephalography, and electrocorticography. We find information about conscious content in visual, ventro-temporal and inferior frontal cortex, with sustained responses in occipital and lateral temporal cortex reflecting stimulus duration, and content-specific synchronization between frontal and early visual areas. These results confirm some predictions of IIT and GNWT, while substantially challenging both theories: for IIT, a lack of sustained synchronization within posterior cortex contradicts the claim that network connectivity specifies consciousness. GNWT is challenged by the general lack of ignition at stimulus offset and limited representation of certain conscious dimensions in prefrontal cortex. Beyond challenging the theories themselves, we present an alternative approach to advance cognitive neuroscience through a principled, theory-driven, collaborative effort. We highlight the challenges to change people&#39;s mind and the need for a quantitative framework integrating evidence for systematic theory testing and building.</p>
      </div>
    </div>
  </div><div class="accordion-item">
    <h3 class="accordion-header" id="flush-heading10.1101/2023.06.23.546237">
      <button class="accordion-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#flush-collapse10.1101/2023.06.23.546237" aria-expanded="false" aria-controls="flush-collapse10.1101/2023.06.23.546237">
        <p class="paperTitle">A weighted generative model of the human connectome</p>
      </button>
    </h3>
    <div id="flush-collapse10.1101/2023.06.23.546237" class="accordion-collapse collapse" aria-labelledby="flush-heading10.1101/2023.06.23.546237" data-bs-parent="#accordionFlushExample">
      <div class="accordion-body">
        <p class="author">Authors: Akarca, D.; Schiavi, S.; Achterberg, J.; Genc, S.; Jones, D.; Astle, D.</p>
        <p class="info">Score: 32.7, Published: 2023-06-25 </p>
        <p class="info">DOI: <a href='https://doi.org/10.1101/2023.06.23.546237' target='https://doi.org/10.1101/2023.06.23.546237'> 10.1101/2023.06.23.546237</a></p>
        <p class="abstract">Probabilistic generative network models have offered an exciting window into the constraints governing the human connectome&#39;s organization. In particular, they have highlighted the economic context of network formation and the special roles that physical geometry and self-similarity likely play in determining the connectome&#39;s topology. However, a critical limitation of these models is that they do not consider the strength of anatomical connectivity between regions. This significantly limits their scope to answer neurobiological questions. The current work draws inspiration from the principle of redundancy reduction to develop a novel weighted generative network model. This weighted generative network model is a significant advance because it not only incorporates the theoretical advancements of previous models, but also has the ability to capture the dynamic strengthening or weakening of connections over time. Using a state-of-the-art Convex Optimization Modelling for Microstructure-Informed Tractography (COMMIT) approach, in a sample of children and adolescents (n = 88, aged 8 to 18 years), we show that this model can accurately approximate simultaneously the topology and edge-weights of the connectome (specifically, the MRI signal fraction attributed to axonal projections). We achieve this at both sparse and dense connectome densities. Generative model fits are comparable to, and in many cases better than, published findings simulating topology in the absence of weights. Our findings have implications for future research by providing new avenues for exploring normative developmental trends, models of neural computation and wider conceptual implications of the economics of connectomics supporting human functioning.</p>
      </div>
    </div>
  </div><div class="accordion-item">
    <h3 class="accordion-header" id="flush-heading10.1101/2023.06.19.544278">
      <button class="accordion-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#flush-collapse10.1101/2023.06.19.544278" aria-expanded="false" aria-controls="flush-collapse10.1101/2023.06.19.544278">
        <p class="paperTitle">Human iPSC 4R tauopathy model uncovers modifiers of tau propagation</p>
      </button>
    </h3>
    <div id="flush-collapse10.1101/2023.06.19.544278" class="accordion-collapse collapse" aria-labelledby="flush-heading10.1101/2023.06.19.544278" data-bs-parent="#accordionFlushExample">
      <div class="accordion-body">
        <p class="author">Authors: Parra Bravo, C.; Giani, A. M.; Madero-Perez, J.; Zhao, Z.; Samelson, A. J.; Wong, M. Y.; Evangelisti, A.; Fan, L.; Pozner, T.; Mercedes, M.; Ye, P.; Patel, T.; Yarahmady, A.; Carling, G.; Lee, V. M. Y.; Sharma, M.; Mok, S.-A.; Luo, W.; Zhao, M.; Kampmann, M.; Gong, S.; Gan, L.</p>
        <p class="info">Score: 28.5, Published: 2023-06-22 </p>
        <p class="info">DOI: <a href='https://doi.org/10.1101/2023.06.19.544278' target='https://doi.org/10.1101/2023.06.19.544278'> 10.1101/2023.06.19.544278</a></p>
        <p class="abstract">Tauopathies are age-associated neurodegenerative diseases whose mechanistic underpinnings remain elusive, partially due to lack of appropriate human models. Current human induced pluripotent stem cell (hiPSC)-derived neurons express very low levels of 4-repeat (4R)-tau isoforms that are normally expressed in adult brain. Here, we engineered new iPSC lines to express 4R-tau and 4R-tau carrying the P301S MAPT mutation when differentiated into neurons. 4R-P301S neurons display progressive Tau inclusions upon seeding with Tau fibrils and recapitulate features of tauopathy phenotypes, including shared transcriptomic signatures, autophagic body accumulation, and impaired neuronal activity. A CRISPRi screen of genes associated with Tau pathobiology identified over 500 genetic modifiers of Tau-seeding-induced Tau propagation, including retromer VPS29 and the UFMylation cascade as top modifiers. In AD brains, the UFMylation cascade is altered in neurofibrillary-tangle-bearing neurons. Inhibiting the UFMylation cascade suppressed seeding-induced Tau propagation. This model provides a powerful platform to identify novel therapeutic strategies for 4R tauopathy.</p>
      </div>
    </div>
  </div><div class="accordion-item">
    <h3 class="accordion-header" id="flush-heading10.1101/2023.05.30.542725">
      <button class="accordion-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#flush-collapse10.1101/2023.05.30.542725" aria-expanded="false" aria-controls="flush-collapse10.1101/2023.05.30.542725">
        <p class="paperTitle">Synaptic architecture of leg and wing motor control networks in Drosophila</p>
      </button>
    </h3>
    <div id="flush-collapse10.1101/2023.05.30.542725" class="accordion-collapse collapse" aria-labelledby="flush-heading10.1101/2023.05.30.542725" data-bs-parent="#accordionFlushExample">
      <div class="accordion-body">
        <p class="author">Authors: Lesser, E.; Azevedo, A. W.; Phelps, J. S.; Elabbady, L.; Cook, A. P.; Mark, B.; Kuroda, S.; Sustar, A.; Moussa, A. J.; Dallmann, C. J.; Agrawal, S.; Lee, S.-Y. J.; Pratt, B. G.; Skutt-Kakari, K.; Gerhard, S.; Lu, R.; Kemnitz, N.; Lee, K.; Halageri, A.; Castro, M.; Ih, D.; Gager, J.; Tammam, M.; Dorkenwald, S.; Collman, F. C.; Schneider-Mizell, C. M.; Brittain, D.; Jordan, C. S.; Seung, H. S.; Macrina, T.; Dickinson, M. H.; Lee, W.-C. A.; Tuthill, J. C.</p>
        <p class="info">Score: 28.6, Published: 2023-05-31 </p>
        <p class="info">DOI: <a href='https://doi.org/10.1101/2023.05.30.542725' target='https://doi.org/10.1101/2023.05.30.542725'> 10.1101/2023.05.30.542725</a></p>
        <p class="abstract">Animal movement is controlled by motor neurons (MNs), which project out of the central nervous system to activate muscles. Because individual muscles may be used in many different behaviors, MN activity must be flexibly coordinated by dedicated premotor circuitry, the organization of which remains largely unknown. Here, we use comprehensive reconstruction of neuron anatomy and synaptic connectivity from volumetric electron microscopy (i.e., connectomics) to analyze the wiring logic of motor circuits controlling the Drosophila leg and wing. We find that both leg and wing premotor networks are organized into modules that link MNs innervating muscles with related functions. However, the connectivity patterns within leg and wing motor modules are distinct. Leg premotor neurons exhibit proportional gradients of synaptic input onto MNs within each module, revealing a novel circuit basis for hierarchical MN recruitment. In comparison, wing premotor neurons lack proportional synaptic connectivity, which may allow muscles to be recruited in different combinations or with different relative timing. By comparing the architecture of distinct limb motor control systems within the same animal, we identify common principles of premotor network organization and specializations that reflect the unique biomechanical constraints and evolutionary origins of leg and wing motor control.</p>
      </div>
    </div>
  </div><div class="accordion-item">
    <h3 class="accordion-header" id="flush-heading10.1101/2023.06.21.546024">
      <button class="accordion-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#flush-collapse10.1101/2023.06.21.546024" aria-expanded="false" aria-controls="flush-collapse10.1101/2023.06.21.546024">
        <p class="paperTitle">Small-field visual projection neurons detect translational optic flow and support walking control</p>
      </button>
    </h3>
    <div id="flush-collapse10.1101/2023.06.21.546024" class="accordion-collapse collapse" aria-labelledby="flush-heading10.1101/2023.06.21.546024" data-bs-parent="#accordionFlushExample">
      <div class="accordion-body">
        <p class="author">Authors: Isaacson, M. D.; Eliason, J. L.; Nern, A.; Rogers, E. M.; Lott, G. K.; Tabachnik, T.; Rowell, W. J.; Edwards, A. W.; Korff, W. L.; Rubin, G. M.; Branson, K.; Reiser, M. B.</p>
        <p class="info">Score: 28.2, Published: 2023-06-22 </p>
        <p class="info">DOI: <a href='https://doi.org/10.1101/2023.06.21.546024' target='https://doi.org/10.1101/2023.06.21.546024'> 10.1101/2023.06.21.546024</a></p>
        <p class="abstract">Animals rely on visual motion for navigating the world, and research in flies has clarified how neural circuits extract information from moving visual scenes. However, the major pathways connecting these patterns of optic flow to behavior remain poorly understood. Using a high-throughput quantitative assay of visually guided behaviors and genetic neuronal silencing, we discovered a region in Drosophilas protocerebrum critical for visual motion following. We used neuronal silencing, calcium imaging, and optogenetics to identify a single cell type, LPC1, that innervates this region, detects translational optic flow, and plays a key role in regulating forward walking. Moreover, the population of LPC1s can estimate the travelling direction, such as when gaze direction diverges from body heading. By linking specific cell types and their visual computations to specific behaviors, our findings establish a foundation for understanding how the nervous system uses vision to guide navigation.</p>
      </div>
    </div>
  </div><div class="accordion-item">
    <h3 class="accordion-header" id="flush-heading10.1101/2023.06.08.544257">
      <button class="accordion-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#flush-collapse10.1101/2023.06.08.544257" aria-expanded="false" aria-controls="flush-collapse10.1101/2023.06.08.544257">
        <p class="paperTitle">Not everything, not everywhere, not all at once: a study of brain-wide encoding of movement</p>
      </button>
    </h3>
    <div id="flush-collapse10.1101/2023.06.08.544257" class="accordion-collapse collapse" aria-labelledby="flush-heading10.1101/2023.06.08.544257" data-bs-parent="#accordionFlushExample">
      <div class="accordion-body">
        <p class="author">Authors: Wang, Z. A.; Chen, S.; Liu, Y.; Liu, D.; Svoboda, K.; Li, N.; Druckmann, S.</p>
        <p class="info">Score: 47.2, Published: 2023-06-14 </p>
        <p class="info">DOI: <a href='https://doi.org/10.1101/2023.06.08.544257' target='https://doi.org/10.1101/2023.06.08.544257'> 10.1101/2023.06.08.544257</a></p>
        <p class="abstract">Activity related to movement is found throughout sensory and motor regions of the brain. However, it remains unclear how movement-related activity is distributed across the brain and whether systematic differences exist between brain areas. Here, we analyzed movement related activity in brain-wide recordings containing more than 50,000 neurons in mice performing a decision-making task. Using multiple techniques, from markers to deep neural networks, we find that movement-related signals were pervasive across the brain, but systematically differed across areas. Movement-related activity was stronger in areas closer to the motor or sensory periphery. Delineating activity in terms of sensory- and motor-related components revealed finer scale structures of their encodings within brain areas. We further identified activity modulation that correlates with decision-making and uninstructed movement. Our work charts out a largescale map of movement encoding and provides a roadmap for dissecting different forms of movement and decision-making related encoding across multi-regional neural circuits.</p>
      </div>
    </div>
  </div><div class="accordion-item">
    <h3 class="accordion-header" id="flush-heading10.1101/2023.06.08.544277">
      <button class="accordion-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#flush-collapse10.1101/2023.06.08.544277" aria-expanded="false" aria-controls="flush-collapse10.1101/2023.06.08.544277">
        <p class="paperTitle">Expansion-assisted selective plane illumination microscopy for nanoscale imaging of centimeter-scale tissues</p>
      </button>
    </h3>
    <div id="flush-collapse10.1101/2023.06.08.544277" class="accordion-collapse collapse" aria-labelledby="flush-heading10.1101/2023.06.08.544277" data-bs-parent="#accordionFlushExample">
      <div class="accordion-body">
        <p class="author">Authors: Glaser, A.; Chandrashekar, J.; Vasquez, J.; Arshadi, C.; Ouellette, N.; Jiang, X.; Baka, J.; Kovacs, G.; Woodard, M.; Seshamani, S.; Cao, K.; Clack, N.; Recknagel, A.; Grim, A.; Balaram, P.; Turschak, E.; Liddell, A.; Rohde, J.; Hellevik, A.; Takasaki, K.; Erion Barner, L.; Logsdon, M.; Chronopoulos, C.; de Vries, S.; Ting, J.; Perlmutter, S.; Kalmbach, B.; Dembrow, N.; Reid, R. C.; Feng, D.; Svoboda, K.</p>
        <p class="info">Score: 361.4, Published: 2023-06-27 </p>
        <p class="info">DOI: <a href='https://doi.org/10.1101/2023.06.08.544277' target='https://doi.org/10.1101/2023.06.08.544277'> 10.1101/2023.06.08.544277</a></p>
        <p class="abstract">Recent advances in tissue processing, labeling, and fluorescence microscopy are providing unprecedented views of the structure of cells and tissues at sub-diffraction resolutions and near single molecule sensitivity, driving discoveries in diverse fields of biology, including neuroscience. Biological tissue is organized over scales of nanometers to centimeters. Harnessing molecular imaging across three-dimensional samples on this scale requires new types of microscopes with larger fields of view and working distance, as well as higher imaging throughput. We present a new expansion-assisted selective plane illumination microscope (ExA-SPIM) with diffraction-limited and aberration-free performance over a large field of view (85 mm2) and working distance (35 mm). Combined with new tissue clearing and expansion methods, the microscope allows nanoscale imaging of centimeter-scale samples, including entire mouse brains, with diffraction-limited resolutions and high contrast without sectioning. We illustrate ExA-SPIM by reconstructing individual neurons across the mouse brain, imaging cortico-spinal neurons in the macaque motor cortex, and tracing axons in human white matter.</p>
      </div>
    </div>
  </div>
</div>









<script src="/TRxiv2/js/bundle.min.js" defer></script>



  </div>

  <footer class="post-footer">
    <ul class="post-tags">
    </ul>
  </footer>
</article>
    </main>
    
<footer class="footer">
    <span>&copy; 2023 <a href="https://yorks0n.github.io/TRxiv2">TRxiv2</a></span>
    <span>
        Â· Made by Yorkson
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
</body>

</html>
