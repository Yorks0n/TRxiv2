<!DOCTYPE html>
<html lang="en" dir="auto">

<head>
<head>
    <title>radiology and imaging</title>
    <meta charset="utf-8">
    <meta name="description"
        content="Website meta description for google search results go here" />
    <meta name="dc.relation" content="https://trxiv.yorks0n.com" />
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta name="theme-color" content="#1A94D2" />

    

    
    
    
    <link rel="stylesheet" href="/css/main.min.css" media="screen">

</head>


<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>radiology and imaging | TRxiv2</title>
<meta name="keywords" content="">
<meta name="description" content="Multi-contrast high-field quality image synthesis for portable low-field MRI using generative adversarial networks and paired data
Authors: Lucas, A.; Arnold, T. C.; Okar, S. V.; Vadali, C.; Kawatra, K. D.; Ren, Z.; Cao, Q.; Shinohara, R. T.; Schindler, M. K.; Davis, K. A.; Litt, B.; Reich, D. S.; Stein, J. M.
Score: 15.9, Published: 2023-12-29 DOI: 10.1101/2023.12.28.23300409
IntroductionPortable low-field strength (64mT) MRI scanners promise to increase access to neuroimaging for clinical and research purposes, however these devices produce lower quality images compared to high-field scanners.">
<meta name="author" content="">
<link rel="canonical" href="https://trxiv.yorks0n.com/posts/radiology-and-imaging/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.904bd1e751cdd2a584fa6bed3fa1166dfd8ec9949ebfd0c4d69c5add5e17c23d.css" integrity="sha256-kEvR51HN0qWE&#43;mvtP6EWbf2OyZSev9DE1pxa3V4Xwj0=" rel="preload stylesheet" as="style">
<script defer crossorigin="anonymous" src="/assets/js/highlight.f413e19d0714851f6474e7ee9632408e58ac146fbdbe62747134bea2fa3415e0.js" integrity="sha256-9BPhnQcUhR9kdOfuljJAjlisFG&#43;9vmJ0cTS&#43;ovo0FeA="
    onload="hljs.initHighlightingOnLoad();"></script>
<link rel="icon" href="https://trxiv.yorks0n.com/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="https://trxiv.yorks0n.com/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://trxiv.yorks0n.com/favicon-32x32.png">
<link rel="apple-touch-icon" href="https://trxiv.yorks0n.com/apple-touch-icon.png">
<link rel="mask-icon" href="https://trxiv.yorks0n.com/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --hljs-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript><meta property="og:title" content="radiology and imaging" />
<meta property="og:description" content="Multi-contrast high-field quality image synthesis for portable low-field MRI using generative adversarial networks and paired data
Authors: Lucas, A.; Arnold, T. C.; Okar, S. V.; Vadali, C.; Kawatra, K. D.; Ren, Z.; Cao, Q.; Shinohara, R. T.; Schindler, M. K.; Davis, K. A.; Litt, B.; Reich, D. S.; Stein, J. M.
Score: 15.9, Published: 2023-12-29 DOI: 10.1101/2023.12.28.23300409
IntroductionPortable low-field strength (64mT) MRI scanners promise to increase access to neuroimaging for clinical and research purposes, however these devices produce lower quality images compared to high-field scanners." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://trxiv.yorks0n.com/posts/radiology-and-imaging/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2024-01-10T10:40:05+00:00" />
<meta property="article:modified_time" content="2024-01-10T10:40:05+00:00" />

<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="radiology and imaging"/>
<meta name="twitter:description" content="Multi-contrast high-field quality image synthesis for portable low-field MRI using generative adversarial networks and paired data
Authors: Lucas, A.; Arnold, T. C.; Okar, S. V.; Vadali, C.; Kawatra, K. D.; Ren, Z.; Cao, Q.; Shinohara, R. T.; Schindler, M. K.; Davis, K. A.; Litt, B.; Reich, D. S.; Stein, J. M.
Score: 15.9, Published: 2023-12-29 DOI: 10.1101/2023.12.28.23300409
IntroductionPortable low-field strength (64mT) MRI scanners promise to increase access to neuroimaging for clinical and research purposes, however these devices produce lower quality images compared to high-field scanners."/>


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "Posts",
      "item": "https://trxiv.yorks0n.com/posts/"
    }, 
    {
      "@type": "ListItem",
      "position":  3 ,
      "name": "radiology and imaging",
      "item": "https://trxiv.yorks0n.com/posts/radiology-and-imaging/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "radiology and imaging",
  "name": "radiology and imaging",
  "description": "Multi-contrast high-field quality image synthesis for portable low-field MRI using generative adversarial networks and paired data\nAuthors: Lucas, A.; Arnold, T. C.; Okar, S. V.; Vadali, C.; Kawatra, K. D.; Ren, Z.; Cao, Q.; Shinohara, R. T.; Schindler, M. K.; Davis, K. A.; Litt, B.; Reich, D. S.; Stein, J. M.\nScore: 15.9, Published: 2023-12-29 DOI: 10.1101/2023.12.28.23300409\nIntroductionPortable low-field strength (64mT) MRI scanners promise to increase access to neuroimaging for clinical and research purposes, however these devices produce lower quality images compared to high-field scanners.",
  "keywords": [
    
  ],
  "articleBody": " Multi-contrast high-field quality image synthesis for portable low-field MRI using generative adversarial networks and paired data\nAuthors: Lucas, A.; Arnold, T. C.; Okar, S. V.; Vadali, C.; Kawatra, K. D.; Ren, Z.; Cao, Q.; Shinohara, R. T.; Schindler, M. K.; Davis, K. A.; Litt, B.; Reich, D. S.; Stein, J. M.\nScore: 15.9, Published: 2023-12-29 DOI: 10.1101/2023.12.28.23300409\nIntroductionPortable low-field strength (64mT) MRI scanners promise to increase access to neuroimaging for clinical and research purposes, however these devices produce lower quality images compared to high-field scanners. In this study, we developed and evaluated a deep learning architecture to generate high-field quality brain images from low-field inputs using a paired dataset of multiple sclerosis (MS) patients scanned at 64mT and 3T. MethodsA total of 49 MS patients were scanned on portable 64mT and standard 3T scanners at Penn (n=25) or the National Institutes of Health (NIH, n=24) with T1-weighted, T2-weighted and FLAIR acquisitions. Using this paired data, we developed a generative adversarial network (GAN) architecture for low- to high-field image translation (LowGAN). We then evaluated synthesized images with respect to image quality, brain morphometry, and white matter lesions. ResultsSynthetic high-field images demonstrated visually superior quality compared to low-field inputs and significantly higher normalized cross-correlation (NCC) to actual high-field images for T1 (p=0.001) and FLAIR (p\u003c0.001) contrasts. LowGAN generally outperformed the current state- of-the-art for low-field volumetrics. For example, thalamic, lateral ventricle, and total cortical volumes in LowGAN outputs did not differ significantly from 3T measurements. Synthetic outputs preserved MS lesions and captured a known inverse relationship between total lesion volume and thalamic volume. ConclusionsLowGAN generates synthetic high-field images with comparable visual and quantitative quality to actual high-field scans. Enhancing portable MRI image quality could add value and boost clinician confidence, enabling wider adoption of this technology.\nSCIseg: Automatic Segmentation of T2-weighted Hyperintense Lesions in Spinal Cord Injury\nAuthors: Enamundram, N. K.; Valosek, J.; Smith, A. C.; Pfyffer, D.; Schading-Sassenhausen, S.; Farner, L.; Weber, K. A.; Freund, P.; Cohen-Adad, J.\nScore: 3.0, Published: 2024-01-03 DOI: 10.1101/2024.01.03.24300794\nBackgroundQuantitative MRI biomarkers in spinal cord injury (SCI) can help understand the extent of the focal injury. However, due to the lack of automatic segmentation methods, these biomarkers are derived manually, which is a time-consuming process prone to intra- and inter-rater variability, thus limiting large multi-site studies and translation to clinical workflows. PurposeTo develop a deep learning tool for the automatic segmentation of T2-weighted hyperintense lesions and the spinal cord in SCI patients. Material and MethodsThis retrospective study included a cohort of SCI patients from three sites enrolled between July 2002 and February 2023 who underwent clinical MRI examination. A deep learning model, SCIseg, was trained on T2-weighted images with heterogeneous image resolutions (isotropic, anisotropic), and orientations (axial, sagittal) acquired using scanners from different manufacturers (Siemens, Philips, GE) and different field strengths (1T, 1.5T, 3T) for the automatic segmentation of SCI lesions and the spinal cord. The proposed method was visually and quantitatively compared with other open-source baseline methods. Quantitative biomarkers (lesion volume, lesion length, and maximal axial damage ratio) computed from manual ground-truth lesion masks and automatic SCIseg predictions were correlated with clinical scores (pinprick, light touch, and lower extremity motor scores). A between-group comparison was performed using the Wilcoxon signed-rank test. ResultsMRI data from 191 SCI patients (mean age, 48.1 years {+/-} 17.9 [SD]; 142 males) were used for training. Compared to existing methods, SCIseg achieved the best segmentation performance for both the cord and lesions and generalized well to both traumatic and non-traumatic SCI patients. SCIseg is open-source and accessible through the Spinal Cord Toolbox. ConclusionAutomatic segmentation of intramedullary lesions commonly seen in traumatic SCI replaces the tedious manual annotation process and enables the extraction of relevant lesion morphometrics in large cohorts. The proposed model generalizes across lesion etiologies (traumatic, ischemic), scanner manufacturers and heterogeneous image resolutions. SummaryAutomatic segmentation of the spinal cord and T2-weighted hyperintense lesions in spinal cord injury on MRI scans across different treatment strategies, lesion etiologies, sites, scanner manufacturers, and heterogeneous image resolutions. Key ResultsO_LIAn open-source, automatic method, SCIseg, was trained on a dataset of 191 spinal cord injury patients from three sites for the segmentation of spinal cord and T2-weighted hyperintense lesions. C_LIO_LISCIseg generalizes across traumatic and non-traumatic lesions, scanner manufacturers, and heterogeneous image resolutions, enabling the automatic extraction of lesion morphometrics in large multi-site cohorts. C_LIO_LIMorphometrics derived from the automatic predictions showed no statistically significant difference when compared with manual ground truth, implying reliability in SCIsegs predictions. C_LI\nRadiomics-based prediction of local control in patients with brain metastases following postoperative stereotactic radiotherapy\nAuthors: Buchner, J. A.; Kofler, F.; Mayinger, M.; Christ, S. M.; Brunner, T. B.; Wittig, A.; Menze, B.; Zimmer, C.; Meyer, B.; Guckenberger, M.; Andratschke, N.; El Shafie, R. A.; Debus, J.; Rogers, S.; Riesterer, O.; Schulze, K.; Feldmann, H. J.; Blanck, O.; Zamboglou, C.; Ferentinos, K.; Bilger-Zähringer, A.; Grosu, A. L.; Wolff, R.; Piraud, M.; Eitz, K. A.; Combs, S. E.; Bernhardt, D.; Rueckert, D.; Wiestler, B.; Peeken, J. C.\nScore: 1.0, Published: 2024-01-04 DOI: 10.1101/2024.01.03.24300782\nBackgroundSurgical resection is the standard of care for patients with large or symptomatic brain metastases (BMs). Despite improved local control after adjuvant stereotactic radiotherapy, the local failure (LF) risk persists. Therefore, we aimed to develop and externally validate a pre-therapeutic radiomics-based prediction tool to identify patients at high LF risk. MethodsData were collected from A Multicenter Analysis of Stereotactic Radiotherapy to the Resection Cavity of Brain Metastases (AURORA) retrospective study (training cohort: 253 patients (two centers); external test cohort: 99 patients (five centers)). Radiomic features were extracted from the contrast-enhancing BM (T1-CE MRI sequence) and the surrounding edema (FLAIR sequence). Different combinations of radiomic and clinical features were compared. The final models were trained on the entire training cohort with the best parameters previously determined by internal 5-fold cross-validation and tested on the external test set. ResultsThe best performance in the external test was achieved by an elastic net regression model trained with a combination of radiomic and clinical features with a concordance index (CI) of 0.77, outperforming any clinical model (best CI: 0.70). The model effectively stratified patients by LF risk in a Kaplan-Meier analysis (p \u003c 0.001) and demonstrated an incremental net clinical benefit. At 24 months, we found LF in 9% and 74% of the low and high-risk groups, respectively. ConclusionsA combination of clinical and radiomic features predicted freedom from LF better than any clinical feature set alone. Patients at high risk for LF may benefit from stricter follow-up routines or intensified therapy. Key pointsO_LIRadiomics can predict the freedom from local failure in brain metastasis patients C_LIO_LIClinical and MRI-based radiomic features combined performed better than either alone C_LIO_LIThe proposed model significantly stratifies patients according to their risk C_LI Importance of the StudyLocal failure after treatment of brain metastases has a severe impact on patients, often resulting in additional therapy and loss of quality of life. This multicenter study investigated the possibility of predicting local failure of brain metastases after surgical resection and stereotactic radiotherapy using radiomic features extracted from the contrast-enhancing metastases and the surrounding FLAIR-hyperintense edema. By interpreting this as a survival task rather than a classification task, we were able to predict the freedom from failure probability at different time points and appropriately account for the censoring present in clinical time-to-event data. We found that synergistically combining clinical and imaging data performed better than either alone in the multicenter external test cohort, highlighting the potential of multimodal data analysis in this challenging task. Our results could improve the management of patients with brain metastases by tailoring follow-up and therapy to their individual risk of local failure.\n",
  "wordCount" : "1262",
  "inLanguage": "en",
  "datePublished": "2024-01-10T10:40:05Z",
  "dateModified": "2024-01-10T10:40:05Z",
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://trxiv.yorks0n.com/posts/radiology-and-imaging/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "TRxiv2",
    "logo": {
      "@type": "ImageObject",
      "url": "https://trxiv.yorks0n.com/favicon.ico"
    }
  }
}
</script>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://trxiv.yorks0n.com" accesskey="h" title="TRxiv2 (Alt + H)">TRxiv2</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
        </ul>
    </nav>
</header>
<main class="main">
<article class="post-single">
  <header class="post-header">
    
    <h1 class="post-title">
      radiology and imaging
    </h1>
    <div class="post-meta">&lt;span&gt;updated on January 10, 2024&lt;/span&gt;

</div>
  </header> 
  <div class="post-content"><div class="accordion accordion-flush" id="accordionFlushExample"><div class="accordion-item">
    <h3 class="accordion-header" id="flush-heading10.1101/2023.12.28.23300409">
      <button class="accordion-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#flush-collapse10.1101/2023.12.28.23300409" aria-expanded="false" aria-controls="flush-collapse10.1101/2023.12.28.23300409">
        <p class="paperTitle">Multi-contrast high-field quality image synthesis for portable low-field MRI using generative adversarial networks and paired data</p>
      </button>
    </h3>
    <div id="flush-collapse10.1101/2023.12.28.23300409" class="accordion-collapse collapse" aria-labelledby="flush-heading10.1101/2023.12.28.23300409" data-bs-parent="#accordionFlushExample">
      <div class="accordion-body">
        <p class="author">Authors: Lucas, A.; Arnold, T. C.; Okar, S. V.; Vadali, C.; Kawatra, K. D.; Ren, Z.; Cao, Q.; Shinohara, R. T.; Schindler, M. K.; Davis, K. A.; Litt, B.; Reich, D. S.; Stein, J. M.</p>
        <p class="info">Score: 15.9, Published: 2023-12-29 </p>
        <p class="info">DOI: <a href='https://doi.org/10.1101/2023.12.28.23300409' target='https://doi.org/10.1101/2023.12.28.23300409'> 10.1101/2023.12.28.23300409</a></p>
        <p class="abstract">IntroductionPortable low-field strength (64mT) MRI scanners promise to increase access to neuroimaging for clinical and research purposes, however these devices produce lower quality images compared to high-field scanners. In this study, we developed and evaluated a deep learning architecture to generate high-field quality brain images from low-field inputs using a paired dataset of multiple sclerosis (MS) patients scanned at 64mT and 3T.

MethodsA total of 49 MS patients were scanned on portable 64mT and standard 3T scanners at Penn (n=25) or the National Institutes of Health (NIH, n=24) with T1-weighted, T2-weighted and FLAIR acquisitions. Using this paired data, we developed a generative adversarial network (GAN) architecture for low- to high-field image translation (LowGAN). We then evaluated synthesized images with respect to image quality, brain morphometry, and white matter lesions.

ResultsSynthetic high-field images demonstrated visually superior quality compared to low-field inputs and significantly higher normalized cross-correlation (NCC) to actual high-field images for T1 (p=0.001) and FLAIR (p&lt;0.001) contrasts. LowGAN generally outperformed the current state- of-the-art for low-field volumetrics. For example, thalamic, lateral ventricle, and total cortical volumes in LowGAN outputs did not differ significantly from 3T measurements. Synthetic outputs preserved MS lesions and captured a known inverse relationship between total lesion volume and thalamic volume.

ConclusionsLowGAN generates synthetic high-field images with comparable visual and quantitative quality to actual high-field scans. Enhancing portable MRI image quality could add value and boost clinician confidence, enabling wider adoption of this technology.</p>
      </div>
    </div>
  </div><div class="accordion-item">
    <h3 class="accordion-header" id="flush-heading10.1101/2024.01.03.24300794">
      <button class="accordion-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#flush-collapse10.1101/2024.01.03.24300794" aria-expanded="false" aria-controls="flush-collapse10.1101/2024.01.03.24300794">
        <p class="paperTitle">SCIseg: Automatic Segmentation of T2-weighted Hyperintense Lesions in Spinal Cord Injury</p>
      </button>
    </h3>
    <div id="flush-collapse10.1101/2024.01.03.24300794" class="accordion-collapse collapse" aria-labelledby="flush-heading10.1101/2024.01.03.24300794" data-bs-parent="#accordionFlushExample">
      <div class="accordion-body">
        <p class="author">Authors: Enamundram, N. K.; Valosek, J.; Smith, A. C.; Pfyffer, D.; Schading-Sassenhausen, S.; Farner, L.; Weber, K. A.; Freund, P.; Cohen-Adad, J.</p>
        <p class="info">Score: 3.0, Published: 2024-01-03 </p>
        <p class="info">DOI: <a href='https://doi.org/10.1101/2024.01.03.24300794' target='https://doi.org/10.1101/2024.01.03.24300794'> 10.1101/2024.01.03.24300794</a></p>
        <p class="abstract">BackgroundQuantitative MRI biomarkers in spinal cord injury (SCI) can help understand the extent of the focal injury. However, due to the lack of automatic segmentation methods, these biomarkers are derived manually, which is a time-consuming process prone to intra- and inter-rater variability, thus limiting large multi-site studies and translation to clinical workflows.

PurposeTo develop a deep learning tool for the automatic segmentation of T2-weighted hyperintense lesions and the spinal cord in SCI patients.

Material and MethodsThis retrospective study included a cohort of SCI patients from three sites enrolled between July 2002 and February 2023 who underwent clinical MRI examination. A deep learning model, SCIseg, was trained on T2-weighted images with heterogeneous image resolutions (isotropic, anisotropic), and orientations (axial, sagittal) acquired using scanners from different manufacturers (Siemens, Philips, GE) and different field strengths (1T, 1.5T, 3T) for the automatic segmentation of SCI lesions and the spinal cord. The proposed method was visually and quantitatively compared with other open-source baseline methods. Quantitative biomarkers (lesion volume, lesion length, and maximal axial damage ratio) computed from manual ground-truth lesion masks and automatic SCIseg predictions were correlated with clinical scores (pinprick, light touch, and lower extremity motor scores). A between-group comparison was performed using the Wilcoxon signed-rank test.

ResultsMRI data from 191 SCI patients (mean age, 48.1 years {&#43;/-} 17.9 [SD]; 142 males) were used for training. Compared to existing methods, SCIseg achieved the best segmentation performance for both the cord and lesions and generalized well to both traumatic and non-traumatic SCI patients. SCIseg is open-source and accessible through the Spinal Cord Toolbox.

ConclusionAutomatic segmentation of intramedullary lesions commonly seen in traumatic SCI replaces the tedious manual annotation process and enables the extraction of relevant lesion morphometrics in large cohorts. The proposed model generalizes across lesion etiologies (traumatic, ischemic), scanner manufacturers and heterogeneous image resolutions.

SummaryAutomatic segmentation of the spinal cord and T2-weighted hyperintense lesions in spinal cord injury on MRI scans across different treatment strategies, lesion etiologies, sites, scanner manufacturers, and heterogeneous image resolutions.

Key ResultsO_LIAn open-source, automatic method, SCIseg, was trained on a dataset of 191 spinal cord injury patients from three sites for the segmentation of spinal cord and T2-weighted hyperintense lesions.
C_LIO_LISCIseg generalizes across traumatic and non-traumatic lesions, scanner manufacturers, and heterogeneous image resolutions, enabling the automatic extraction of lesion morphometrics in large multi-site cohorts.
C_LIO_LIMorphometrics derived from the automatic predictions showed no statistically significant difference when compared with manual ground truth, implying reliability in SCIsegs predictions.
C_LI</p>
      </div>
    </div>
  </div><div class="accordion-item">
    <h3 class="accordion-header" id="flush-heading10.1101/2024.01.03.24300782">
      <button class="accordion-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#flush-collapse10.1101/2024.01.03.24300782" aria-expanded="false" aria-controls="flush-collapse10.1101/2024.01.03.24300782">
        <p class="paperTitle">Radiomics-based prediction of local control in patients with brain metastases following postoperative stereotactic radiotherapy</p>
      </button>
    </h3>
    <div id="flush-collapse10.1101/2024.01.03.24300782" class="accordion-collapse collapse" aria-labelledby="flush-heading10.1101/2024.01.03.24300782" data-bs-parent="#accordionFlushExample">
      <div class="accordion-body">
        <p class="author">Authors: Buchner, J. A.; Kofler, F.; Mayinger, M.; Christ, S. M.; Brunner, T. B.; Wittig, A.; Menze, B.; Zimmer, C.; Meyer, B.; Guckenberger, M.; Andratschke, N.; El Shafie, R. A.; Debus, J.; Rogers, S.; Riesterer, O.; Schulze, K.; Feldmann, H. J.; Blanck, O.; Zamboglou, C.; Ferentinos, K.; Bilger-Zähringer, A.; Grosu, A. L.; Wolff, R.; Piraud, M.; Eitz, K. A.; Combs, S. E.; Bernhardt, D.; Rueckert, D.; Wiestler, B.; Peeken, J. C.</p>
        <p class="info">Score: 1.0, Published: 2024-01-04 </p>
        <p class="info">DOI: <a href='https://doi.org/10.1101/2024.01.03.24300782' target='https://doi.org/10.1101/2024.01.03.24300782'> 10.1101/2024.01.03.24300782</a></p>
        <p class="abstract">BackgroundSurgical resection is the standard of care for patients with large or symptomatic brain metastases (BMs). Despite improved local control after adjuvant stereotactic radiotherapy, the local failure (LF) risk persists. Therefore, we aimed to develop and externally validate a pre-therapeutic radiomics-based prediction tool to identify patients at high LF risk.

MethodsData were collected from A Multicenter Analysis of Stereotactic Radiotherapy to the Resection Cavity of Brain Metastases (AURORA) retrospective study (training cohort: 253 patients (two centers); external test cohort: 99 patients (five centers)). Radiomic features were extracted from the contrast-enhancing BM (T1-CE MRI sequence) and the surrounding edema (FLAIR sequence). Different combinations of radiomic and clinical features were compared. The final models were trained on the entire training cohort with the best parameters previously determined by internal 5-fold cross-validation and tested on the external test set.

ResultsThe best performance in the external test was achieved by an elastic net regression model trained with a combination of radiomic and clinical features with a concordance index (CI) of 0.77, outperforming any clinical model (best CI: 0.70). The model effectively stratified patients by LF risk in a Kaplan-Meier analysis (p &lt; 0.001) and demonstrated an incremental net clinical benefit. At 24 months, we found LF in 9% and 74% of the low and high-risk groups, respectively.

ConclusionsA combination of clinical and radiomic features predicted freedom from LF better than any clinical feature set alone. Patients at high risk for LF may benefit from stricter follow-up routines or intensified therapy.

Key pointsO_LIRadiomics can predict the freedom from local failure in brain metastasis patients
C_LIO_LIClinical and MRI-based radiomic features combined performed better than either alone
C_LIO_LIThe proposed model significantly stratifies patients according to their risk
C_LI

Importance of the StudyLocal failure after treatment of brain metastases has a severe impact on patients, often resulting in additional therapy and loss of quality of life. This multicenter study investigated the possibility of predicting local failure of brain metastases after surgical resection and stereotactic radiotherapy using radiomic features extracted from the contrast-enhancing metastases and the surrounding FLAIR-hyperintense edema.

By interpreting this as a survival task rather than a classification task, we were able to predict the freedom from failure probability at different time points and appropriately account for the censoring present in clinical time-to-event data.

We found that synergistically combining clinical and imaging data performed better than either alone in the multicenter external test cohort, highlighting the potential of multimodal data analysis in this challenging task. Our results could improve the management of patients with brain metastases by tailoring follow-up and therapy to their individual risk of local failure.</p>
      </div>
    </div>
  </div>
</div>









<script src="/js/bundle.min.js" defer></script>



  </div>

  <footer class="post-footer">
    <ul class="post-tags">
    </ul>
  </footer>
</article>
    </main>
    
<footer class="footer">
    <span>&copy; 2024 <a href="https://trxiv.yorks0n.com">TRxiv2</a></span>
    <span>
        · Made by Yorkson
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
</body>

</html>
