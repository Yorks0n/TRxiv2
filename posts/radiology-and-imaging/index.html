<!DOCTYPE html>
<html lang="en" dir="auto">

<head>
<head>
    <title>radiology and imaging</title>
    <meta charset="utf-8">
    <meta name="description"
        content="Website meta description for google search results go here" />
    <meta name="dc.relation" content="https://trxiv.yorks0n.com" />
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta name="theme-color" content="#1A94D2" />

    

    
    
    
    <link rel="stylesheet" href="/css/main.min.css" media="screen">

</head>


<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>radiology and imaging | TRxiv2</title>
<meta name="keywords" content="">
<meta name="description" content="Automated quantitative evaluation of thymic involution and hyperplasia on plain chest CT
Authors: Okamura, Y. T.; Endo, K.; Toriihara, A.; Fukuda, I.; Isogai, J.; Sato, Y.; Yasuoka, K.; Kagami, S.-I.
Score: 1.2, Published: 2023-11-14 DOI: 10.1101/2023.11.13.23298440
ObjectiveTo establish an automatic method to quantify thymic involution and hyperplasia based on plain chest computed tomography (CT). MethodsWe defined the thymic region for quantification (TRQ) as the target region. We manually segmented the TRQ in 135 CT studies, followed by construction of segmentation neural network (NN) models based on the data.">
<meta name="author" content="">
<link rel="canonical" href="https://trxiv.yorks0n.com/posts/radiology-and-imaging/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.904bd1e751cdd2a584fa6bed3fa1166dfd8ec9949ebfd0c4d69c5add5e17c23d.css" integrity="sha256-kEvR51HN0qWE&#43;mvtP6EWbf2OyZSev9DE1pxa3V4Xwj0=" rel="preload stylesheet" as="style">
<script defer crossorigin="anonymous" src="/assets/js/highlight.f413e19d0714851f6474e7ee9632408e58ac146fbdbe62747134bea2fa3415e0.js" integrity="sha256-9BPhnQcUhR9kdOfuljJAjlisFG&#43;9vmJ0cTS&#43;ovo0FeA="
    onload="hljs.initHighlightingOnLoad();"></script>
<link rel="icon" href="https://trxiv.yorks0n.com/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="https://trxiv.yorks0n.com/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://trxiv.yorks0n.com/favicon-32x32.png">
<link rel="apple-touch-icon" href="https://trxiv.yorks0n.com/apple-touch-icon.png">
<link rel="mask-icon" href="https://trxiv.yorks0n.com/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --hljs-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript><meta property="og:title" content="radiology and imaging" />
<meta property="og:description" content="Automated quantitative evaluation of thymic involution and hyperplasia on plain chest CT
Authors: Okamura, Y. T.; Endo, K.; Toriihara, A.; Fukuda, I.; Isogai, J.; Sato, Y.; Yasuoka, K.; Kagami, S.-I.
Score: 1.2, Published: 2023-11-14 DOI: 10.1101/2023.11.13.23298440
ObjectiveTo establish an automatic method to quantify thymic involution and hyperplasia based on plain chest computed tomography (CT). MethodsWe defined the thymic region for quantification (TRQ) as the target region. We manually segmented the TRQ in 135 CT studies, followed by construction of segmentation neural network (NN) models based on the data." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://trxiv.yorks0n.com/posts/radiology-and-imaging/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-11-19T10:38:34+00:00" />
<meta property="article:modified_time" content="2023-11-19T10:38:34+00:00" />

<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="radiology and imaging"/>
<meta name="twitter:description" content="Automated quantitative evaluation of thymic involution and hyperplasia on plain chest CT
Authors: Okamura, Y. T.; Endo, K.; Toriihara, A.; Fukuda, I.; Isogai, J.; Sato, Y.; Yasuoka, K.; Kagami, S.-I.
Score: 1.2, Published: 2023-11-14 DOI: 10.1101/2023.11.13.23298440
ObjectiveTo establish an automatic method to quantify thymic involution and hyperplasia based on plain chest computed tomography (CT). MethodsWe defined the thymic region for quantification (TRQ) as the target region. We manually segmented the TRQ in 135 CT studies, followed by construction of segmentation neural network (NN) models based on the data."/>


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "Posts",
      "item": "https://trxiv.yorks0n.com/posts/"
    }, 
    {
      "@type": "ListItem",
      "position":  3 ,
      "name": "radiology and imaging",
      "item": "https://trxiv.yorks0n.com/posts/radiology-and-imaging/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "radiology and imaging",
  "name": "radiology and imaging",
  "description": "Automated quantitative evaluation of thymic involution and hyperplasia on plain chest CT\nAuthors: Okamura, Y. T.; Endo, K.; Toriihara, A.; Fukuda, I.; Isogai, J.; Sato, Y.; Yasuoka, K.; Kagami, S.-I.\nScore: 1.2, Published: 2023-11-14 DOI: 10.1101/2023.11.13.23298440\nObjectiveTo establish an automatic method to quantify thymic involution and hyperplasia based on plain chest computed tomography (CT). MethodsWe defined the thymic region for quantification (TRQ) as the target region. We manually segmented the TRQ in 135 CT studies, followed by construction of segmentation neural network (NN) models based on the data.",
  "keywords": [
    
  ],
  "articleBody": " Automated quantitative evaluation of thymic involution and hyperplasia on plain chest CT\nAuthors: Okamura, Y. T.; Endo, K.; Toriihara, A.; Fukuda, I.; Isogai, J.; Sato, Y.; Yasuoka, K.; Kagami, S.-I.\nScore: 1.2, Published: 2023-11-14 DOI: 10.1101/2023.11.13.23298440\nObjectiveTo establish an automatic method to quantify thymic involution and hyperplasia based on plain chest computed tomography (CT). MethodsWe defined the thymic region for quantification (TRQ) as the target region. We manually segmented the TRQ in 135 CT studies, followed by construction of segmentation neural network (NN) models based on the data. We developed the estimator of thymic volume (ETV), a measure of the thymic tissue volume in the segmented TRQ. The Hounsfield unit (HU) value and volume of the TRQ were measured, and the ETV was calculated in each CT study from 853 healthy subjects. We investigated how these measures were related to the age and sex using quantile additive regression models. We defined the ETV z-score, an age- and sex-adjusted version of ETV, to distinguish between subjects with thymic hyperplasia (18 cases) and healthy subjects. A receiver operating characteristic (ROC) curve analysis was conducted. ResultsA significant correlation between the NN-segmented and manually segmented TRQ was seen for both the HU value and volume of the TRQ (r = 0.996 and r = 0.986 respectively). The ETV could detect age-related decline in the thymic tissue volume (p \u003c 0.001). No statistically significant difference was detected between male and female subjects (p = 0.19). The ETV was significantly higher in the thymic hyperplasia group as compared with that in the healthy control group (p \u003c 0.001). The ETV z-score could distinguish between subjects with thymic hyperplasia and healthy subjects, with the ROC curve analysis revealing an area under the curve (AUC) of 0.88 (95% CI: 0.75-1.0). ConclusionOur method enabled robust quantification of thymic involution and hyperplasia. The results were consistent with the trends found in previous studies. Clinical Relevance StatementOur method allows reliable and automatic measurement of thymic involution and hyperplasia on CT images. This may aid in the early detection and monitoring of pathologies related to the thymus, including autoimmune diseases. Key Points- We defined the thymic region for quantification (TRQ) to fully automate the evaluation of thymic involution and hyperplasia. The neural networks could identify the TRQ with sufficient accuracy. - We developed the estimator of thymic volume (ETV) to quantify the thymic tissue in the TRQ. ETV captured age-related thymic involution and thymic hyperplasia. - The ETV could prove useful in the management of pathologies associated with involution or hyperplasia of the thymus.\nPerformance of Multimodal GPT-4V on USMLE with Image: Potential for Imaging Diagnostic Support with Explanations\nAuthors: Yang, Z.; Yao, Z.; Tasmin, M.; Vashisht, P.; Jang, W. S.; Wang, B.; Ouyang, F.; Berlowitz, D.; Yu, H.\nScore: 1.2, Published: 2023-11-15 DOI: 10.1101/2023.10.26.23297629\nImportanceUsing artificial intelligence (AI) to help clinical diagnoses has been an active research topic for more than six decades. Few research however has the scale and accuracy that can be turned into clinical practice. The tide may be turned today with the power of large language models (LLMs). In this application, we evaluated the accuracy of medical license exam using the newly released Generative Pre-trained Transformer 4 with vision (GPT-4V), a large multimodal model trained to analyze image inputs with the text instructions from the user. This study is the first to evaluate GPTs for interpreting medical images. ObjectiveThis study aimed to evaluate the performance of GPT-4V on medical licensing examination questions with images, as well as to analyze interpretability. Design, Setting, and ParticipantsWe used 3 sets of multiple-choice questions with images to evaluate GPT-4Vs performance. The first set was the United States Medical Licensing Examination (USMLE) from the National Board of Medical Examiners (NBME) sample questions in step1, step2CK, and step3. The second set was derived from AMBOSS, a commonly used question bank for medical students, which also provides statistics on question difficulty and the performance on an exam relative to the user base. The third set was the Diagnostic Radiology Qualifying Core Exam (DRQCE) from the American Board of Radiology. The study (including data analysis) was conducted from September to October 2023. Main Outcomes and MeasuresThe choice accuracy of GPT-4V was compared to two other large language models, GPT-4 and ChatGPT. The GPT-4V explanation was evaluated across 4 qualitative metrics: image misunderstanding, text hallucination, reasoning error, and non-medical error. ResultsOf the 3 exams with images, NBME, AMBOSS, and DRQCE, GPT-4V achieved accuracies of 86.2%, 62.0%, and 73.1%, respectively. GPT-4V outperformed ChatGPT and GPT-4 by 131.8% and 64.5% on average across various data sets. The model demonstrated a decreasing trend in performance as question difficulty increased in the AMBOSS dataset. GPT-4V achieves an accuracy of 90.7% in the full USMLE exam, outperforming the passing threshold of about 60% accuracy. Among the incorrect answers, 75.9% of responses included misinterpretation of the image. However, 39.0% of them could be easily solved with a short hint. ConclusionIn this cross-sectional study, GPT-4V achieved a high accuracy of USMLE that was in the 70th - 80th percentile with AMBOSS users preparing for the exam. The results suggest the potential of GPT-4V for clinical decision support. However, GPT-4V generated explanation revealed several issues. It needs to improve explanation quality for potential use in clinical decision support.\n",
  "wordCount" : "874",
  "inLanguage": "en",
  "datePublished": "2023-11-19T10:38:34Z",
  "dateModified": "2023-11-19T10:38:34Z",
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://trxiv.yorks0n.com/posts/radiology-and-imaging/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "TRxiv2",
    "logo": {
      "@type": "ImageObject",
      "url": "https://trxiv.yorks0n.com/favicon.ico"
    }
  }
}
</script>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://trxiv.yorks0n.com" accesskey="h" title="TRxiv2 (Alt + H)">TRxiv2</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
        </ul>
    </nav>
</header>
<main class="main">
<article class="post-single">
  <header class="post-header">
    
    <h1 class="post-title">
      radiology and imaging
    </h1>
    <div class="post-meta">&lt;span&gt;updated on November 19, 2023&lt;/span&gt;

</div>
  </header> 
  <div class="post-content"><div class="accordion accordion-flush" id="accordionFlushExample"><div class="accordion-item">
    <h3 class="accordion-header" id="flush-heading10.1101/2023.11.13.23298440">
      <button class="accordion-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#flush-collapse10.1101/2023.11.13.23298440" aria-expanded="false" aria-controls="flush-collapse10.1101/2023.11.13.23298440">
        <p class="paperTitle">Automated quantitative evaluation of thymic involution and hyperplasia on plain chest CT</p>
      </button>
    </h3>
    <div id="flush-collapse10.1101/2023.11.13.23298440" class="accordion-collapse collapse" aria-labelledby="flush-heading10.1101/2023.11.13.23298440" data-bs-parent="#accordionFlushExample">
      <div class="accordion-body">
        <p class="author">Authors: Okamura, Y. T.; Endo, K.; Toriihara, A.; Fukuda, I.; Isogai, J.; Sato, Y.; Yasuoka, K.; Kagami, S.-I.</p>
        <p class="info">Score: 1.2, Published: 2023-11-14 </p>
        <p class="info">DOI: <a href='https://doi.org/10.1101/2023.11.13.23298440' target='https://doi.org/10.1101/2023.11.13.23298440'> 10.1101/2023.11.13.23298440</a></p>
        <p class="abstract">ObjectiveTo establish an automatic method to quantify thymic involution and hyperplasia based on plain chest computed tomography (CT).

MethodsWe defined the thymic region for quantification (TRQ) as the target region. We manually segmented the TRQ in 135 CT studies, followed by construction of segmentation neural network (NN) models based on the data. We developed the estimator of thymic volume (ETV), a measure of the thymic tissue volume in the segmented TRQ. The Hounsfield unit (HU) value and volume of the TRQ were measured, and the ETV was calculated in each CT study from 853 healthy subjects. We investigated how these measures were related to the age and sex using quantile additive regression models. We defined the ETV z-score, an age- and sex-adjusted version of ETV, to distinguish between subjects with thymic hyperplasia (18 cases) and healthy subjects. A receiver operating characteristic (ROC) curve analysis was conducted.

ResultsA significant correlation between the NN-segmented and manually segmented TRQ was seen for both the HU value and volume of the TRQ (r = 0.996 and r = 0.986 respectively). The ETV could detect age-related decline in the thymic tissue volume (p &lt; 0.001). No statistically significant difference was detected between male and female subjects (p = 0.19). The ETV was significantly higher in the thymic hyperplasia group as compared with that in the healthy control group (p &lt; 0.001). The ETV z-score could distinguish between subjects with thymic hyperplasia and healthy subjects, with the ROC curve analysis revealing an area under the curve (AUC) of 0.88 (95% CI: 0.75-1.0).

ConclusionOur method enabled robust quantification of thymic involution and hyperplasia. The results were consistent with the trends found in previous studies.

Clinical Relevance StatementOur method allows reliable and automatic measurement of thymic involution and hyperplasia on CT images. This may aid in the early detection and monitoring of pathologies related to the thymus, including autoimmune diseases.

Key Points- We defined the thymic region for quantification (TRQ) to fully automate the evaluation of thymic involution and hyperplasia. The neural networks could identify the TRQ with sufficient accuracy.
- We developed the estimator of thymic volume (ETV) to quantify the thymic tissue in the TRQ. ETV captured age-related thymic involution and thymic hyperplasia.
- The ETV could prove useful in the management of pathologies associated with involution or hyperplasia of the thymus.</p>
      </div>
    </div>
  </div><div class="accordion-item">
    <h3 class="accordion-header" id="flush-heading10.1101/2023.10.26.23297629">
      <button class="accordion-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#flush-collapse10.1101/2023.10.26.23297629" aria-expanded="false" aria-controls="flush-collapse10.1101/2023.10.26.23297629">
        <p class="paperTitle">Performance of Multimodal GPT-4V on USMLE with Image: Potential for Imaging Diagnostic Support with Explanations</p>
      </button>
    </h3>
    <div id="flush-collapse10.1101/2023.10.26.23297629" class="accordion-collapse collapse" aria-labelledby="flush-heading10.1101/2023.10.26.23297629" data-bs-parent="#accordionFlushExample">
      <div class="accordion-body">
        <p class="author">Authors: Yang, Z.; Yao, Z.; Tasmin, M.; Vashisht, P.; Jang, W. S.; Wang, B.; Ouyang, F.; Berlowitz, D.; Yu, H.</p>
        <p class="info">Score: 1.2, Published: 2023-11-15 </p>
        <p class="info">DOI: <a href='https://doi.org/10.1101/2023.10.26.23297629' target='https://doi.org/10.1101/2023.10.26.23297629'> 10.1101/2023.10.26.23297629</a></p>
        <p class="abstract">ImportanceUsing artificial intelligence (AI) to help clinical diagnoses has been an active research topic for more than six decades. Few research however has the scale and accuracy that can be turned into clinical practice. The tide may be turned today with the power of large language models (LLMs). In this application, we evaluated the accuracy of medical license exam using the newly released Generative Pre-trained Transformer 4 with vision (GPT-4V), a large multimodal model trained to analyze image inputs with the text instructions from the user. This study is the first to evaluate GPTs for interpreting medical images.

ObjectiveThis study aimed to evaluate the performance of GPT-4V on medical licensing examination questions with images, as well as to analyze interpretability.

Design, Setting, and ParticipantsWe used 3 sets of multiple-choice questions with images to evaluate GPT-4Vs performance. The first set was the United States Medical Licensing Examination (USMLE) from the National Board of Medical Examiners (NBME) sample questions in step1, step2CK, and step3. The second set was derived from AMBOSS, a commonly used question bank for medical students, which also provides statistics on question difficulty and the performance on an exam relative to the user base. The third set was the Diagnostic Radiology Qualifying Core Exam (DRQCE) from the American Board of Radiology. The study (including data analysis) was conducted from September to October 2023.

Main Outcomes and MeasuresThe choice accuracy of GPT-4V was compared to two other large language models, GPT-4 and ChatGPT. The GPT-4V explanation was evaluated across 4 qualitative metrics: image misunderstanding, text hallucination, reasoning error, and non-medical error.

ResultsOf the 3 exams with images, NBME, AMBOSS, and DRQCE, GPT-4V achieved accuracies of 86.2%, 62.0%, and 73.1%, respectively. GPT-4V outperformed ChatGPT and GPT-4 by 131.8% and 64.5% on average across various data sets. The model demonstrated a decreasing trend in performance as question difficulty increased in the AMBOSS dataset. GPT-4V achieves an accuracy of 90.7% in the full USMLE exam, outperforming the passing threshold of about 60% accuracy. Among the incorrect answers, 75.9% of responses included misinterpretation of the image. However, 39.0% of them could be easily solved with a short hint.

ConclusionIn this cross-sectional study, GPT-4V achieved a high accuracy of USMLE that was in the 70th - 80th percentile with AMBOSS users preparing for the exam. The results suggest the potential of GPT-4V for clinical decision support. However, GPT-4V generated explanation revealed several issues. It needs to improve explanation quality for potential use in clinical decision support.</p>
      </div>
    </div>
  </div>
</div>









<script src="/js/bundle.min.js" defer></script>



  </div>

  <footer class="post-footer">
    <ul class="post-tags">
    </ul>
  </footer>
</article>
    </main>
    
<footer class="footer">
    <span>&copy; 2023 <a href="https://trxiv.yorks0n.com">TRxiv2</a></span>
    <span>
        · Made by Yorkson
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
</body>

</html>
