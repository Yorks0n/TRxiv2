<!DOCTYPE html>
<html lang="en" dir="auto">

<head>
<head>
    <title>radiology and imaging</title>
    <meta charset="utf-8">
    <meta name="description"
        content="Website meta description for google search results go here" />
    <meta name="dc.relation" content="https://trxiv.yorks0n.com" />
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta name="theme-color" content="#1A94D2" />

    

    
    
    
    <link rel="stylesheet" href="/css/main.min.css" media="screen">

</head>


<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>radiology and imaging | TRxiv2</title>
<meta name="keywords" content="">
<meta name="description" content="Multi-contrast high-field quality image synthesis for portable low-field MRI using generative adversarial networks and paired data
Authors: Lucas, A.; Arnold, T. C.; Okar, S. V.; Vadali, C.; Kawatra, K. D.; Ren, Z.; Cao, Q.; Shinohara, R. T.; Schindler, M. K.; Davis, K. A.; Litt, B.; Reich, D. S.; Stein, J. M.
Score: 16.1, Published: 2023-12-29 DOI: 10.1101/2023.12.28.23300409
IntroductionPortable low-field strength (64mT) MRI scanners promise to increase access to neuroimaging for clinical and research purposes, however these devices produce lower quality images compared to high-field scanners.">
<meta name="author" content="">
<link rel="canonical" href="https://trxiv.yorks0n.com/posts/radiology-and-imaging/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.904bd1e751cdd2a584fa6bed3fa1166dfd8ec9949ebfd0c4d69c5add5e17c23d.css" integrity="sha256-kEvR51HN0qWE&#43;mvtP6EWbf2OyZSev9DE1pxa3V4Xwj0=" rel="preload stylesheet" as="style">
<script defer crossorigin="anonymous" src="/assets/js/highlight.f413e19d0714851f6474e7ee9632408e58ac146fbdbe62747134bea2fa3415e0.js" integrity="sha256-9BPhnQcUhR9kdOfuljJAjlisFG&#43;9vmJ0cTS&#43;ovo0FeA="
    onload="hljs.initHighlightingOnLoad();"></script>
<link rel="icon" href="https://trxiv.yorks0n.com/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="https://trxiv.yorks0n.com/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://trxiv.yorks0n.com/favicon-32x32.png">
<link rel="apple-touch-icon" href="https://trxiv.yorks0n.com/apple-touch-icon.png">
<link rel="mask-icon" href="https://trxiv.yorks0n.com/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --hljs-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript><meta property="og:title" content="radiology and imaging" />
<meta property="og:description" content="Multi-contrast high-field quality image synthesis for portable low-field MRI using generative adversarial networks and paired data
Authors: Lucas, A.; Arnold, T. C.; Okar, S. V.; Vadali, C.; Kawatra, K. D.; Ren, Z.; Cao, Q.; Shinohara, R. T.; Schindler, M. K.; Davis, K. A.; Litt, B.; Reich, D. S.; Stein, J. M.
Score: 16.1, Published: 2023-12-29 DOI: 10.1101/2023.12.28.23300409
IntroductionPortable low-field strength (64mT) MRI scanners promise to increase access to neuroimaging for clinical and research purposes, however these devices produce lower quality images compared to high-field scanners." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://trxiv.yorks0n.com/posts/radiology-and-imaging/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2024-01-14T10:38:40+00:00" />
<meta property="article:modified_time" content="2024-01-14T10:38:40+00:00" />

<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="radiology and imaging"/>
<meta name="twitter:description" content="Multi-contrast high-field quality image synthesis for portable low-field MRI using generative adversarial networks and paired data
Authors: Lucas, A.; Arnold, T. C.; Okar, S. V.; Vadali, C.; Kawatra, K. D.; Ren, Z.; Cao, Q.; Shinohara, R. T.; Schindler, M. K.; Davis, K. A.; Litt, B.; Reich, D. S.; Stein, J. M.
Score: 16.1, Published: 2023-12-29 DOI: 10.1101/2023.12.28.23300409
IntroductionPortable low-field strength (64mT) MRI scanners promise to increase access to neuroimaging for clinical and research purposes, however these devices produce lower quality images compared to high-field scanners."/>


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "Posts",
      "item": "https://trxiv.yorks0n.com/posts/"
    }, 
    {
      "@type": "ListItem",
      "position":  3 ,
      "name": "radiology and imaging",
      "item": "https://trxiv.yorks0n.com/posts/radiology-and-imaging/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "radiology and imaging",
  "name": "radiology and imaging",
  "description": "Multi-contrast high-field quality image synthesis for portable low-field MRI using generative adversarial networks and paired data\nAuthors: Lucas, A.; Arnold, T. C.; Okar, S. V.; Vadali, C.; Kawatra, K. D.; Ren, Z.; Cao, Q.; Shinohara, R. T.; Schindler, M. K.; Davis, K. A.; Litt, B.; Reich, D. S.; Stein, J. M.\nScore: 16.1, Published: 2023-12-29 DOI: 10.1101/2023.12.28.23300409\nIntroductionPortable low-field strength (64mT) MRI scanners promise to increase access to neuroimaging for clinical and research purposes, however these devices produce lower quality images compared to high-field scanners.",
  "keywords": [
    
  ],
  "articleBody": " Multi-contrast high-field quality image synthesis for portable low-field MRI using generative adversarial networks and paired data\nAuthors: Lucas, A.; Arnold, T. C.; Okar, S. V.; Vadali, C.; Kawatra, K. D.; Ren, Z.; Cao, Q.; Shinohara, R. T.; Schindler, M. K.; Davis, K. A.; Litt, B.; Reich, D. S.; Stein, J. M.\nScore: 16.1, Published: 2023-12-29 DOI: 10.1101/2023.12.28.23300409\nIntroductionPortable low-field strength (64mT) MRI scanners promise to increase access to neuroimaging for clinical and research purposes, however these devices produce lower quality images compared to high-field scanners. In this study, we developed and evaluated a deep learning architecture to generate high-field quality brain images from low-field inputs using a paired dataset of multiple sclerosis (MS) patients scanned at 64mT and 3T. MethodsA total of 49 MS patients were scanned on portable 64mT and standard 3T scanners at Penn (n=25) or the National Institutes of Health (NIH, n=24) with T1-weighted, T2-weighted and FLAIR acquisitions. Using this paired data, we developed a generative adversarial network (GAN) architecture for low- to high-field image translation (LowGAN). We then evaluated synthesized images with respect to image quality, brain morphometry, and white matter lesions. ResultsSynthetic high-field images demonstrated visually superior quality compared to low-field inputs and significantly higher normalized cross-correlation (NCC) to actual high-field images for T1 (p=0.001) and FLAIR (p\u003c0.001) contrasts. LowGAN generally outperformed the current state- of-the-art for low-field volumetrics. For example, thalamic, lateral ventricle, and total cortical volumes in LowGAN outputs did not differ significantly from 3T measurements. Synthetic outputs preserved MS lesions and captured a known inverse relationship between total lesion volume and thalamic volume. ConclusionsLowGAN generates synthetic high-field images with comparable visual and quantitative quality to actual high-field scans. Enhancing portable MRI image quality could add value and boost clinician confidence, enabling wider adoption of this technology.\nAssessing Performance of Multimodal ChatGPT-4 on an image based Radiology Board-style Examination: An exploratory study\nAuthors: Bera, K.; Gupta, A.; Jiang, S.; Berlin, S.; Faraji, N.; Tippareddy, C.; Chiong, I.; Jones, R.; Nemer, O.; Nayate, A.; Tirumani, S. H.; Ramaiya, N.\nScore: 1.6, Published: 2024-01-13 DOI: 10.1101/2024.01.12.24301222\nObjective To evaluate the performance of multimodal ChatGPT 4 on a radiology board-style examination containing text and radiologic images. Methods In this prospective exploratory study from October 30 to December 10, 2023, 110 multiple-choice questions containing images designed to match the style and content of radiology board examination like the American Board of Radiology Core or Canadian Board of Radiology examination were prompted to multimodal ChatGPT 4. Questions were further sub stratified according to lower-order (recall, understanding) and higher-order (analyze, synthesize), domains (according to radiology subspecialty), imaging modalities and difficulty (rated by both radiologists and radiologists-in-training). ChatGPT performance was assessed overall as well as in subcategories using Fisher exact test with multiple comparisons. Confidence in answering questions was assessed using a Likert scale (1-5) by consensus between a radiologist and radiologist-in-training. Reproducibility was assessed by comparing two different runs using two different accounts. Results ChatGPT 4 answered 55% (61/110) of image-rich questions correctly. While there was no significant difference in performance amongst the various sub-groups on exploratory analysis, performance was better on lower-order [61% (25/41)] when compared to higher-order [52% (36/69)] [P=.46]. Among clinical domains, performance was best on cardiovascular imaging [80% (8/10)], and worst on thoracic imaging [30% [3/10)]. Confidence in answering questions was confident/highly confident [89%(98/110)], even when incorrect There was poor reproducibility between two runs, with the answers being different in 14% (15/110) questions. Conclusion Despite no radiology specific pre-training, multimodal capabilities of ChatGPT appear promising on questions containing images. However, the lack of reproducibility among two runs, even with the same questions poses challenges of reliability.\nReduced Oxygen Extraction Fraction in Deep Cerebral Veins Associated with Cognitive Impairment in Multiple Sclerosis\nAuthors: Sawan, H.; Li, C.; Buch, S.; Bernitsas, E.; Haacke, E. M.; Ge, Y.; Chen, Y.\nScore: 1.5, Published: 2024-01-12 DOI: 10.1101/2024.01.10.24301049\nStudying the relationship between cerebral oxygen utilization and cognitive impairment is essential to understanding neuronal functional changes in the disease progression of multiple sclerosis (MS). This study explores the potential of using venous susceptibility in internal cerebral veins (ICVs) as an imaging biomarker for cognitive impairment in relapsing-remitting MS (RRMS) patients. Quantitative susceptibility mapping derived from fully flow-compensated MRI phase data was employed to directly measure venous blood oxygen saturation levels (SvO2) in the ICVs. Results revealed a significant reduction in the susceptibility of ICVs (212.4 {+/-} 30.8 ppb vs 239.4 {+/-} 25.9 ppb) and a significant increase of SvO2 (74.5 {+/-} 1.89 % vs 72.4 {+/-} 2.23 %) in patients with RRMS compared with age- and sex-matched healthy controls. Both the susceptibility of ICVs (r = 0.646, p = 0.004) and the SvO2 (r = -0.603, p = 0.008) exhibited a strong correlation with cognitive decline in these patients assessed by the Paced Auditory Serial Addition Test, while no significant correlation was observed with clinical disability measured by the Expanded Disability Status Scale. The findings suggest that venous susceptibility in ICVs has the potential to serve as a specific indicator of oxygen metabolism and cognitive function in RRMS.\nFive dominant dimensions of brain aging are identified via deep learning: associations with clinical, lifestyle, and genetic measures\nAuthors: Yang, Z.; Wen, J.; Erus, G.; Govindarajan, S. T.; Melhem, R.; Mamourian, E.; Cui, Y.; Srinivasan, D.; Abdulkadir, A.; Parmpi, P.; Wittfeld, K.; Grabe, H. J.; Bulow, R.; Frenzel, S.; Tosun, D.; Bilgel, M.; An, Y.; Yi, D.; Marcus, D. S.; LaMontagne, P.; Benzinger, T. L. S.; Heckbert, S. R.; Austin, T. R.; Waldstein, S. R.; Evans, M. K.; Zonderman, A. B.; Launer, L. J.; Sotiras, A.; Espeland, M. A.; Masters, C. L.; Maruff, P.; Fripp, J.; Toga, A.; O'Bryant, S.; Chakravarty, M. M.; Villeneuve, S.; Johnson, S. C.; Morris, J. C.; Albert, M. S.; Yaffe, K.; Volzke, H.; Ferrucci, L.; Bryan, N. R.; Shin\nScore: 9.5, Published: 2023-12-30 DOI: 10.1101/2023.12.29.23300642\nAbstractBrain aging is a complex process influenced by various lifestyle, environmental, and genetic factors, as well as by age-related and often co-existing pathologies. MRI and, more recently, AI methods have been instrumental in understanding the neuroanatomical changes that occur during aging in large and diverse populations. However, the multiplicity and mutual overlap of both pathologic processes and affected brain regions make it difficult to precisely characterize the underlying neurodegenerative profile of an individual from an MRI scan. Herein, we leverage a state-of-the art deep representation learning method, Surreal-GAN, and present both methodological advances and extensive experimental results that allow us to elucidate the heterogeneity of brain aging in a large and diverse cohort of 49,482 individuals from 11 studies. Five dominant patterns of neurodegeneration were identified and quantified for each individual by their respective (herein referred to as) R-indices. Significant associations between R-indices and distinct biomedical, lifestyle, and genetic factors provide insights into the etiology of observed variances. Furthermore, baseline R-indices showed predictive value for disease progression and mortality. These five R-indices contribute to MRI-based precision diagnostics, prognostication, and may inform stratification into clinical trials.\n",
  "wordCount" : "1152",
  "inLanguage": "en",
  "datePublished": "2024-01-14T10:38:40Z",
  "dateModified": "2024-01-14T10:38:40Z",
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://trxiv.yorks0n.com/posts/radiology-and-imaging/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "TRxiv2",
    "logo": {
      "@type": "ImageObject",
      "url": "https://trxiv.yorks0n.com/favicon.ico"
    }
  }
}
</script>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://trxiv.yorks0n.com" accesskey="h" title="TRxiv2 (Alt + H)">TRxiv2</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
        </ul>
    </nav>
</header>
<main class="main">
<article class="post-single">
  <header class="post-header">
    
    <h1 class="post-title">
      radiology and imaging
    </h1>
    <div class="post-meta">&lt;span&gt;updated on January 14, 2024&lt;/span&gt;

</div>
  </header> 
  <div class="post-content"><div class="accordion accordion-flush" id="accordionFlushExample"><div class="accordion-item">
    <h3 class="accordion-header" id="flush-heading10.1101/2023.12.28.23300409">
      <button class="accordion-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#flush-collapse10.1101/2023.12.28.23300409" aria-expanded="false" aria-controls="flush-collapse10.1101/2023.12.28.23300409">
        <p class="paperTitle">Multi-contrast high-field quality image synthesis for portable low-field MRI using generative adversarial networks and paired data</p>
      </button>
    </h3>
    <div id="flush-collapse10.1101/2023.12.28.23300409" class="accordion-collapse collapse" aria-labelledby="flush-heading10.1101/2023.12.28.23300409" data-bs-parent="#accordionFlushExample">
      <div class="accordion-body">
        <p class="author">Authors: Lucas, A.; Arnold, T. C.; Okar, S. V.; Vadali, C.; Kawatra, K. D.; Ren, Z.; Cao, Q.; Shinohara, R. T.; Schindler, M. K.; Davis, K. A.; Litt, B.; Reich, D. S.; Stein, J. M.</p>
        <p class="info">Score: 16.1, Published: 2023-12-29 </p>
        <p class="info">DOI: <a href='https://doi.org/10.1101/2023.12.28.23300409' target='https://doi.org/10.1101/2023.12.28.23300409'> 10.1101/2023.12.28.23300409</a></p>
        <p class="abstract">IntroductionPortable low-field strength (64mT) MRI scanners promise to increase access to neuroimaging for clinical and research purposes, however these devices produce lower quality images compared to high-field scanners. In this study, we developed and evaluated a deep learning architecture to generate high-field quality brain images from low-field inputs using a paired dataset of multiple sclerosis (MS) patients scanned at 64mT and 3T.

MethodsA total of 49 MS patients were scanned on portable 64mT and standard 3T scanners at Penn (n=25) or the National Institutes of Health (NIH, n=24) with T1-weighted, T2-weighted and FLAIR acquisitions. Using this paired data, we developed a generative adversarial network (GAN) architecture for low- to high-field image translation (LowGAN). We then evaluated synthesized images with respect to image quality, brain morphometry, and white matter lesions.

ResultsSynthetic high-field images demonstrated visually superior quality compared to low-field inputs and significantly higher normalized cross-correlation (NCC) to actual high-field images for T1 (p=0.001) and FLAIR (p&lt;0.001) contrasts. LowGAN generally outperformed the current state- of-the-art for low-field volumetrics. For example, thalamic, lateral ventricle, and total cortical volumes in LowGAN outputs did not differ significantly from 3T measurements. Synthetic outputs preserved MS lesions and captured a known inverse relationship between total lesion volume and thalamic volume.

ConclusionsLowGAN generates synthetic high-field images with comparable visual and quantitative quality to actual high-field scans. Enhancing portable MRI image quality could add value and boost clinician confidence, enabling wider adoption of this technology.</p>
      </div>
    </div>
  </div><div class="accordion-item">
    <h3 class="accordion-header" id="flush-heading10.1101/2024.01.12.24301222">
      <button class="accordion-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#flush-collapse10.1101/2024.01.12.24301222" aria-expanded="false" aria-controls="flush-collapse10.1101/2024.01.12.24301222">
        <p class="paperTitle">Assessing Performance of Multimodal ChatGPT-4 on an image based Radiology Board-style Examination: An exploratory study</p>
      </button>
    </h3>
    <div id="flush-collapse10.1101/2024.01.12.24301222" class="accordion-collapse collapse" aria-labelledby="flush-heading10.1101/2024.01.12.24301222" data-bs-parent="#accordionFlushExample">
      <div class="accordion-body">
        <p class="author">Authors: Bera, K.; Gupta, A.; Jiang, S.; Berlin, S.; Faraji, N.; Tippareddy, C.; Chiong, I.; Jones, R.; Nemer, O.; Nayate, A.; Tirumani, S. H.; Ramaiya, N.</p>
        <p class="info">Score: 1.6, Published: 2024-01-13 </p>
        <p class="info">DOI: <a href='https://doi.org/10.1101/2024.01.12.24301222' target='https://doi.org/10.1101/2024.01.12.24301222'> 10.1101/2024.01.12.24301222</a></p>
        <p class="abstract">Objective To evaluate the performance of multimodal ChatGPT 4 on a radiology board-style examination containing text and radiologic images. Methods In this prospective exploratory study from October 30 to December 10, 2023, 110 multiple-choice questions containing images designed to match the style and content of radiology board examination like the American Board of Radiology Core or Canadian Board of Radiology examination were prompted to multimodal ChatGPT 4. Questions were further sub stratified according to lower-order (recall, understanding) and higher-order (analyze, synthesize), domains (according to radiology subspecialty), imaging modalities and difficulty (rated by both radiologists and radiologists-in-training). ChatGPT performance was assessed overall as well as in subcategories using Fisher exact test with multiple comparisons. Confidence in answering questions was assessed using a Likert scale (1-5) by consensus between a radiologist and radiologist-in-training. Reproducibility was assessed by comparing two different runs using two different accounts. Results ChatGPT 4 answered 55% (61/110) of image-rich questions correctly. While there was no significant difference in performance amongst the various sub-groups on exploratory analysis, performance was better on lower-order [61% (25/41)] when compared to higher-order [52% (36/69)] [P=.46]. Among clinical domains, performance was best on cardiovascular imaging [80% (8/10)], and worst on thoracic imaging [30% [3/10)]. Confidence in answering questions was confident/highly confident [89%(98/110)], even when incorrect There was poor reproducibility between two runs, with the answers being different in 14% (15/110) questions. Conclusion Despite no radiology specific pre-training, multimodal capabilities of ChatGPT appear promising on questions containing images. However, the lack of reproducibility among two runs, even with the same questions poses challenges of reliability.</p>
      </div>
    </div>
  </div><div class="accordion-item">
    <h3 class="accordion-header" id="flush-heading10.1101/2024.01.10.24301049">
      <button class="accordion-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#flush-collapse10.1101/2024.01.10.24301049" aria-expanded="false" aria-controls="flush-collapse10.1101/2024.01.10.24301049">
        <p class="paperTitle">Reduced Oxygen Extraction Fraction in Deep Cerebral Veins Associated with Cognitive Impairment in Multiple Sclerosis</p>
      </button>
    </h3>
    <div id="flush-collapse10.1101/2024.01.10.24301049" class="accordion-collapse collapse" aria-labelledby="flush-heading10.1101/2024.01.10.24301049" data-bs-parent="#accordionFlushExample">
      <div class="accordion-body">
        <p class="author">Authors: Sawan, H.; Li, C.; Buch, S.; Bernitsas, E.; Haacke, E. M.; Ge, Y.; Chen, Y.</p>
        <p class="info">Score: 1.5, Published: 2024-01-12 </p>
        <p class="info">DOI: <a href='https://doi.org/10.1101/2024.01.10.24301049' target='https://doi.org/10.1101/2024.01.10.24301049'> 10.1101/2024.01.10.24301049</a></p>
        <p class="abstract">Studying the relationship between cerebral oxygen utilization and cognitive impairment is essential to understanding neuronal functional changes in the disease progression of multiple sclerosis (MS). This study explores the potential of using venous susceptibility in internal cerebral veins (ICVs) as an imaging biomarker for cognitive impairment in relapsing-remitting MS (RRMS) patients. Quantitative susceptibility mapping derived from fully flow-compensated MRI phase data was employed to directly measure venous blood oxygen saturation levels (SvO2) in the ICVs. Results revealed a significant reduction in the susceptibility of ICVs (212.4 {&#43;/-} 30.8 ppb vs 239.4 {&#43;/-} 25.9 ppb) and a significant increase of SvO2 (74.5 {&#43;/-} 1.89 % vs 72.4 {&#43;/-} 2.23 %) in patients with RRMS compared with age- and sex-matched healthy controls. Both the susceptibility of ICVs (r = 0.646, p = 0.004) and the SvO2 (r = -0.603, p = 0.008) exhibited a strong correlation with cognitive decline in these patients assessed by the Paced Auditory Serial Addition Test, while no significant correlation was observed with clinical disability measured by the Expanded Disability Status Scale. The findings suggest that venous susceptibility in ICVs has the potential to serve as a specific indicator of oxygen metabolism and cognitive function in RRMS.</p>
      </div>
    </div>
  </div><div class="accordion-item">
    <h3 class="accordion-header" id="flush-heading10.1101/2023.12.29.23300642">
      <button class="accordion-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#flush-collapse10.1101/2023.12.29.23300642" aria-expanded="false" aria-controls="flush-collapse10.1101/2023.12.29.23300642">
        <p class="paperTitle">Five dominant dimensions of brain aging are identified via deep learning: associations with clinical, lifestyle, and genetic measures</p>
      </button>
    </h3>
    <div id="flush-collapse10.1101/2023.12.29.23300642" class="accordion-collapse collapse" aria-labelledby="flush-heading10.1101/2023.12.29.23300642" data-bs-parent="#accordionFlushExample">
      <div class="accordion-body">
        <p class="author">Authors: Yang, Z.; Wen, J.; Erus, G.; Govindarajan, S. T.; Melhem, R.; Mamourian, E.; Cui, Y.; Srinivasan, D.; Abdulkadir, A.; Parmpi, P.; Wittfeld, K.; Grabe, H. J.; Bulow, R.; Frenzel, S.; Tosun, D.; Bilgel, M.; An, Y.; Yi, D.; Marcus, D. S.; LaMontagne, P.; Benzinger, T. L. S.; Heckbert, S. R.; Austin, T. R.; Waldstein, S. R.; Evans, M. K.; Zonderman, A. B.; Launer, L. J.; Sotiras, A.; Espeland, M. A.; Masters, C. L.; Maruff, P.; Fripp, J.; Toga, A.; O&#39;Bryant, S.; Chakravarty, M. M.; Villeneuve, S.; Johnson, S. C.; Morris, J. C.; Albert, M. S.; Yaffe, K.; Volzke, H.; Ferrucci, L.; Bryan, N. R.; Shin</p>
        <p class="info">Score: 9.5, Published: 2023-12-30 </p>
        <p class="info">DOI: <a href='https://doi.org/10.1101/2023.12.29.23300642' target='https://doi.org/10.1101/2023.12.29.23300642'> 10.1101/2023.12.29.23300642</a></p>
        <p class="abstract">AbstractBrain aging is a complex process influenced by various lifestyle, environmental, and genetic factors, as well as by age-related and often co-existing pathologies. MRI and, more recently, AI methods have been instrumental in understanding the neuroanatomical changes that occur during aging in large and diverse populations. However, the multiplicity and mutual overlap of both pathologic processes and affected brain regions make it difficult to precisely characterize the underlying neurodegenerative profile of an individual from an MRI scan. Herein, we leverage a state-of-the art deep representation learning method, Surreal-GAN, and present both methodological advances and extensive experimental results that allow us to elucidate the heterogeneity of brain aging in a large and diverse cohort of 49,482 individuals from 11 studies. Five dominant patterns of neurodegeneration were identified and quantified for each individual by their respective (herein referred to as) R-indices. Significant associations between R-indices and distinct biomedical, lifestyle, and genetic factors provide insights into the etiology of observed variances. Furthermore, baseline R-indices showed predictive value for disease progression and mortality. These five R-indices contribute to MRI-based precision diagnostics, prognostication, and may inform stratification into clinical trials.</p>
      </div>
    </div>
  </div>
</div>









<script src="/js/bundle.min.js" defer></script>



  </div>

  <footer class="post-footer">
    <ul class="post-tags">
    </ul>
  </footer>
</article>
    </main>
    
<footer class="footer">
    <span>&copy; 2024 <a href="https://trxiv.yorks0n.com">TRxiv2</a></span>
    <span>
        Â· Made by Yorkson
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
</body>

</html>
