<!DOCTYPE html>
<html lang="en" dir="auto">

<head>
<head>
    <title>bioinformatics</title>
    <meta charset="utf-8">
    <meta name="description"
        content="Website meta description for google search results go here" />
    <meta name="dc.relation" content="https://trxiv.yorks0n.com" />
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta name="theme-color" content="#1A94D2" />

    

    
    
    
    <link rel="stylesheet" href="/css/main.min.css" media="screen">

</head>


<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>bioinformatics | TRxiv2</title>
<meta name="keywords" content="">
<meta name="description" content="DL4MicEverywhere: Deep learning for microscopy made flexible, shareable, and reproducible
Authors: Hidalgo-Cenalmor, I.; Pylvänäinen, J. W.; Ferreira, M. G.; Russell, C. T.; Arganda-Carreras, I.; AI4Life Consortium, ; Jacquemet, G.; Henriques, R.; Gomez-de-Mariscal, E.
Score: 49.9, Published: 2023-11-19 DOI: 10.1101/2023.11.19.567606
Deep learning has revolutionised the analysis of extensive microscopy datasets, yet challenges persist in the widespread adoption of these techniques. Many lack access to training data, computing resources, and expertise to develop complex models.">
<meta name="author" content="">
<link rel="canonical" href="https://trxiv.yorks0n.com/posts/bioinformatics/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.904bd1e751cdd2a584fa6bed3fa1166dfd8ec9949ebfd0c4d69c5add5e17c23d.css" integrity="sha256-kEvR51HN0qWE&#43;mvtP6EWbf2OyZSev9DE1pxa3V4Xwj0=" rel="preload stylesheet" as="style">
<script defer crossorigin="anonymous" src="/assets/js/highlight.f413e19d0714851f6474e7ee9632408e58ac146fbdbe62747134bea2fa3415e0.js" integrity="sha256-9BPhnQcUhR9kdOfuljJAjlisFG&#43;9vmJ0cTS&#43;ovo0FeA="
    onload="hljs.initHighlightingOnLoad();"></script>
<link rel="icon" href="https://trxiv.yorks0n.com/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="https://trxiv.yorks0n.com/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://trxiv.yorks0n.com/favicon-32x32.png">
<link rel="apple-touch-icon" href="https://trxiv.yorks0n.com/apple-touch-icon.png">
<link rel="mask-icon" href="https://trxiv.yorks0n.com/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --hljs-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript><meta property="og:title" content="bioinformatics" />
<meta property="og:description" content="DL4MicEverywhere: Deep learning for microscopy made flexible, shareable, and reproducible
Authors: Hidalgo-Cenalmor, I.; Pylvänäinen, J. W.; Ferreira, M. G.; Russell, C. T.; Arganda-Carreras, I.; AI4Life Consortium, ; Jacquemet, G.; Henriques, R.; Gomez-de-Mariscal, E.
Score: 49.9, Published: 2023-11-19 DOI: 10.1101/2023.11.19.567606
Deep learning has revolutionised the analysis of extensive microscopy datasets, yet challenges persist in the widespread adoption of these techniques. Many lack access to training data, computing resources, and expertise to develop complex models." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://trxiv.yorks0n.com/posts/bioinformatics/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-11-26T10:37:33+00:00" />
<meta property="article:modified_time" content="2023-11-26T10:37:33+00:00" />

<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="bioinformatics"/>
<meta name="twitter:description" content="DL4MicEverywhere: Deep learning for microscopy made flexible, shareable, and reproducible
Authors: Hidalgo-Cenalmor, I.; Pylvänäinen, J. W.; Ferreira, M. G.; Russell, C. T.; Arganda-Carreras, I.; AI4Life Consortium, ; Jacquemet, G.; Henriques, R.; Gomez-de-Mariscal, E.
Score: 49.9, Published: 2023-11-19 DOI: 10.1101/2023.11.19.567606
Deep learning has revolutionised the analysis of extensive microscopy datasets, yet challenges persist in the widespread adoption of these techniques. Many lack access to training data, computing resources, and expertise to develop complex models."/>


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "Posts",
      "item": "https://trxiv.yorks0n.com/posts/"
    }, 
    {
      "@type": "ListItem",
      "position":  3 ,
      "name": "bioinformatics",
      "item": "https://trxiv.yorks0n.com/posts/bioinformatics/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "bioinformatics",
  "name": "bioinformatics",
  "description": "DL4MicEverywhere: Deep learning for microscopy made flexible, shareable, and reproducible\nAuthors: Hidalgo-Cenalmor, I.; Pylvänäinen, J. W.; Ferreira, M. G.; Russell, C. T.; Arganda-Carreras, I.; AI4Life Consortium, ; Jacquemet, G.; Henriques, R.; Gomez-de-Mariscal, E.\nScore: 49.9, Published: 2023-11-19 DOI: 10.1101/2023.11.19.567606\nDeep learning has revolutionised the analysis of extensive microscopy datasets, yet challenges persist in the widespread adoption of these techniques. Many lack access to training data, computing resources, and expertise to develop complex models.",
  "keywords": [
    
  ],
  "articleBody": " DL4MicEverywhere: Deep learning for microscopy made flexible, shareable, and reproducible\nAuthors: Hidalgo-Cenalmor, I.; Pylvänäinen, J. W.; Ferreira, M. G.; Russell, C. T.; Arganda-Carreras, I.; AI4Life Consortium, ; Jacquemet, G.; Henriques, R.; Gomez-de-Mariscal, E.\nScore: 49.9, Published: 2023-11-19 DOI: 10.1101/2023.11.19.567606\nDeep learning has revolutionised the analysis of extensive microscopy datasets, yet challenges persist in the widespread adoption of these techniques. Many lack access to training data, computing resources, and expertise to develop complex models. We introduce DL4MicEverywhere, advancing our previous ZeroCostDL4Mic platform, to make deep learning more accessible. DL4MicEverywhere uniquely allows flexible training and deployment across diverse computational environments by encapsulating methods in interactive Jupyter notebooks within Docker containers -a standalone virtualisation of required packages and code to reproduce a computational environment-. This enhances reproducibility and convenience. The platform includes twice as many techniques as originally provided by ZeroCostDL4Mic and enables community contributions via automated build pipelines. DL4MicEverywhere empowers participatory innovation and aims to democratise deep learning for bioimage analysis.\nMetagenome profiling and containment estimation through abundance-corrected k-mer sketching with sylph\nAuthors: Shaw, J.; Yu, Y. W.\nScore: 31.9, Published: 2023-11-20 DOI: 10.1101/2023.11.20.567879\nProfiling metagenomes against databases allows for the detection and quantification of microbes, even at low abundances where assembly is not possible. We introduce sylph (https://github.com/bluenote-1577/sylph), a metagenome profiler that estimates metagenome-genome average nucleotide identity (ANI) through zero-inflated Poisson k-mer statistics, enabling ANI-based taxa detection. Sylph is the most accurate method on the CAMI2 marine dataset, and compared to Kraken2 for multi-sample profiling, sylph takes 10x less CPU time and uses 30x less memory. Sylphs ANI estimates provide an orthogonal signal to abundance, enabling an ANI-based metagenome-wide association study for Parkinsons disease against 289,323 genomes, confirming known butyrate-PD associations at the strain level. Sylph takes \u003c 1 minute and 16 GB of RAM to profile against 85,205 prokaryotic and 2,917,521 viral genomes, detecting 30x more viral sequences in the human gut compared to RefSeq. Sylph offers precise, efficient profiling with accurate ANI estimation for even low-coverage genomes.\nNeuroVelo: interpretable learning of cellular dynamics from single-cell transcriptomic data\nAuthors: Kouadri Boudjelthia, I.; Milite, S.; El Kazwini, N.; Fernandez-Mateos, J.; Valeri, N.; Huang, Y.; Sottoriva, A.; Sanguinetti, G.\nScore: 34.9, Published: 2023-11-17 DOI: 10.1101/2023.11.17.567500\nReconstructing temporal cellular dynamics from static single-cell transcriptomics remains a major challenge. Methods based on RNA velocity, often in combination with non-linear dimensionality reduction, have been proposed. However, interpreting their results in the light of the underlying biology remains difficult, and their predictive power is limited. Here we propose NeuroVelo, a method that couples learning of an optimal linear projection with a non-linear low-dimensional dynamical system. Using dynamical systems theory, NeuroVelo can then identify genes and biological processes driving temporal cellular dynamics. We benchmark NeuroVelo against several current methods using single-cell multi-omic data, demonstrating that NeuroVelo is superior to competing methods in terms of identifying biological pathways and reconstructing evolutionary dynamics.\nA Foundation Model for Cell Segmentation\nAuthors: Israel, U.; Marks, M.; Dilip, R.; Li, Q.; Schwartz, M. S.; Pradhan, E.; Pao, E.; Li, S.; Pearson-Goulart, A.; Perona, P.; Gkioxari, G.; Barnowski, R.; Yue, Y.; Van Valen, D. A.\nScore: 29.1, Published: 2023-11-20 DOI: 10.1101/2023.11.17.567630\nCells are the fundamental unit of biological organization, and identifying them in imaging data - cell segmentation - is a critical task for various cellular imaging experiments. While deep learning methods have led to substantial progress on this problem, models that have seen wide use are specialist models that work well for specific domains. Methods that have learned the general notion of \"what is a cell\" and can identify them across different domains of cellular imaging data have proven elusive. In this work, we present CellSAM, a foundation model for cell segmentation that generalizes across diverse cellular imaging data. CellSAM builds on top of the Segment Anything Model (SAM) by developing a prompt engineering approach to mask generation. We train an object detector, CellFinder, to automatically detect cells and prompt SAM to generate segmentations. We show that this approach allows a single model to achieve state-of-the-art performance for segmenting images of mammalian cells (in tissues and cell culture), yeast, and bacteria collected with various imaging modalities. To enable accessibility, we integrate CellSAM into DeepCell Label to further accelerate human-in-the-loop labeling strategies for cellular imaging data. A deployed version of CellSAM is available at https://label-dev.deepcell.org/.\nBARtab \u0026 bartools: an integrated Nextflow pipeline and R package for the analysis of synthetic cellular barcodes in the genome and transcriptome\nAuthors: Vassiliadis, D.; Dawson, M. A.; Holze, H.; Fennell, K. A.; Talarmain, L.; Lam, E. Y.\nScore: 27.8, Published: 2023-11-22 DOI: 10.1101/2023.11.21.568179\nCellular barcoding using heritable synthetic barcodes coupled to high throughput sequencing is a powerful technique for the accurate tracing of clonal lineages in a wide variety of biological contexts. Recent studies have integrated cellular barcoding with a single-cell transcriptomics readout, extending the capabilities of these lineage tracing methods to the single-cell level. However there remains a lack of scalable and standardised open-source tools to pre-process and visualise both population-level and single-cell level cellular barcoding datasets. To address these limitations, we developed BARtab, a portable and scalable Nextflow pipeline that automates upstream barcode extraction, quality control, filtering and enumeration from high throughput sequencing data; and bartools, an open-source R package that streamlines the analysis and visualisation of population and single-cell level cellular barcoding datasets. BARtab contains additional methods for the extraction and annotation of transcribed barcodes from single-cell RNA-seq and spatial transcriptomics experiments, thus extending this analytical toolbox to also support novel expressed cellular barcoding methodologies. We showcase the integrated BARtab and bartools workflow through comparison with previously published toolsets and via the analysis of exemplar bulk, single-cell, and spatial transcriptomics cellular barcoding datasets.\nscfetch: an R package to access and format single-cell RNA sequencing datasets from public repositories\nAuthors: Song, Y.; Gao, J.; Wang, J.\nScore: 20.8, Published: 2023-11-20 DOI: 10.1101/2023.11.18.567507\nSummaryDownloading and reanalyzing the existing single-cell RNA sequencing (scRNA-seq) datasets is an efficient method to gain clues or new insights. However, there is no tool to access diverse scRNA-seq datasets (fastq/bam files, count matrices and processed objects) distributed in various repositories, consider features of datasets from different scRNA-seq protocols, and prepare for downstream analysis. Here, we present scfetch, an R package to download diverse scRNA-seq datasets from SRA, GEO, PanglaoDB, UCSC Cell Browser, Zenodo and CELLxGENE, and load the downloaded datasets to Seurat. scfetch supports scRNA-seq datasets generated by different protocols such as 10x Genomics and Smart-seq2. Besides, scfetch enables users to convert formats between different scRNA-seq objects, including SeuratObject, Anndata, SingleCellExperiment, CellDataSet/cell_data_set and loom. Furthermore, scfetch also supports downloading fastq/bam files and count matrices of bulk RNA-seq from SRA and GEO. Availability and ImplementationThe scfetch package and vignettes are freely available at https://github.com/showteeth/scfetch and https://showteeth.github.io/scfetch/. Contactgaojx@im.ac.cn, jianbinwang@tsinghua.edu.cn. Supplementary informationSupplementary data are appended.\nTaxometer: Improving taxonomic classification of metagenomics contigs\nAuthors: Kutuzova, S.; Nielsen, M.; Piera Lindez, P.; Nybo Nissen, J.; Rasmussen, S.\nScore: 18.2, Published: 2023-11-23 DOI: 10.1101/2023.11.23.568413\nFor taxonomy based classification of metagenomics assembled contigs, current methods use sequence similarity to identify their most likely taxonomy. However, in the related field of metagenomics binning contigs are routinely clustered using information from both the contig sequences and their abundance. We introduce Taxometer, a neural network based method that improves the annotations and estimates the quality of any taxonomic classifier by combining contig abundance profiles and tetra-nucleotide frequencies. When applied to five short-read CAMI2 datasets, it increased the average share of correct species-level contig annotations of the MMSeqs2 tool from 66.6% to 86.2% and reduced the share of wrong species-level annotations in the CAMI2 Rhizosphere dataset two-fold on average for Metabuli, Centrifuge, and Kraken2. Finally, we applied Taxometer to two complex long-read metagenomics data sets for benchmarking taxonomic classifiers. Taxometer is available as open-source software and can enhance any taxonomic annotation of metagenomic contigs.\nflowVI: Flow Cytometry Variational Inference\nAuthors: Inecik, K.; Meric, A.; Konig, L. M.; Theis, F. J.\nScore: 21.5, Published: 2023-11-11 DOI: 10.1101/2023.11.10.566661\nSingle-cell flow cytometry stands as a pivotal instrument in both biomedical research and clinical practice, not only offering invaluable insights into cellular phenotypes and functions but also significantly advancing our understanding of various patient states. However, its potential is often constrained by factors such as technical limitations, noise interference, and batch effects, which complicate comparison between flow cytometry experiments and compromise its overall impact. Recent advances in deep representation learning have demonstrated promise in overcoming similar challenges in related fields, particularly in the context of single-cell transcriptomic sequencing data analysis. Here, we propose flowVI, a multimodal deep generative model, tailored for integrative analysis of multiple massively parallel cytometry datasets from diverse sources. By effectively modeling noise variances, technical biases, and batch-specific heterogeneity using probabilistic data representation, we demonstrate that flowVI not only excels in the imputation of missing protein markers but also seamlessly integrates data from distinct cytometry panels. FlowVI thus emerges as a potent tool for constructing comprehensive flow cytometry atlases and enhancing the precision of flow cytometry data analyses. The source code for replicating these findings is hosted on GitHub, theislab/flowVI\nChromosome-level scaffolding of haplotype-resolved assemblies using Hi-C data without reference genomes\nAuthors: Zeng, X.; Yi, Z.; Zhang, X.; Du, Y.; Li, Y.; Zhou, Z.; Chen, S.; Zhao, H.; Yang, S.; Wang, Y.; Chen, G.\nScore: 14.4, Published: 2023-11-18 DOI: 10.1101/2023.11.18.567668\nScaffolding is crucial for constructing most chromosome-level genomes. The high-throughput chromatin conformation capture (Hi-C) technology has become the primary scaffolding strategy due to its convenience and cost-effectiveness. As sequencing technologies and assembly algorithms advance, constructing haplotype-resolved genomes is increasingly preferred because haplotypes can provide additional genetic information on allelic and non-allelic variations. ALLHiC is a widely used allele-aware scaffolding tool designed for this purpose. However, its dependence on chromosome-level reference genomes and a higher chromosome misassignment rate still impede the unraveling of haplotype-resolved genomes. In this paper, we present HapHiC, a reference-independent allele-aware scaffolding tool with superior performance on chromosome assignment as well as contig ordering and orientation. Additionally, we provide new insights into the challenges in allele-aware scaffolding by conducting comprehensive analyses on various adverse factors. Finally, with the help of HapHiC, we constructed the haplotype-resolved allotriploid genome for Miscanthus x giganteus, an important lignocellulosic bioenergy crop. HapHiC is available at https://github.com/zengxiaofei/HapHiC.\nvmrseq: Probabilistic Modeling of Single-cell Methylation Heterogeneity\nAuthors: Shen, N.; Korthauer, K.\nScore: 12.6, Published: 2023-11-21 DOI: 10.1101/2023.11.20.567911\nSingle-cell DNA methylation measurements reveal genome-scale inter-cellular epigenetic heterogeneity, but extreme sparsity and noise challenges rigorous analysis. Previous methods to detect variably methylated regions (VMRs) have relied on predefined regions or sliding windows, and report regions insensitive to heterogeneity level present in input. We present vmrseq, a statistical method that overcomes these challenges to detect VMRs with increased accuracy in synthetic benchmarks and improved feature selection in case studies. vmrseq also highlights context-dependent correlations between methylation and gene expression, supporting previous findings and facilitating novel hypotheses on epigenetic regulation. vmrseq is available at https://github.com/nshen7/vmrseq.\n",
  "wordCount" : "1801",
  "inLanguage": "en",
  "datePublished": "2023-11-26T10:37:33Z",
  "dateModified": "2023-11-26T10:37:33Z",
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://trxiv.yorks0n.com/posts/bioinformatics/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "TRxiv2",
    "logo": {
      "@type": "ImageObject",
      "url": "https://trxiv.yorks0n.com/favicon.ico"
    }
  }
}
</script>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://trxiv.yorks0n.com" accesskey="h" title="TRxiv2 (Alt + H)">TRxiv2</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
        </ul>
    </nav>
</header>
<main class="main">
<article class="post-single">
  <header class="post-header">
    
    <h1 class="post-title">
      bioinformatics
    </h1>
    <div class="post-meta">&lt;span&gt;updated on November 26, 2023&lt;/span&gt;

</div>
  </header> 
  <div class="post-content"><div class="accordion accordion-flush" id="accordionFlushExample"><div class="accordion-item">
    <h3 class="accordion-header" id="flush-heading10.1101/2023.11.19.567606">
      <button class="accordion-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#flush-collapse10.1101/2023.11.19.567606" aria-expanded="false" aria-controls="flush-collapse10.1101/2023.11.19.567606">
        <p class="paperTitle">DL4MicEverywhere: Deep learning for microscopy made flexible, shareable, and reproducible</p>
      </button>
    </h3>
    <div id="flush-collapse10.1101/2023.11.19.567606" class="accordion-collapse collapse" aria-labelledby="flush-heading10.1101/2023.11.19.567606" data-bs-parent="#accordionFlushExample">
      <div class="accordion-body">
        <p class="author">Authors: Hidalgo-Cenalmor, I.; Pylvänäinen, J. W.; Ferreira, M. G.; Russell, C. T.; Arganda-Carreras, I.; AI4Life Consortium,  ; Jacquemet, G.; Henriques, R.; Gomez-de-Mariscal, E.</p>
        <p class="info">Score: 49.9, Published: 2023-11-19 </p>
        <p class="info">DOI: <a href='https://doi.org/10.1101/2023.11.19.567606' target='https://doi.org/10.1101/2023.11.19.567606'> 10.1101/2023.11.19.567606</a></p>
        <p class="abstract">Deep learning has revolutionised the analysis of extensive microscopy datasets, yet challenges persist in the widespread adoption of these techniques. Many lack access to training data, computing resources, and expertise to develop complex models. We introduce DL4MicEverywhere, advancing our previous ZeroCostDL4Mic platform, to make deep learning more accessible. DL4MicEverywhere uniquely allows flexible training and deployment across diverse computational environments by encapsulating methods in interactive Jupyter notebooks within Docker containers -a standalone virtualisation of required packages and code to reproduce a computational environment-. This enhances reproducibility and convenience. The platform includes twice as many techniques as originally provided by ZeroCostDL4Mic and enables community contributions via automated build pipelines. DL4MicEverywhere empowers participatory innovation and aims to democratise deep learning for bioimage analysis.</p>
      </div>
    </div>
  </div><div class="accordion-item">
    <h3 class="accordion-header" id="flush-heading10.1101/2023.11.20.567879">
      <button class="accordion-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#flush-collapse10.1101/2023.11.20.567879" aria-expanded="false" aria-controls="flush-collapse10.1101/2023.11.20.567879">
        <p class="paperTitle">Metagenome profiling and containment estimation through abundance-corrected k-mer sketching with sylph</p>
      </button>
    </h3>
    <div id="flush-collapse10.1101/2023.11.20.567879" class="accordion-collapse collapse" aria-labelledby="flush-heading10.1101/2023.11.20.567879" data-bs-parent="#accordionFlushExample">
      <div class="accordion-body">
        <p class="author">Authors: Shaw, J.; Yu, Y. W.</p>
        <p class="info">Score: 31.9, Published: 2023-11-20 </p>
        <p class="info">DOI: <a href='https://doi.org/10.1101/2023.11.20.567879' target='https://doi.org/10.1101/2023.11.20.567879'> 10.1101/2023.11.20.567879</a></p>
        <p class="abstract">Profiling metagenomes against databases allows for the detection and quantification of microbes, even at low abundances where assembly is not possible. We introduce sylph (https://github.com/bluenote-1577/sylph), a metagenome profiler that estimates metagenome-genome average nucleotide identity (ANI) through zero-inflated Poisson k-mer statistics, enabling ANI-based taxa detection. Sylph is the most accurate method on the CAMI2 marine dataset, and compared to Kraken2 for multi-sample profiling, sylph takes 10x less CPU time and uses 30x less memory. Sylphs ANI estimates provide an orthogonal signal to abundance, enabling an ANI-based metagenome-wide association study for Parkinsons disease against 289,323 genomes, confirming known butyrate-PD associations at the strain level. Sylph takes &lt; 1 minute and 16 GB of RAM to profile against 85,205 prokaryotic and 2,917,521 viral genomes, detecting 30x more viral sequences in the human gut compared to RefSeq. Sylph offers precise, efficient profiling with accurate ANI estimation for even low-coverage genomes.</p>
      </div>
    </div>
  </div><div class="accordion-item">
    <h3 class="accordion-header" id="flush-heading10.1101/2023.11.17.567500">
      <button class="accordion-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#flush-collapse10.1101/2023.11.17.567500" aria-expanded="false" aria-controls="flush-collapse10.1101/2023.11.17.567500">
        <p class="paperTitle">NeuroVelo: interpretable learning of cellular dynamics from single-cell transcriptomic data</p>
      </button>
    </h3>
    <div id="flush-collapse10.1101/2023.11.17.567500" class="accordion-collapse collapse" aria-labelledby="flush-heading10.1101/2023.11.17.567500" data-bs-parent="#accordionFlushExample">
      <div class="accordion-body">
        <p class="author">Authors: Kouadri Boudjelthia, I.; Milite, S.; El Kazwini, N.; Fernandez-Mateos, J.; Valeri, N.; Huang, Y.; Sottoriva, A.; Sanguinetti, G.</p>
        <p class="info">Score: 34.9, Published: 2023-11-17 </p>
        <p class="info">DOI: <a href='https://doi.org/10.1101/2023.11.17.567500' target='https://doi.org/10.1101/2023.11.17.567500'> 10.1101/2023.11.17.567500</a></p>
        <p class="abstract">Reconstructing temporal cellular dynamics from static single-cell transcriptomics remains a major challenge. Methods based on RNA velocity, often in combination with non-linear dimensionality reduction, have been proposed. However, interpreting their results in the light of the underlying biology remains difficult, and their predictive power is limited. Here we propose NeuroVelo, a method that couples learning of an optimal linear projection with a non-linear low-dimensional dynamical system. Using dynamical systems theory, NeuroVelo can then identify genes and biological processes driving temporal cellular dynamics. We benchmark NeuroVelo against several current methods using single-cell multi-omic data, demonstrating that NeuroVelo is superior to competing methods in terms of identifying biological pathways and reconstructing evolutionary dynamics.</p>
      </div>
    </div>
  </div><div class="accordion-item">
    <h3 class="accordion-header" id="flush-heading10.1101/2023.11.17.567630">
      <button class="accordion-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#flush-collapse10.1101/2023.11.17.567630" aria-expanded="false" aria-controls="flush-collapse10.1101/2023.11.17.567630">
        <p class="paperTitle">A Foundation Model for Cell Segmentation</p>
      </button>
    </h3>
    <div id="flush-collapse10.1101/2023.11.17.567630" class="accordion-collapse collapse" aria-labelledby="flush-heading10.1101/2023.11.17.567630" data-bs-parent="#accordionFlushExample">
      <div class="accordion-body">
        <p class="author">Authors: Israel, U.; Marks, M.; Dilip, R.; Li, Q.; Schwartz, M. S.; Pradhan, E.; Pao, E.; Li, S.; Pearson-Goulart, A.; Perona, P.; Gkioxari, G.; Barnowski, R.; Yue, Y.; Van Valen, D. A.</p>
        <p class="info">Score: 29.1, Published: 2023-11-20 </p>
        <p class="info">DOI: <a href='https://doi.org/10.1101/2023.11.17.567630' target='https://doi.org/10.1101/2023.11.17.567630'> 10.1101/2023.11.17.567630</a></p>
        <p class="abstract">Cells are the fundamental unit of biological organization, and identifying them in imaging data - cell segmentation - is a critical task for various cellular imaging experiments. While deep learning methods have led to substantial progress on this problem, models that have seen wide use are specialist models that work well for specific domains. Methods that have learned the general notion of &#34;what is a cell&#34; and can identify them across different domains of cellular imaging data have proven elusive. In this work, we present CellSAM, a foundation model for cell segmentation that generalizes across diverse cellular imaging data. CellSAM builds on top of the Segment Anything Model (SAM) by developing a prompt engineering approach to mask generation. We train an object detector, CellFinder, to automatically detect cells and prompt SAM to generate segmentations. We show that this approach allows a single model to achieve state-of-the-art performance for segmenting images of mammalian cells (in tissues and cell culture), yeast, and bacteria collected with various imaging modalities. To enable accessibility, we integrate CellSAM into DeepCell Label to further accelerate human-in-the-loop labeling strategies for cellular imaging data. A deployed version of CellSAM is available at https://label-dev.deepcell.org/.</p>
      </div>
    </div>
  </div><div class="accordion-item">
    <h3 class="accordion-header" id="flush-heading10.1101/2023.11.21.568179">
      <button class="accordion-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#flush-collapse10.1101/2023.11.21.568179" aria-expanded="false" aria-controls="flush-collapse10.1101/2023.11.21.568179">
        <p class="paperTitle">BARtab &amp; bartools: an integrated Nextflow pipeline and R package for the analysis of synthetic cellular barcodes in the genome and transcriptome</p>
      </button>
    </h3>
    <div id="flush-collapse10.1101/2023.11.21.568179" class="accordion-collapse collapse" aria-labelledby="flush-heading10.1101/2023.11.21.568179" data-bs-parent="#accordionFlushExample">
      <div class="accordion-body">
        <p class="author">Authors: Vassiliadis, D.; Dawson, M. A.; Holze, H.; Fennell, K. A.; Talarmain, L.; Lam, E. Y.</p>
        <p class="info">Score: 27.8, Published: 2023-11-22 </p>
        <p class="info">DOI: <a href='https://doi.org/10.1101/2023.11.21.568179' target='https://doi.org/10.1101/2023.11.21.568179'> 10.1101/2023.11.21.568179</a></p>
        <p class="abstract">Cellular barcoding using heritable synthetic barcodes coupled to high throughput sequencing is a powerful technique for the accurate tracing of clonal lineages in a wide variety of biological contexts. Recent studies have integrated cellular barcoding with a single-cell transcriptomics readout, extending the capabilities of these lineage tracing methods to the single-cell level. However there remains a lack of scalable and standardised open-source tools to pre-process and visualise both population-level and single-cell level cellular barcoding datasets. To address these limitations, we developed BARtab, a portable and scalable Nextflow pipeline that automates upstream barcode extraction, quality control, filtering and enumeration from high throughput sequencing data; and bartools, an open-source R package that streamlines the analysis and visualisation of population and single-cell level cellular barcoding datasets. BARtab contains additional methods for the extraction and annotation of transcribed barcodes from single-cell RNA-seq and spatial transcriptomics experiments, thus extending this analytical toolbox to also support novel expressed cellular barcoding methodologies. We showcase the integrated BARtab and bartools workflow through comparison with previously published toolsets and via the analysis of exemplar bulk, single-cell, and spatial transcriptomics cellular barcoding datasets.</p>
      </div>
    </div>
  </div><div class="accordion-item">
    <h3 class="accordion-header" id="flush-heading10.1101/2023.11.18.567507">
      <button class="accordion-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#flush-collapse10.1101/2023.11.18.567507" aria-expanded="false" aria-controls="flush-collapse10.1101/2023.11.18.567507">
        <p class="paperTitle">scfetch: an R package to access and format single-cell RNA sequencing datasets from public repositories</p>
      </button>
    </h3>
    <div id="flush-collapse10.1101/2023.11.18.567507" class="accordion-collapse collapse" aria-labelledby="flush-heading10.1101/2023.11.18.567507" data-bs-parent="#accordionFlushExample">
      <div class="accordion-body">
        <p class="author">Authors: Song, Y.; Gao, J.; Wang, J.</p>
        <p class="info">Score: 20.8, Published: 2023-11-20 </p>
        <p class="info">DOI: <a href='https://doi.org/10.1101/2023.11.18.567507' target='https://doi.org/10.1101/2023.11.18.567507'> 10.1101/2023.11.18.567507</a></p>
        <p class="abstract">SummaryDownloading and reanalyzing the existing single-cell RNA sequencing (scRNA-seq) datasets is an efficient method to gain clues or new insights. However, there is no tool to access diverse scRNA-seq datasets (fastq/bam files, count matrices and processed objects) distributed in various repositories, consider features of datasets from different scRNA-seq protocols, and prepare for downstream analysis. Here, we present scfetch, an R package to download diverse scRNA-seq datasets from SRA, GEO, PanglaoDB, UCSC Cell Browser, Zenodo and CELLxGENE, and load the downloaded datasets to Seurat. scfetch supports scRNA-seq datasets generated by different protocols such as 10x Genomics and Smart-seq2. Besides, scfetch enables users to convert formats between different scRNA-seq objects, including SeuratObject, Anndata, SingleCellExperiment, CellDataSet/cell_data_set and loom. Furthermore, scfetch also supports downloading fastq/bam files and count matrices of bulk RNA-seq from SRA and GEO.

Availability and ImplementationThe scfetch package and vignettes are freely available at https://github.com/showteeth/scfetch and https://showteeth.github.io/scfetch/.

Contactgaojx@im.ac.cn, jianbinwang@tsinghua.edu.cn.

Supplementary informationSupplementary data are appended.</p>
      </div>
    </div>
  </div><div class="accordion-item">
    <h3 class="accordion-header" id="flush-heading10.1101/2023.11.23.568413">
      <button class="accordion-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#flush-collapse10.1101/2023.11.23.568413" aria-expanded="false" aria-controls="flush-collapse10.1101/2023.11.23.568413">
        <p class="paperTitle">Taxometer: Improving taxonomic classification of metagenomics contigs</p>
      </button>
    </h3>
    <div id="flush-collapse10.1101/2023.11.23.568413" class="accordion-collapse collapse" aria-labelledby="flush-heading10.1101/2023.11.23.568413" data-bs-parent="#accordionFlushExample">
      <div class="accordion-body">
        <p class="author">Authors: Kutuzova, S.; Nielsen, M.; Piera Lindez, P.; Nybo Nissen, J.; Rasmussen, S.</p>
        <p class="info">Score: 18.2, Published: 2023-11-23 </p>
        <p class="info">DOI: <a href='https://doi.org/10.1101/2023.11.23.568413' target='https://doi.org/10.1101/2023.11.23.568413'> 10.1101/2023.11.23.568413</a></p>
        <p class="abstract">For taxonomy based classification of metagenomics assembled contigs, current methods use sequence similarity to identify their most likely taxonomy. However, in the related field of metagenomics binning contigs are routinely clustered using information from both the contig sequences and their abundance. We introduce Taxometer, a neural network based method that improves the annotations and estimates the quality of any taxonomic classifier by combining contig abundance profiles and tetra-nucleotide frequencies. When applied to five short-read CAMI2 datasets, it increased the average share of correct species-level contig annotations of the MMSeqs2 tool from 66.6% to 86.2% and reduced the share of wrong species-level annotations in the CAMI2 Rhizosphere dataset two-fold on average for Metabuli, Centrifuge, and Kraken2. Finally, we applied Taxometer to two complex long-read metagenomics data sets for benchmarking taxonomic classifiers. Taxometer is available as open-source software and can enhance any taxonomic annotation of metagenomic contigs.</p>
      </div>
    </div>
  </div><div class="accordion-item">
    <h3 class="accordion-header" id="flush-heading10.1101/2023.11.10.566661">
      <button class="accordion-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#flush-collapse10.1101/2023.11.10.566661" aria-expanded="false" aria-controls="flush-collapse10.1101/2023.11.10.566661">
        <p class="paperTitle">flowVI: Flow Cytometry Variational Inference</p>
      </button>
    </h3>
    <div id="flush-collapse10.1101/2023.11.10.566661" class="accordion-collapse collapse" aria-labelledby="flush-heading10.1101/2023.11.10.566661" data-bs-parent="#accordionFlushExample">
      <div class="accordion-body">
        <p class="author">Authors: Inecik, K.; Meric, A.; Konig, L. M.; Theis, F. J.</p>
        <p class="info">Score: 21.5, Published: 2023-11-11 </p>
        <p class="info">DOI: <a href='https://doi.org/10.1101/2023.11.10.566661' target='https://doi.org/10.1101/2023.11.10.566661'> 10.1101/2023.11.10.566661</a></p>
        <p class="abstract">Single-cell flow cytometry stands as a pivotal instrument in both biomedical research and clinical practice, not only offering invaluable insights into cellular phenotypes and functions but also significantly advancing our understanding of various patient states. However, its potential is often constrained by factors such as technical limitations, noise interference, and batch effects, which complicate comparison between flow cytometry experiments and compromise its overall impact. Recent advances in deep representation learning have demonstrated promise in overcoming similar challenges in related fields, particularly in the context of single-cell transcriptomic sequencing data analysis. Here, we propose flowVI, a multimodal deep generative model, tailored for integrative analysis of multiple massively parallel cytometry datasets from diverse sources. By effectively modeling noise variances, technical biases, and batch-specific heterogeneity using probabilistic data representation, we demonstrate that flowVI not only excels in the imputation of missing protein markers but also seamlessly integrates data from distinct cytometry panels. FlowVI thus emerges as a potent tool for constructing comprehensive flow cytometry atlases and enhancing the precision of flow cytometry data analyses. The source code for replicating these findings is hosted on GitHub,  theislab/flowVI</p>
      </div>
    </div>
  </div><div class="accordion-item">
    <h3 class="accordion-header" id="flush-heading10.1101/2023.11.18.567668">
      <button class="accordion-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#flush-collapse10.1101/2023.11.18.567668" aria-expanded="false" aria-controls="flush-collapse10.1101/2023.11.18.567668">
        <p class="paperTitle">Chromosome-level scaffolding of haplotype-resolved assemblies using Hi-C data without reference genomes</p>
      </button>
    </h3>
    <div id="flush-collapse10.1101/2023.11.18.567668" class="accordion-collapse collapse" aria-labelledby="flush-heading10.1101/2023.11.18.567668" data-bs-parent="#accordionFlushExample">
      <div class="accordion-body">
        <p class="author">Authors: Zeng, X.; Yi, Z.; Zhang, X.; Du, Y.; Li, Y.; Zhou, Z.; Chen, S.; Zhao, H.; Yang, S.; Wang, Y.; Chen, G.</p>
        <p class="info">Score: 14.4, Published: 2023-11-18 </p>
        <p class="info">DOI: <a href='https://doi.org/10.1101/2023.11.18.567668' target='https://doi.org/10.1101/2023.11.18.567668'> 10.1101/2023.11.18.567668</a></p>
        <p class="abstract">Scaffolding is crucial for constructing most chromosome-level genomes. The high-throughput chromatin conformation capture (Hi-C) technology has become the primary scaffolding strategy due to its convenience and cost-effectiveness. As sequencing technologies and assembly algorithms advance, constructing haplotype-resolved genomes is increasingly preferred because haplotypes can provide additional genetic information on allelic and non-allelic variations. ALLHiC is a widely used allele-aware scaffolding tool designed for this purpose. However, its dependence on chromosome-level reference genomes and a higher chromosome misassignment rate still impede the unraveling of haplotype-resolved genomes. In this paper, we present HapHiC, a reference-independent allele-aware scaffolding tool with superior performance on chromosome assignment as well as contig ordering and orientation. Additionally, we provide new insights into the challenges in allele-aware scaffolding by conducting comprehensive analyses on various adverse factors. Finally, with the help of HapHiC, we constructed the haplotype-resolved allotriploid genome for Miscanthus x giganteus, an important lignocellulosic bioenergy crop. HapHiC is available at https://github.com/zengxiaofei/HapHiC.</p>
      </div>
    </div>
  </div><div class="accordion-item">
    <h3 class="accordion-header" id="flush-heading10.1101/2023.11.20.567911">
      <button class="accordion-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#flush-collapse10.1101/2023.11.20.567911" aria-expanded="false" aria-controls="flush-collapse10.1101/2023.11.20.567911">
        <p class="paperTitle">vmrseq: Probabilistic Modeling of Single-cell Methylation Heterogeneity</p>
      </button>
    </h3>
    <div id="flush-collapse10.1101/2023.11.20.567911" class="accordion-collapse collapse" aria-labelledby="flush-heading10.1101/2023.11.20.567911" data-bs-parent="#accordionFlushExample">
      <div class="accordion-body">
        <p class="author">Authors: Shen, N.; Korthauer, K.</p>
        <p class="info">Score: 12.6, Published: 2023-11-21 </p>
        <p class="info">DOI: <a href='https://doi.org/10.1101/2023.11.20.567911' target='https://doi.org/10.1101/2023.11.20.567911'> 10.1101/2023.11.20.567911</a></p>
        <p class="abstract">Single-cell DNA methylation measurements reveal genome-scale inter-cellular epigenetic heterogeneity, but extreme sparsity and noise challenges rigorous analysis. Previous methods to detect variably methylated regions (VMRs) have relied on predefined regions or sliding windows, and report regions insensitive to heterogeneity level present in input. We present vmrseq, a statistical method that overcomes these challenges to detect VMRs with increased accuracy in synthetic benchmarks and improved feature selection in case studies. vmrseq also highlights context-dependent correlations between methylation and gene expression, supporting previous findings and facilitating novel hypotheses on epigenetic regulation. vmrseq is available at https://github.com/nshen7/vmrseq.</p>
      </div>
    </div>
  </div>
</div>









<script src="/js/bundle.min.js" defer></script>



  </div>

  <footer class="post-footer">
    <ul class="post-tags">
    </ul>
  </footer>
</article>
    </main>
    
<footer class="footer">
    <span>&copy; 2023 <a href="https://trxiv.yorks0n.com">TRxiv2</a></span>
    <span>
        · Made by Yorkson
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
</body>

</html>
