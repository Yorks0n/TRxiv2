<!DOCTYPE html>
<html lang="en" dir="auto">

<head>
<head>
    <title>animal behavior and cognition</title>
    <meta charset="utf-8">
    <meta name="description"
        content="Website meta description for google search results go here" />
    <meta name="dc.relation" content="https://trxiv.yorks0n.com" />
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta name="theme-color" content="#1A94D2" />

    

    
    
    
    <link rel="stylesheet" href="/css/main.min.css" media="screen">

</head>


<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>animal behavior and cognition | TRxiv2</title>
<meta name="keywords" content="">
<meta name="description" content="A history of avoidance does not impact extinction learning in male rats
Authors: Lopez-Moraga, A.; Luyten, L.; Beckers, T.
Score: 11.5, Published: 2023-09-22 DOI: 10.1101/2023.09.22.558816
Pervasive avoidance is one of the central symptoms of all anxiety-related disorders. In treatment, avoidance behaviors are typically discouraged because they are assumed to maintain anxiety. Yet, it is not clear that engaging in avoidance is always detrimental. In this study, we used a platform-mediated avoidance task to investigate the influence of avoidance history on extinction learning in male rats.">
<meta name="author" content="">
<link rel="canonical" href="https://trxiv.yorks0n.com/posts/animal-behavior-and-cognition/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.904bd1e751cdd2a584fa6bed3fa1166dfd8ec9949ebfd0c4d69c5add5e17c23d.css" integrity="sha256-kEvR51HN0qWE&#43;mvtP6EWbf2OyZSev9DE1pxa3V4Xwj0=" rel="preload stylesheet" as="style">
<script defer crossorigin="anonymous" src="/assets/js/highlight.f413e19d0714851f6474e7ee9632408e58ac146fbdbe62747134bea2fa3415e0.js" integrity="sha256-9BPhnQcUhR9kdOfuljJAjlisFG&#43;9vmJ0cTS&#43;ovo0FeA="
    onload="hljs.initHighlightingOnLoad();"></script>
<link rel="icon" href="https://trxiv.yorks0n.com/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="https://trxiv.yorks0n.com/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://trxiv.yorks0n.com/favicon-32x32.png">
<link rel="apple-touch-icon" href="https://trxiv.yorks0n.com/apple-touch-icon.png">
<link rel="mask-icon" href="https://trxiv.yorks0n.com/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --hljs-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript><meta property="og:title" content="animal behavior and cognition" />
<meta property="og:description" content="A history of avoidance does not impact extinction learning in male rats
Authors: Lopez-Moraga, A.; Luyten, L.; Beckers, T.
Score: 11.5, Published: 2023-09-22 DOI: 10.1101/2023.09.22.558816
Pervasive avoidance is one of the central symptoms of all anxiety-related disorders. In treatment, avoidance behaviors are typically discouraged because they are assumed to maintain anxiety. Yet, it is not clear that engaging in avoidance is always detrimental. In this study, we used a platform-mediated avoidance task to investigate the influence of avoidance history on extinction learning in male rats." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://trxiv.yorks0n.com/posts/animal-behavior-and-cognition/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-10-01T10:37:47+00:00" />
<meta property="article:modified_time" content="2023-10-01T10:37:47+00:00" />

<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="animal behavior and cognition"/>
<meta name="twitter:description" content="A history of avoidance does not impact extinction learning in male rats
Authors: Lopez-Moraga, A.; Luyten, L.; Beckers, T.
Score: 11.5, Published: 2023-09-22 DOI: 10.1101/2023.09.22.558816
Pervasive avoidance is one of the central symptoms of all anxiety-related disorders. In treatment, avoidance behaviors are typically discouraged because they are assumed to maintain anxiety. Yet, it is not clear that engaging in avoidance is always detrimental. In this study, we used a platform-mediated avoidance task to investigate the influence of avoidance history on extinction learning in male rats."/>


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "Posts",
      "item": "https://trxiv.yorks0n.com/posts/"
    }, 
    {
      "@type": "ListItem",
      "position":  3 ,
      "name": "animal behavior and cognition",
      "item": "https://trxiv.yorks0n.com/posts/animal-behavior-and-cognition/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "animal behavior and cognition",
  "name": "animal behavior and cognition",
  "description": "A history of avoidance does not impact extinction learning in male rats\nAuthors: Lopez-Moraga, A.; Luyten, L.; Beckers, T.\nScore: 11.5, Published: 2023-09-22 DOI: 10.1101/2023.09.22.558816\nPervasive avoidance is one of the central symptoms of all anxiety-related disorders. In treatment, avoidance behaviors are typically discouraged because they are assumed to maintain anxiety. Yet, it is not clear that engaging in avoidance is always detrimental. In this study, we used a platform-mediated avoidance task to investigate the influence of avoidance history on extinction learning in male rats.",
  "keywords": [
    
  ],
  "articleBody": " A history of avoidance does not impact extinction learning in male rats\nAuthors: Lopez-Moraga, A.; Luyten, L.; Beckers, T.\nScore: 11.5, Published: 2023-09-22 DOI: 10.1101/2023.09.22.558816\nPervasive avoidance is one of the central symptoms of all anxiety-related disorders. In treatment, avoidance behaviors are typically discouraged because they are assumed to maintain anxiety. Yet, it is not clear that engaging in avoidance is always detrimental. In this study, we used a platform-mediated avoidance task to investigate the influence of avoidance history on extinction learning in male rats. Our results show that having the opportunity to avoid during fear acquisition training has no marked effect on the extinction of auditory cued fear in a platform-mediated avoidance procedure that constitutes a realistic approach/avoidance conflict in male rats, regardless of whether avoidance was possible during extinction or not. This suggests that imposing a realistic cost on avoidance behavior prevents the adverse effects that avoidance has been claimed to have on extinction, but even then, avoidance does not appear to have clear positive effects on extinction learning nor on retention either.\nMoveFormer: a Transformer-based model for step-selection animal movement modelling\nAuthors: Cifka, O.; Chamaille-Jammes, S.; Liutkus, A.\nScore: 14.2, Published: 2023-10-01 DOI: 10.1101/2023.03.05.531080\nThe movement of animals is a central component of their behavioural strategies. Statistical tools for movement data analysis, however, have long been limited, and in particular, unable to account for past movement information except in a very simplified way. In this work, we propose MoveFormer, a new step-based model of movement capable of learning directly from full animal trajectories. While inspired by the classical step-selection framework and previous work on the quantification of uncertainty in movement predictions, MoveFormer also builds upon recent developments in deep learning, such as the Transformer architecture, allowing it to incorporate long temporal contexts. The model predicts an animals next movement step given its past movement history, including not only purely positional and temporal information, but also any available environmental covariates such as land cover or temperature. We apply our model to a diverse dataset made up of over 1550 trajectories from over 100 studies, and show how it can be used to gain insights about the importance of the provided context features, including the extent of past movement history. Our software, along with the trained model weights, is released as open source.\nValidation of a Radio frequency identification system for tracking location of laying hens in a quasi-commercial aviary system\nAuthors: Gebhardt-Henrich, S. G.; Kashev, A.; Petelle, M. B.; Toscano, M. J.\nScore: 4.8, Published: 2023-09-19 DOI: 10.1101/2023.02.16.528820\nAO_SCPLOWBSTRACTC_SCPLOWCage-free housing is increasingly chosen in Europe, North America, and Australia as an animal-welfare friendly farm system for laying hens. However, hens are kept in large numbers in those systems which makes checking for health and welfare difficult and individuals cannot be identified. Tracking systems like radio frequency identification allow researchers to monitor these individuals almost continuously. Individual tracking data has revealed substantial individual variation in movement patterns, however, in recent studies, only a subset of animals per flock was tracked. We applied an RFID tracking system to monitor all 1125 laying hens of a flock, which were divided into 5 pens of 225 birds each in a barn with an aviary system. In each pen, 26 antennas were placed on the edges of three tiers and in the litter. For validation purposes, 3 hens in 2 connected pens were fitted with colored backpacks. They were recorded on video and their location throughout the pen was taken from the video and compared with registrations from the RFID system. For 93% of compared transitions, the RFID data matched the observational data regarding the tier or litter whereas the value fell to 39% for specific antennae. When the antennae on the litter were excluded for the validation, the match on tier-level was at least 98% but on antenna-level it remained lower than 50%. The sensitivity of the detection of tiers/litter but not antennae differed among the three hens. We conclude that the RFID tracking system was suitable for studying the movement pattern of individual hens among tiers in an aviary system in a reliable way but tracking birds on the litter needs to be improved.\nBreeding alters females' social positions by changing dominance dynamics\nAuthors: Dehnen, T.; Nyaguthii, B.; Cherono, W.; Boogert, N. J.; Farine, D. R.\nScore: 6.9, Published: 2023-09-22 DOI: 10.1101/2023.09.20.558583\nAgonistic and affiliative interactions with group members dictate individuals access to resources, and investment in competing for resources is often traded off with other needs. For example, reproductive investment can reduce body condition and, thereby, an individuals ability to win future agonistic interactions. However, group members may also alter their behaviour towards reproductive individuals, such as becoming more or less aggressive. Here, we investigated the social consequences of reproduction in female vulturine guineafowl Acryllium vulturinum, a plural breeder in which females disperse and are subordinate to males. We found opposing patterns for breeders within- and between-sex dominance interactions from before to after breeding. Specifically, while breeding females became far less likely to win dominance interactions with non-breeding females after breeding than before breeding, they received considerably fewer male aggressions than non-breeding females after breeding. Using agent-based models, we then show that hierarchies inferred using the Percolation and Conductance method are robust to such variation in interaction rates, while other common methods may be prone to systematically overestimating or underestimating particular individuals hierarchy positions. Our study highlights reproduction as a driver of dominance dynamics, and illustrates how the study of dominance may benefit from considering variation in interaction rates.\nEye-specific detection and a multi-eye integration model of biological motion perception\nAuthors: De Agro, M.; Rössler, D. C.; Shamble, P. S.\nScore: 1.5, Published: 2023-09-24 DOI: 10.1101/2023.09.24.559175\nThe term biological motion refers to the peculiar kinematics of living organisms. Their interconnected joints move at a fixed distance from each other, a pattern that is common among all locomotive, rigid animals. Across the animal kingdom, many species have developed specialized circuitry to visually recognize biologically moving stimuli and discriminate them from other patterns. Recently, this skill has also been observed in the distributed visual system of jumping spiders. These eight-eyed animals use three of their eye pairs to perceive motion. Then, the gaze of the remaining pair is shifted towards the detected object for further inspection. When presented with a biologically moving stimulus and a random one, jumping spiders turn to face the latter, demonstrating discrimination. In the current paper, we systematically tested the ability of jumping spiders to discriminate biological from random displays using every single eye-pair, by blocking the others with paint. The animals were able to discriminate the stimuli only when the anterior-lateral eyes were unblocked, performing at chance level with the other pairs. Crucially, the spiders preferred the biological stimulus, not the random one. To explain this preference reversal we hypothesized a model, describing how the anterior-lateral eyes specialization in detecting biological motion feeds into a multi-eye integration system, generating more complex behavior from the combination of the simple, single-eye responses. We propose that this in-built modularity may be a solution to the limited resources of these invertebrates brains, constituting a novel approach to visual processing.\nNovel Epidermal Oxysterols Function as Alarm Substances in Zebrafish\nAuthors: Li, Y.; Yan, Z.; Lin, A.; Yang, X.; Li, X.; Yin, X.; Li, W.; Li, K.\nScore: 1.2, Published: 2023-09-29 DOI: 10.1101/2023.09.26.559639\nAquatic animals often use chemical cues to signal predation risk. When injured, shoaling fish skins release alarm substances that induce intense fear and a suite of anti-predator behaviors in other shoal members. However, the chemical nature of alarm substances remains largely unknown. Here we show that zebrafish alarm substance comprises 24-methyl-5-cholestane-3,7,12,24,28-pentahydroxy 28-sulfate, a novel oxysterol sulfate, and 5-cyprinol sulfate. These compounds are present in zebrafish skin extract and, at concentrations of less than one nanomolar, each induces anti-predator behaviors and increases cortisol levels. Their mixture, at its natural ratio, replicates the skin extract in eliciting the full suite of anti-predator behavior patterns. Our findings reveal a molecular-level mechanism whereby fish signal predation danger.\nWild sulphur-crested cockatoos match human activity rhythms to access food in the urban environment\nAuthors: Fehlmann, G.; Martin, J. M.; Safi, K.; Aplin, L. M.\nScore: 1.0, Published: 2023-09-27 DOI: 10.1101/2023.09.26.555651\nAO_SCPLOWBSTRACTC_SCPLOWUrban areas are growing rapidly across the globe, and wild species are occupying this new environment. Despite offering potential resources, disparities in the urban matrix can lead to specific challenges, with pathways and resources fragmented in space and time. Urban-dwelling species would therefore benefit from learning when and where to exploit human derived food. Here, we investigate whether birds synchronize the exploitation of the most urbanized areas to match food-provisioning patterns, using the example of the popular hand-feeding of sulphur-crested cockatoos (Cacatua galerita) in Sydney, Australia. We monitored the provisioning behaviour of people via a large-scale citizen science program, and tested for synchrony with the spatial behaviour of eight birds equipped with GPS loggers. Our data show that sulphur-crested cockatoos exploited the urban environment, relying on the green areas of the city; importantly, they also visited buildings within more urbanized areas. Sulphur-crested cockatoos used urban space with specific time patterns particularly matching human recreational feeding routines, suggestive of time-place learning. We show that urban environments provide daily temporal foraging resources for which species adjust behaviorally. Thus, our data support the general claim that retaining green spaces in cities is essential to sustainable urban planning, and key to allow species to exploit the urban environment, particularly in areas of high human density. This study builds on the literature investigating human-animal interactions, expanding our understanding of animals exploitation of human behavior. Further research should include the impact of such interactions on urban wildlifes fitness according to their cognitive and behavioral traits.\nASBAR: an Animal Skeleton-Based Action Recognition framework. Recognizing great ape behaviors in the wild using pose estimation with domain adaptation.\nAuthors: Fuchs, M.; Genty, E.; Zuberbühler, K.; Cotofrei, P.\nScore: 1.0, Published: 2023-09-25 DOI: 10.1101/2023.09.24.559236\nTo date, the investigation and classification of animal behaviors have mostly relied on direct human observations or video recordings with posthoc analysis, which can be labor-intensive, time-consuming, and prone to human bias. Recent advances in machine learning for computer vision tasks, such as pose estimation and action recognition, thus have the potential to significantly improve and deepen our understanding of animal behavior. However, despite the increased availability of open-source toolboxes and large-scale datasets for animal pose estimation, their practical relevance for behavior recognition remains under-explored. In this paper, we propose an innovative framework, ASBAR, for Animal Skeleton-Based Action Recognition, which fully integrates animal pose estimation and behavior recognition. We demonstrate the use of this framework in a particularly challenging task: the classification of great ape natural behaviors in the wild. First, we built a robust pose estimator model leveraging OpenMonkeyChallenge, one of the largest available open-source primate pose datasets, through a benchmark analysis on several CNN models from DeepLabCut, integrated into our framework. Second, we extracted the great apes skeletal motion from the PanAf dataset, a large collection of in-the-wild videos of gorillas and chimpanzees annotated for natural behaviors, which we used to train and evaluate PoseConv3D from MMaction2, a second deep learning model fully integrated into our framework. We hereby classify behaviors into nine distinct categories and achieve a Top 1 accuracy of 74.98%, comparable to previous studies using video-based methods, while reducing the models input size by a factor of around 20. Additionally, we provide an open-source terminal-based GUI that integrates our full pipeline and release a set of 5,440 keypoint annotations to facilitate the replication of our results on other species and/or behaviors. All models, code, and data can be accessed at: https://github.com/MitchFuchs/asbar. Author summaryThe study of animal behaviors has mostly relied on human observations and/or video analysis traditionally. In this paper, we introduce a new framework called ASBAR (for Animal Skeleton-Based Action Recognition) that integrates recent advances in machine learning to classify animal behaviors from videos. Compared to other methods that use the entire video information, our approach relies on the detection of the animals pose (e.g., position of the head, eyes, limbs) from which the behavior can be recognized. We demonstrate its successful application in a challenging task for computers as it classifies nine great ape behaviors in their natural habitat with high accuracy. To facilitate its use for other researchers, we provide a graphical user interface (GUI) and annotated data to replicate our results for other animal species and/or behaviors.\n",
  "wordCount" : "2064",
  "inLanguage": "en",
  "datePublished": "2023-10-01T10:37:47Z",
  "dateModified": "2023-10-01T10:37:47Z",
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://trxiv.yorks0n.com/posts/animal-behavior-and-cognition/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "TRxiv2",
    "logo": {
      "@type": "ImageObject",
      "url": "https://trxiv.yorks0n.com/favicon.ico"
    }
  }
}
</script>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://trxiv.yorks0n.com" accesskey="h" title="TRxiv2 (Alt + H)">TRxiv2</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
        </ul>
    </nav>
</header>
<main class="main">
<article class="post-single">
  <header class="post-header">
    
    <h1 class="post-title">
      animal behavior and cognition
    </h1>
    <div class="post-meta"><span>updated on October 1, 2023</span>

</div>
  </header> 
  <div class="post-content"><div class="accordion accordion-flush" id="accordionFlushExample"><div class="accordion-item">
    <h3 class="accordion-header" id="flush-heading10.1101/2023.09.22.558816">
      <button class="accordion-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#flush-collapse10.1101/2023.09.22.558816" aria-expanded="false" aria-controls="flush-collapse10.1101/2023.09.22.558816">
        <p class="paperTitle">A history of avoidance does not impact extinction learning in male rats</p>
      </button>
    </h3>
    <div id="flush-collapse10.1101/2023.09.22.558816" class="accordion-collapse collapse" aria-labelledby="flush-heading10.1101/2023.09.22.558816" data-bs-parent="#accordionFlushExample">
      <div class="accordion-body">
        <p class="author">Authors: Lopez-Moraga, A.; Luyten, L.; Beckers, T.</p>
        <p class="info">Score: 11.5, Published: 2023-09-22 </p>
        <p class="info">DOI: <a href='https://doi.org/10.1101/2023.09.22.558816' target='https://doi.org/10.1101/2023.09.22.558816'> 10.1101/2023.09.22.558816</a></p>
        <p class="abstract">Pervasive avoidance is one of the central symptoms of all anxiety-related disorders. In treatment, avoidance behaviors are typically discouraged because they are assumed to maintain anxiety. Yet, it is not clear that engaging in avoidance is always detrimental. In this study, we used a platform-mediated avoidance task to investigate the influence of avoidance history on extinction learning in male rats. Our results show that having the opportunity to avoid during fear acquisition training has no marked effect on the extinction of auditory cued fear in a platform-mediated avoidance procedure that constitutes a realistic approach/avoidance conflict in male rats, regardless of whether avoidance was possible during extinction or not. This suggests that imposing a realistic cost on avoidance behavior prevents the adverse effects that avoidance has been claimed to have on extinction, but even then, avoidance does not appear to have clear positive effects on extinction learning nor on retention either.</p>
      </div>
    </div>
  </div><div class="accordion-item">
    <h3 class="accordion-header" id="flush-heading10.1101/2023.03.05.531080">
      <button class="accordion-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#flush-collapse10.1101/2023.03.05.531080" aria-expanded="false" aria-controls="flush-collapse10.1101/2023.03.05.531080">
        <p class="paperTitle">MoveFormer: a Transformer-based model for step-selection animal movement modelling</p>
      </button>
    </h3>
    <div id="flush-collapse10.1101/2023.03.05.531080" class="accordion-collapse collapse" aria-labelledby="flush-heading10.1101/2023.03.05.531080" data-bs-parent="#accordionFlushExample">
      <div class="accordion-body">
        <p class="author">Authors: Cifka, O.; Chamaille-Jammes, S.; Liutkus, A.</p>
        <p class="info">Score: 14.2, Published: 2023-10-01 </p>
        <p class="info">DOI: <a href='https://doi.org/10.1101/2023.03.05.531080' target='https://doi.org/10.1101/2023.03.05.531080'> 10.1101/2023.03.05.531080</a></p>
        <p class="abstract">The movement of animals is a central component of their behavioural strategies. Statistical tools for movement data analysis, however, have long been limited, and in particular, unable to account for past movement information except in a very simplified way. In this work, we propose MoveFormer, a new step-based model of movement capable of learning directly from full animal trajectories. While inspired by the classical step-selection framework and previous work on the quantification of uncertainty in movement predictions, MoveFormer also builds upon recent developments in deep learning, such as the Transformer architecture, allowing it to incorporate long temporal contexts. The model predicts an animals next movement step given its past movement history, including not only purely positional and temporal information, but also any available environmental covariates such as land cover or temperature. We apply our model to a diverse dataset made up of over 1550 trajectories from over 100 studies, and show how it can be used to gain insights about the importance of the provided context features, including the extent of past movement history. Our software, along with the trained model weights, is released as open source.</p>
      </div>
    </div>
  </div><div class="accordion-item">
    <h3 class="accordion-header" id="flush-heading10.1101/2023.02.16.528820">
      <button class="accordion-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#flush-collapse10.1101/2023.02.16.528820" aria-expanded="false" aria-controls="flush-collapse10.1101/2023.02.16.528820">
        <p class="paperTitle">Validation of a Radio frequency identification system for tracking location of laying hens in a quasi-commercial aviary system</p>
      </button>
    </h3>
    <div id="flush-collapse10.1101/2023.02.16.528820" class="accordion-collapse collapse" aria-labelledby="flush-heading10.1101/2023.02.16.528820" data-bs-parent="#accordionFlushExample">
      <div class="accordion-body">
        <p class="author">Authors: Gebhardt-Henrich, S. G.; Kashev, A.; Petelle, M. B.; Toscano, M. J.</p>
        <p class="info">Score: 4.8, Published: 2023-09-19 </p>
        <p class="info">DOI: <a href='https://doi.org/10.1101/2023.02.16.528820' target='https://doi.org/10.1101/2023.02.16.528820'> 10.1101/2023.02.16.528820</a></p>
        <p class="abstract">AO_SCPLOWBSTRACTC_SCPLOWCage-free housing is increasingly chosen in Europe, North America, and Australia as an animal-welfare friendly farm system for laying hens. However, hens are kept in large numbers in those systems which makes checking for health and welfare difficult and individuals cannot be identified. Tracking systems like radio frequency identification allow researchers to monitor these individuals almost continuously. Individual tracking data has revealed substantial individual variation in movement patterns, however, in recent studies, only a subset of animals per flock was tracked. We applied an RFID tracking system to monitor all 1125 laying hens of a flock, which were divided into 5 pens of 225 birds each in a barn with an aviary system. In each pen, 26 antennas were placed on the edges of three tiers and in the litter. For validation purposes, 3 hens in 2 connected pens were fitted with colored backpacks. They were recorded on video and their location throughout the pen was taken from the video and compared with registrations from the RFID system. For 93% of compared transitions, the RFID data matched the observational data regarding the tier or litter whereas the value fell to 39% for specific antennae. When the antennae on the litter were excluded for the validation, the match on tier-level was at least 98% but on antenna-level it remained lower than 50%. The sensitivity of the detection of tiers/litter but not antennae differed among the three hens. We conclude that the RFID tracking system was suitable for studying the movement pattern of individual hens among tiers in an aviary system in a reliable way but tracking birds on the litter needs to be improved.</p>
      </div>
    </div>
  </div><div class="accordion-item">
    <h3 class="accordion-header" id="flush-heading10.1101/2023.09.20.558583">
      <button class="accordion-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#flush-collapse10.1101/2023.09.20.558583" aria-expanded="false" aria-controls="flush-collapse10.1101/2023.09.20.558583">
        <p class="paperTitle">Breeding alters females&#39; social positions by changing dominance dynamics</p>
      </button>
    </h3>
    <div id="flush-collapse10.1101/2023.09.20.558583" class="accordion-collapse collapse" aria-labelledby="flush-heading10.1101/2023.09.20.558583" data-bs-parent="#accordionFlushExample">
      <div class="accordion-body">
        <p class="author">Authors: Dehnen, T.; Nyaguthii, B.; Cherono, W.; Boogert, N. J.; Farine, D. R.</p>
        <p class="info">Score: 6.9, Published: 2023-09-22 </p>
        <p class="info">DOI: <a href='https://doi.org/10.1101/2023.09.20.558583' target='https://doi.org/10.1101/2023.09.20.558583'> 10.1101/2023.09.20.558583</a></p>
        <p class="abstract">Agonistic and affiliative interactions with group members dictate individuals access to resources, and investment in competing for resources is often traded off with other needs. For example, reproductive investment can reduce body condition and, thereby, an individuals ability to win future agonistic interactions. However, group members may also alter their behaviour towards reproductive individuals, such as becoming more or less aggressive. Here, we investigated the social consequences of reproduction in female vulturine guineafowl Acryllium vulturinum, a plural breeder in which females disperse and are subordinate to males. We found opposing patterns for breeders within- and between-sex dominance interactions from before to after breeding. Specifically, while breeding females became far less likely to win dominance interactions with non-breeding females after breeding than before breeding, they received considerably fewer male aggressions than non-breeding females after breeding. Using agent-based models, we then show that hierarchies inferred using the Percolation and Conductance method are robust to such variation in interaction rates, while other common methods may be prone to systematically overestimating or underestimating particular individuals hierarchy positions. Our study highlights reproduction as a driver of dominance dynamics, and illustrates how the study of dominance may benefit from considering variation in interaction rates.</p>
      </div>
    </div>
  </div><div class="accordion-item">
    <h3 class="accordion-header" id="flush-heading10.1101/2023.09.24.559175">
      <button class="accordion-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#flush-collapse10.1101/2023.09.24.559175" aria-expanded="false" aria-controls="flush-collapse10.1101/2023.09.24.559175">
        <p class="paperTitle">Eye-specific detection and a multi-eye integration model of biological motion perception</p>
      </button>
    </h3>
    <div id="flush-collapse10.1101/2023.09.24.559175" class="accordion-collapse collapse" aria-labelledby="flush-heading10.1101/2023.09.24.559175" data-bs-parent="#accordionFlushExample">
      <div class="accordion-body">
        <p class="author">Authors: De Agro, M.; Rössler, D. C.; Shamble, P. S.</p>
        <p class="info">Score: 1.5, Published: 2023-09-24 </p>
        <p class="info">DOI: <a href='https://doi.org/10.1101/2023.09.24.559175' target='https://doi.org/10.1101/2023.09.24.559175'> 10.1101/2023.09.24.559175</a></p>
        <p class="abstract">The term biological motion refers to the peculiar kinematics of living organisms. Their interconnected joints move at a fixed distance from each other, a pattern that is common among all locomotive, rigid animals. Across the animal kingdom, many species have developed specialized circuitry to visually recognize biologically moving stimuli and discriminate them from other patterns. Recently, this skill has also been observed in the distributed visual system of jumping spiders. These eight-eyed animals use three of their eye pairs to perceive motion. Then, the gaze of the remaining pair is shifted towards the detected object for further inspection. When presented with a biologically moving stimulus and a random one, jumping spiders turn to face the latter, demonstrating discrimination. In the current paper, we systematically tested the ability of jumping spiders to discriminate biological from random displays using every single eye-pair, by blocking the others with paint. The animals were able to discriminate the stimuli only when the anterior-lateral eyes were unblocked, performing at chance level with the other pairs. Crucially, the spiders preferred the biological stimulus, not the random one. To explain this preference reversal we hypothesized a model, describing how the anterior-lateral eyes specialization in detecting biological motion feeds into a multi-eye integration system, generating more complex behavior from the combination of the simple, single-eye responses. We propose that this in-built modularity may be a solution to the limited resources of these invertebrates brains, constituting a novel approach to visual processing.</p>
      </div>
    </div>
  </div><div class="accordion-item">
    <h3 class="accordion-header" id="flush-heading10.1101/2023.09.26.559639">
      <button class="accordion-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#flush-collapse10.1101/2023.09.26.559639" aria-expanded="false" aria-controls="flush-collapse10.1101/2023.09.26.559639">
        <p class="paperTitle">Novel Epidermal Oxysterols Function as Alarm Substances in Zebrafish</p>
      </button>
    </h3>
    <div id="flush-collapse10.1101/2023.09.26.559639" class="accordion-collapse collapse" aria-labelledby="flush-heading10.1101/2023.09.26.559639" data-bs-parent="#accordionFlushExample">
      <div class="accordion-body">
        <p class="author">Authors: Li, Y.; Yan, Z.; Lin, A.; Yang, X.; Li, X.; Yin, X.; Li, W.; Li, K.</p>
        <p class="info">Score: 1.2, Published: 2023-09-29 </p>
        <p class="info">DOI: <a href='https://doi.org/10.1101/2023.09.26.559639' target='https://doi.org/10.1101/2023.09.26.559639'> 10.1101/2023.09.26.559639</a></p>
        <p class="abstract">Aquatic animals often use chemical cues to signal predation risk. When injured, shoaling fish skins release alarm substances that induce intense fear and a suite of anti-predator behaviors in other shoal members. However, the chemical nature of alarm substances remains largely unknown. Here we show that zebrafish alarm substance comprises 24-methyl-5-cholestane-3,7,12,24,28-pentahydroxy 28-sulfate, a novel oxysterol sulfate, and 5-cyprinol sulfate. These compounds are present in zebrafish skin extract and, at concentrations of less than one nanomolar, each induces anti-predator behaviors and increases cortisol levels. Their mixture, at its natural ratio, replicates the skin extract in eliciting the full suite of anti-predator behavior patterns. Our findings reveal a molecular-level mechanism whereby fish signal predation danger.</p>
      </div>
    </div>
  </div><div class="accordion-item">
    <h3 class="accordion-header" id="flush-heading10.1101/2023.09.26.555651">
      <button class="accordion-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#flush-collapse10.1101/2023.09.26.555651" aria-expanded="false" aria-controls="flush-collapse10.1101/2023.09.26.555651">
        <p class="paperTitle">Wild sulphur-crested cockatoos match human activity rhythms to access food in the urban environment</p>
      </button>
    </h3>
    <div id="flush-collapse10.1101/2023.09.26.555651" class="accordion-collapse collapse" aria-labelledby="flush-heading10.1101/2023.09.26.555651" data-bs-parent="#accordionFlushExample">
      <div class="accordion-body">
        <p class="author">Authors: Fehlmann, G.; Martin, J. M.; Safi, K.; Aplin, L. M.</p>
        <p class="info">Score: 1.0, Published: 2023-09-27 </p>
        <p class="info">DOI: <a href='https://doi.org/10.1101/2023.09.26.555651' target='https://doi.org/10.1101/2023.09.26.555651'> 10.1101/2023.09.26.555651</a></p>
        <p class="abstract">AO_SCPLOWBSTRACTC_SCPLOWUrban areas are growing rapidly across the globe, and wild species are occupying this new environment. Despite offering potential resources, disparities in the urban matrix can lead to specific challenges, with pathways and resources fragmented in space and time. Urban-dwelling species would therefore benefit from learning when and where to exploit human derived food. Here, we investigate whether birds synchronize the exploitation of the most urbanized areas to match food-provisioning patterns, using the example of the popular hand-feeding of sulphur-crested cockatoos (Cacatua galerita) in Sydney, Australia. We monitored the provisioning behaviour of people via a large-scale citizen science program, and tested for synchrony with the spatial behaviour of eight birds equipped with GPS loggers. Our data show that sulphur-crested cockatoos exploited the urban environment, relying on the green areas of the city; importantly, they also visited buildings within more urbanized areas. Sulphur-crested cockatoos used urban space with specific time patterns particularly matching human recreational feeding routines, suggestive of time-place learning. We show that urban environments provide daily temporal foraging resources for which species adjust behaviorally. Thus, our data support the general claim that retaining green spaces in cities is essential to sustainable urban planning, and key to allow species to exploit the urban environment, particularly in areas of high human density. This study builds on the literature investigating human-animal interactions, expanding our understanding of animals exploitation of human behavior. Further research should include the impact of such interactions on urban wildlifes fitness according to their cognitive and behavioral traits.</p>
      </div>
    </div>
  </div><div class="accordion-item">
    <h3 class="accordion-header" id="flush-heading10.1101/2023.09.24.559236">
      <button class="accordion-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#flush-collapse10.1101/2023.09.24.559236" aria-expanded="false" aria-controls="flush-collapse10.1101/2023.09.24.559236">
        <p class="paperTitle">ASBAR: an Animal Skeleton-Based Action Recognition framework. Recognizing great ape behaviors in the wild using pose estimation with domain adaptation.</p>
      </button>
    </h3>
    <div id="flush-collapse10.1101/2023.09.24.559236" class="accordion-collapse collapse" aria-labelledby="flush-heading10.1101/2023.09.24.559236" data-bs-parent="#accordionFlushExample">
      <div class="accordion-body">
        <p class="author">Authors: Fuchs, M.; Genty, E.; Zuberbühler, K.; Cotofrei, P.</p>
        <p class="info">Score: 1.0, Published: 2023-09-25 </p>
        <p class="info">DOI: <a href='https://doi.org/10.1101/2023.09.24.559236' target='https://doi.org/10.1101/2023.09.24.559236'> 10.1101/2023.09.24.559236</a></p>
        <p class="abstract">To date, the investigation and classification of animal behaviors have mostly relied on direct human observations or video recordings with posthoc analysis, which can be labor-intensive, time-consuming, and prone to human bias. Recent advances in machine learning for computer vision tasks, such as pose estimation and action recognition, thus have the potential to significantly improve and deepen our understanding of animal behavior. However, despite the increased availability of open-source toolboxes and large-scale datasets for animal pose estimation, their practical relevance for behavior recognition remains under-explored. In this paper, we propose an innovative framework, ASBAR, for Animal Skeleton-Based Action Recognition, which fully integrates animal pose estimation and behavior recognition. We demonstrate the use of this framework in a particularly challenging task: the classification of great ape natural behaviors in the wild. First, we built a robust pose estimator model leveraging OpenMonkeyChallenge, one of the largest available open-source primate pose datasets, through a benchmark analysis on several CNN models from DeepLabCut, integrated into our framework. Second, we extracted the great apes skeletal motion from the PanAf dataset, a large collection of in-the-wild videos of gorillas and chimpanzees annotated for natural behaviors, which we used to train and evaluate PoseConv3D from MMaction2, a second deep learning model fully integrated into our framework. We hereby classify behaviors into nine distinct categories and achieve a Top 1 accuracy of 74.98%, comparable to previous studies using video-based methods, while reducing the models input size by a factor of around 20. Additionally, we provide an open-source terminal-based GUI that integrates our full pipeline and release a set of 5,440 keypoint annotations to facilitate the replication of our results on other species and/or behaviors. All models, code, and data can be accessed at: https://github.com/MitchFuchs/asbar.

Author summaryThe study of animal behaviors has mostly relied on human observations and/or video analysis traditionally. In this paper, we introduce a new framework called ASBAR (for Animal Skeleton-Based Action Recognition) that integrates recent advances in machine learning to classify animal behaviors from videos. Compared to other methods that use the entire video information, our approach relies on the detection of the animals pose (e.g., position of the head, eyes, limbs) from which the behavior can be recognized. We demonstrate its successful application in a challenging task for computers as it classifies nine great ape behaviors in their natural habitat with high accuracy. To facilitate its use for other researchers, we provide a graphical user interface (GUI) and annotated data to replicate our results for other animal species and/or behaviors.</p>
      </div>
    </div>
  </div>
</div>









<script src="/js/bundle.min.js" defer></script>



  </div>

  <footer class="post-footer">
    <ul class="post-tags">
    </ul>
  </footer>
</article>
    </main>
    
<footer class="footer">
    <span>&copy; 2023 <a href="https://trxiv.yorks0n.com">TRxiv2</a></span>
    <span>
        · Made by Yorkson
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
</body>

</html>
