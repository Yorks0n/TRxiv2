<!DOCTYPE html>
<html lang="en" dir="auto">

<head>
<head>
    <title>health informatics</title>
    <meta charset="utf-8">
    <meta name="description"
        content="Website meta description for google search results go here" />
    <meta name="dc.relation" content="https://trxiv.yorks0n.com" />
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta name="theme-color" content="#1A94D2" />

    

    
    
    
    <link rel="stylesheet" href="/css/main.min.css" media="screen">

</head>


<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>health informatics | TRxiv2</title>
<meta name="keywords" content="">
<meta name="description" content="Beyond the hype: large language models propagate race-based medicine
Authors: Omiye, J. A.; Lester, J.; Spichak, S.; Rotemberg, V.; Daneshjou, R.
Score: 36.6, Published: 2023-07-05 DOI: 10.1101/2023.07.03.23292192
ImportanceLarge language models (LLMs) are being integrated into healthcare systems; but these models recapitulate harmful, race-based medicine. ObjectiveThe objective of this study is to assess whether four commercially available large language models (LLMs) propagate harmful, inaccurate, race-based content when responding to eight different scenarios that historically included race-based medicine or widespread misconceptions around race.">
<meta name="author" content="">
<link rel="canonical" href="https://trxiv.yorks0n.com/posts/health-informatics/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.904bd1e751cdd2a584fa6bed3fa1166dfd8ec9949ebfd0c4d69c5add5e17c23d.css" integrity="sha256-kEvR51HN0qWE&#43;mvtP6EWbf2OyZSev9DE1pxa3V4Xwj0=" rel="preload stylesheet" as="style">
<script defer crossorigin="anonymous" src="/assets/js/highlight.f413e19d0714851f6474e7ee9632408e58ac146fbdbe62747134bea2fa3415e0.js" integrity="sha256-9BPhnQcUhR9kdOfuljJAjlisFG&#43;9vmJ0cTS&#43;ovo0FeA="
    onload="hljs.initHighlightingOnLoad();"></script>
<link rel="icon" href="https://trxiv.yorks0n.com/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="https://trxiv.yorks0n.com/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://trxiv.yorks0n.com/favicon-32x32.png">
<link rel="apple-touch-icon" href="https://trxiv.yorks0n.com/apple-touch-icon.png">
<link rel="mask-icon" href="https://trxiv.yorks0n.com/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --hljs-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript><meta property="og:title" content="health informatics" />
<meta property="og:description" content="Beyond the hype: large language models propagate race-based medicine
Authors: Omiye, J. A.; Lester, J.; Spichak, S.; Rotemberg, V.; Daneshjou, R.
Score: 36.6, Published: 2023-07-05 DOI: 10.1101/2023.07.03.23292192
ImportanceLarge language models (LLMs) are being integrated into healthcare systems; but these models recapitulate harmful, race-based medicine. ObjectiveThe objective of this study is to assess whether four commercially available large language models (LLMs) propagate harmful, inaccurate, race-based content when responding to eight different scenarios that historically included race-based medicine or widespread misconceptions around race." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://trxiv.yorks0n.com/posts/health-informatics/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-07-12T10:41:10+00:00" />
<meta property="article:modified_time" content="2023-07-12T10:41:10+00:00" />

<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="health informatics"/>
<meta name="twitter:description" content="Beyond the hype: large language models propagate race-based medicine
Authors: Omiye, J. A.; Lester, J.; Spichak, S.; Rotemberg, V.; Daneshjou, R.
Score: 36.6, Published: 2023-07-05 DOI: 10.1101/2023.07.03.23292192
ImportanceLarge language models (LLMs) are being integrated into healthcare systems; but these models recapitulate harmful, race-based medicine. ObjectiveThe objective of this study is to assess whether four commercially available large language models (LLMs) propagate harmful, inaccurate, race-based content when responding to eight different scenarios that historically included race-based medicine or widespread misconceptions around race."/>


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "Posts",
      "item": "https://trxiv.yorks0n.com/posts/"
    }, 
    {
      "@type": "ListItem",
      "position":  3 ,
      "name": "health informatics",
      "item": "https://trxiv.yorks0n.com/posts/health-informatics/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "health informatics",
  "name": "health informatics",
  "description": "Beyond the hype: large language models propagate race-based medicine\nAuthors: Omiye, J. A.; Lester, J.; Spichak, S.; Rotemberg, V.; Daneshjou, R.\nScore: 36.6, Published: 2023-07-05 DOI: 10.1101/2023.07.03.23292192\nImportanceLarge language models (LLMs) are being integrated into healthcare systems; but these models recapitulate harmful, race-based medicine. ObjectiveThe objective of this study is to assess whether four commercially available large language models (LLMs) propagate harmful, inaccurate, race-based content when responding to eight different scenarios that historically included race-based medicine or widespread misconceptions around race.",
  "keywords": [
    
  ],
  "articleBody": " Beyond the hype: large language models propagate race-based medicine\nAuthors: Omiye, J. A.; Lester, J.; Spichak, S.; Rotemberg, V.; Daneshjou, R.\nScore: 36.6, Published: 2023-07-05 DOI: 10.1101/2023.07.03.23292192\nImportanceLarge language models (LLMs) are being integrated into healthcare systems; but these models recapitulate harmful, race-based medicine. ObjectiveThe objective of this study is to assess whether four commercially available large language models (LLMs) propagate harmful, inaccurate, race-based content when responding to eight different scenarios that historically included race-based medicine or widespread misconceptions around race. Evidence ReviewQuestions were derived from discussion among 4 physician experts and prior work on race-based medical misconceptions of medical trainees. FindingsWe assessed four large language models with eight different questions that were interrogated five times each with a total of forty responses per a model. All models had examples of perpetuating race-based medicine in their responses. Models were not always consistent in their responses when asked the same question repeatedly. Conclusions and RelevanceLLMs are being proposed for use in the healthcare setting, with some models already connecting to electronic health record systems. However, this study shows that based on our findings, these LLMs could potentially cause harm by perpetuating debunked, racist concepts.\nLeveraging Generative AI to Prioritize Drug Repurposing Candidates: Validating Identified Candidates for Alzheimer's Disease in Real-World Clinical Datasets\nAuthors: Wei, W.-Q.; Yan, C.; Grabowska, M. E.; Dickson, A. L.; Li, B.; Wen, Z.; Roden, D. M.; Stein, C. M.; Embi, P. J.; Peterson, J. F.; Feng, Q.; Malin, B. A.\nScore: 4.2, Published: 2023-07-08 DOI: 10.1101/2023.07.07.23292388\nDrug repurposing represents an attractive alternative to the costly and time-consuming process of new drug development, particularly for serious, widespread conditions with limited effective treatments, such as Alzheimers disease (AD). Emerging generative artificial intelligence (GAI) technologies like ChatGPT offer the promise of expediting the review and summary of scientific knowledge. To examine the feasibility of using GAI for identifying drug repurposing candidates, we iteratively tasked ChatGPT with proposing the twenty most promising drugs for repurposing in AD, and tested the top ten for risk of incident AD in exposed and unexposed individuals over age 65 in two large clinical datasets: 1) Vanderbilt University Medical Center and 2) the All of Us Research Program. Among the candidates suggested by ChatGPT, metformin, simvastatin, and losartan were associated with lower AD risk in meta-analysis. These findings suggest GAI technologies can assimilate scientific insights from an extensive Internet-based search space, helping to prioritize drug repurposing candidates and facilitate the treatment of diseases.\nAssessing GPT-3.5 and GPT-4 in Generating International Classification of Diseases Billing Codes\nAuthors: Soroush, A.; Glicksberg, B. S.; Zimlichman, E.; Barash, Y.; Freeman, R. M.; Charney, A.; Nadkarni, G.; Klang, E.\nScore: 2.2, Published: 2023-07-11 DOI: 10.1101/2023.07.07.23292391\nBackground: Large Language Models (LLMs) like GPT-3.5 and GPT-4 are increasingly entering the healthcare domain as a proposed means to assist with administrative tasks. To ensure safe and effective use with billing coding tasks, it is crucial to assess these models' ability to generate the correct International Classification of Diseases (ICD) codes from text descriptions. Objectives: We aimed to evaluate GPT-3.5 and GPT-4's capability to generate correct ICD billing codes, using the ICD-9-CM (2014) and ICD-10-CM and PCS (2023) systems. Methods: We randomly selected 100 unique codes from each of the most recent versions of the ICD-9-CM, ICD-10-CM, and ICD-10-PCS billing code sets published by the Centers for Medicare and Medicaid Services. Using the ChatGPT interface (GPT-3.5 and GPT-4), we prompted for the ICD codes that corresponding to each provided code description. Outputs were compared with the actual billing codes across several performance measures. Errors were qualitatively and quantitatively assessed for any underlying patterns. Results: GPT-4 and GPT-3.5 demonstrated varied performance across each ICD system. In ICD-9-CM, GPT-4 and GPT-3.5 achieved an exact match rate of 22% and 10%, respectively. 13% (GPT-4) and 10% (GPT-3.5) of generated ICD-10-CM codes were exact matches. Notably, both models struggled considerably with the procedurally focused ICD-10-PCS, with neither GPT-4 or GPT-3.5 producing any exactly matched codes. A substantial number of incorrect codes had semantic similarity with the actual codes for ICD-9-CM (GPT-4: 60.3%, GPT-3.5: 51.1%) and ICD-10-CM (GPT-4: 70.1%, GPT-3.5: 61.1%), in contrast to ICD-10-PCS (GPT-4: 30.0%, GPT-3.5: 16.0%). Conclusion: Our evaluation of GPT-3.5 and GPT-4's proficiency in generating ICD billing codes from ICD-9-CM, ICD-10-CM and ICD-10-PCS code descriptions reveals an inadequate level of performance. While the models appear to exhibit a general conceptual understanding of the codes and their descriptions, they have a propensity for hallucinating key details, suggesting underlying technological limitations of the base LLMs. This suggests a need for more rigorous LLM augmentation strategies and validation prior to their implementation in healthcare contexts, particularly in tasks such as ICD coding which require significant digit-level precision.\nNightshift Imposes Irregular Lifestyle Behaviors in Police Academy Trainees\nAuthors: Erickson, M.; North, R.; Counts, J.; Wang, W.; Porter Starr, K. N.; Wideman, L.; Pieper, C.; Dunn, J.; Kraus, W. E.\nScore: 2.1, Published: 2023-07-08 DOI: 10.1101/2023.07.07.23292363\nStudy ObjectiveShiftwork increases risk for numerous chronic diseases, which is hypothesized to be linked to disruption of circadian timing of lifestyle behaviors. However, empirical data on timing of lifestyle behaviors in real-world shift workers are lacking. To address this, we characterized the regularity of timing of lifestyle behaviors in shift-working police trainees. MethodsUsing a two-group observational study design (N=18), we compared lifestyle behavior timing during 6 weeks of in-class training during dayshift, followed by 6 weeks of field-based training during either dayshift or nightshift. Lifestyle behavior timing, including sleep/wake patterns, physical activity, and meals, was captured using wearable activity trackers and mobile devices. The regularity of lifestyle behavior timing was quantified as an index score, which reflects day-to-day stability on a 24h time scale: Sleep Regularity Index (SRI), Physical Activity Regularity Index (PARI) and Mealtime Regularity Index (MRI). Logistic regression was applied to these indices to develop a composite score, termed the Behavior Regularity Index (BRI). ResultsTransitioning from dayshift to nightshift significantly worsened the BRI, relative to maintaining a dayshift schedule. Specifically, nightshift led to more irregular sleep/wake timing and meal timing; physical activity timing was not impacted. In contrast, maintaining a dayshift schedule did not impact regularity indices. ConclusionNightshift imposed irregular timing of lifestyle behaviors, which is consistent with the hypothesis that circadian disruption contributes to chronic disease risk in shift workers. How to mitigate the negative impact of shiftwork on human health as mediated by irregular timing of sleep/wake patterns and meals deserves exploration.\nMachine learning in medicine using JavaScript: building web apps using TensorFlow.js for interpreting biomedical datasets\nAuthors: Pires, J. G.\nScore: 3.2, Published: 2023-07-09 DOI: 10.1101/2023.06.21.23291717\nIntroductionContributions to medicine may come from different areas; and most areas are full of researchers wanting to support. Physists may help with theory, such as for nuclear medicine. Engineers with machineries, such as dialysis machine. Mathematicians with models, such as pharmacokinetics. And computer scientists with codes such as bioinformatics. MethodWe have used TensorFlow.js for modeling using neural networks biomedical datasets from Kaggle. We have modeled three datasets: diabetes detection, surgery complications, and heart failure. We have used Angular coded in TypeScript for the implementation of the models. Using TensorFlow.js, we have built Multilayer Perceptrons (MPLs) for modelling our datasets. We have employed the training and the validation curves to make sure the model learnt, and we have used accuracy as a measure of goodness of each model. Results and discussionWe have built a couple of examples using TensorFlow.js as machine learning platform. Even though python and R are dominant at the moment, JavaScript and derivatives are growing fast, offering basically the same performance, and some extra features associated with JavaScript. Kaggle, the public platform from where we downloaded our datasets, offers a huge amount of datasets for biomedical cases, thus, the reader can easily test what we have discussed, using the same codes, with minor chances, on any case they may be interested in. We were able to find 92% of accuracy for diabetes detection, 100% for surgery complications, and 70% for heart failure. The possibilities are unlimited, and we believe that it is a nice option for researchers aiming at web applications, especially, focused on medicine. ResumoO_ST_ABSPalavras-ChaveC_ST_ABSCC BY-NC-ND 4.0 - This work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International License.\n",
  "wordCount" : "1359",
  "inLanguage": "en",
  "datePublished": "2023-07-12T10:41:10Z",
  "dateModified": "2023-07-12T10:41:10Z",
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://trxiv.yorks0n.com/posts/health-informatics/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "TRxiv2",
    "logo": {
      "@type": "ImageObject",
      "url": "https://trxiv.yorks0n.com/favicon.ico"
    }
  }
}
</script>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://trxiv.yorks0n.com" accesskey="h" title="TRxiv2 (Alt + H)">TRxiv2</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
        </ul>
    </nav>
</header>
<main class="main">
<article class="post-single">
  <header class="post-header">
    
    <h1 class="post-title">
      health informatics
    </h1>
    <div class="post-meta"><span>updated on July 12, 2023</span>

</div>
  </header> 
  <div class="post-content"><div class="accordion accordion-flush" id="accordionFlushExample"><div class="accordion-item">
    <h3 class="accordion-header" id="flush-heading10.1101/2023.07.03.23292192">
      <button class="accordion-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#flush-collapse10.1101/2023.07.03.23292192" aria-expanded="false" aria-controls="flush-collapse10.1101/2023.07.03.23292192">
        <p class="paperTitle">Beyond the hype: large language models propagate race-based medicine</p>
      </button>
    </h3>
    <div id="flush-collapse10.1101/2023.07.03.23292192" class="accordion-collapse collapse" aria-labelledby="flush-heading10.1101/2023.07.03.23292192" data-bs-parent="#accordionFlushExample">
      <div class="accordion-body">
        <p class="author">Authors: Omiye, J. A.; Lester, J.; Spichak, S.; Rotemberg, V.; Daneshjou, R.</p>
        <p class="info">Score: 36.6, Published: 2023-07-05 </p>
        <p class="info">DOI: <a href='https://doi.org/10.1101/2023.07.03.23292192' target='https://doi.org/10.1101/2023.07.03.23292192'> 10.1101/2023.07.03.23292192</a></p>
        <p class="abstract">ImportanceLarge language models (LLMs) are being integrated into healthcare systems; but these models recapitulate harmful, race-based medicine.

ObjectiveThe objective of this study is to assess whether four commercially available large language models (LLMs) propagate harmful, inaccurate, race-based content when responding to eight different scenarios that historically included race-based medicine or widespread misconceptions around race.

Evidence ReviewQuestions were derived from discussion among 4 physician experts and prior work on race-based medical misconceptions of medical trainees.

FindingsWe assessed four large language models with eight different questions that were interrogated five times each with a total of forty responses per a model. All models had examples of perpetuating race-based medicine in their responses. Models were not always consistent in their responses when asked the same question repeatedly.

Conclusions and RelevanceLLMs are being proposed for use in the healthcare setting, with some models already connecting to electronic health record systems. However, this study shows that based on our findings, these LLMs could potentially cause harm by perpetuating debunked, racist concepts.</p>
      </div>
    </div>
  </div><div class="accordion-item">
    <h3 class="accordion-header" id="flush-heading10.1101/2023.07.07.23292388">
      <button class="accordion-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#flush-collapse10.1101/2023.07.07.23292388" aria-expanded="false" aria-controls="flush-collapse10.1101/2023.07.07.23292388">
        <p class="paperTitle">Leveraging Generative AI to Prioritize Drug Repurposing Candidates: Validating Identified Candidates for Alzheimer&#39;s Disease in Real-World Clinical Datasets</p>
      </button>
    </h3>
    <div id="flush-collapse10.1101/2023.07.07.23292388" class="accordion-collapse collapse" aria-labelledby="flush-heading10.1101/2023.07.07.23292388" data-bs-parent="#accordionFlushExample">
      <div class="accordion-body">
        <p class="author">Authors: Wei, W.-Q.; Yan, C.; Grabowska, M. E.; Dickson, A. L.; Li, B.; Wen, Z.; Roden, D. M.; Stein, C. M.; Embi, P. J.; Peterson, J. F.; Feng, Q.; Malin, B. A.</p>
        <p class="info">Score: 4.2, Published: 2023-07-08 </p>
        <p class="info">DOI: <a href='https://doi.org/10.1101/2023.07.07.23292388' target='https://doi.org/10.1101/2023.07.07.23292388'> 10.1101/2023.07.07.23292388</a></p>
        <p class="abstract">Drug repurposing represents an attractive alternative to the costly and time-consuming process of new drug development, particularly for serious, widespread conditions with limited effective treatments, such as Alzheimers disease (AD). Emerging generative artificial intelligence (GAI) technologies like ChatGPT offer the promise of expediting the review and summary of scientific knowledge. To examine the feasibility of using GAI for identifying drug repurposing candidates, we iteratively tasked ChatGPT with proposing the twenty most promising drugs for repurposing in AD, and tested the top ten for risk of incident AD in exposed and unexposed individuals over age 65 in two large clinical datasets: 1) Vanderbilt University Medical Center and 2) the All of Us Research Program. Among the candidates suggested by ChatGPT, metformin, simvastatin, and losartan were associated with lower AD risk in meta-analysis. These findings suggest GAI technologies can assimilate scientific insights from an extensive Internet-based search space, helping to prioritize drug repurposing candidates and facilitate the treatment of diseases.</p>
      </div>
    </div>
  </div><div class="accordion-item">
    <h3 class="accordion-header" id="flush-heading10.1101/2023.07.07.23292391">
      <button class="accordion-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#flush-collapse10.1101/2023.07.07.23292391" aria-expanded="false" aria-controls="flush-collapse10.1101/2023.07.07.23292391">
        <p class="paperTitle">Assessing GPT-3.5 and GPT-4 in Generating International Classification of Diseases Billing Codes</p>
      </button>
    </h3>
    <div id="flush-collapse10.1101/2023.07.07.23292391" class="accordion-collapse collapse" aria-labelledby="flush-heading10.1101/2023.07.07.23292391" data-bs-parent="#accordionFlushExample">
      <div class="accordion-body">
        <p class="author">Authors: Soroush, A.; Glicksberg, B. S.; Zimlichman, E.; Barash, Y.; Freeman, R. M.; Charney, A.; Nadkarni, G.; Klang, E.</p>
        <p class="info">Score: 2.2, Published: 2023-07-11 </p>
        <p class="info">DOI: <a href='https://doi.org/10.1101/2023.07.07.23292391' target='https://doi.org/10.1101/2023.07.07.23292391'> 10.1101/2023.07.07.23292391</a></p>
        <p class="abstract">Background: Large Language Models (LLMs) like GPT-3.5 and GPT-4 are increasingly entering the healthcare domain as a proposed means to assist with administrative tasks. To ensure safe and effective use with billing coding tasks, it is crucial to assess these models&#39; ability to generate the correct International Classification of Diseases (ICD) codes from text descriptions. Objectives: We aimed to evaluate GPT-3.5 and GPT-4&#39;s capability to generate correct ICD billing codes, using the ICD-9-CM (2014) and ICD-10-CM and PCS (2023) systems. Methods: We randomly selected 100 unique codes from each of the most recent versions of the ICD-9-CM, ICD-10-CM, and ICD-10-PCS billing code sets published by the Centers for Medicare and Medicaid Services. Using the ChatGPT interface (GPT-3.5 and GPT-4), we prompted for the ICD codes that corresponding to each provided code description. Outputs were compared with the actual billing codes across several performance measures. Errors were qualitatively and quantitatively assessed for any underlying patterns. Results: GPT-4 and GPT-3.5 demonstrated varied performance across each ICD system. In ICD-9-CM, GPT-4 and GPT-3.5 achieved an exact match rate of 22% and 10%, respectively. 13% (GPT-4) and 10% (GPT-3.5) of generated ICD-10-CM codes were exact matches. Notably, both models struggled considerably with the procedurally focused ICD-10-PCS, with neither GPT-4 or GPT-3.5 producing any exactly matched codes. A substantial number of incorrect codes had semantic similarity with the actual codes for ICD-9-CM (GPT-4: 60.3%, GPT-3.5: 51.1%) and ICD-10-CM (GPT-4: 70.1%, GPT-3.5: 61.1%), in contrast to ICD-10-PCS (GPT-4: 30.0%, GPT-3.5: 16.0%). Conclusion: Our evaluation of GPT-3.5 and GPT-4&#39;s proficiency in generating ICD billing codes from ICD-9-CM, ICD-10-CM and ICD-10-PCS code descriptions reveals an inadequate level of performance. While the models appear to exhibit a general conceptual understanding of the codes and their descriptions, they have a propensity for hallucinating key details, suggesting underlying technological limitations of the base LLMs. This suggests a need for more rigorous LLM augmentation strategies and validation prior to their implementation in healthcare contexts, particularly in tasks such as ICD coding which require significant digit-level precision.</p>
      </div>
    </div>
  </div><div class="accordion-item">
    <h3 class="accordion-header" id="flush-heading10.1101/2023.07.07.23292363">
      <button class="accordion-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#flush-collapse10.1101/2023.07.07.23292363" aria-expanded="false" aria-controls="flush-collapse10.1101/2023.07.07.23292363">
        <p class="paperTitle">Nightshift Imposes Irregular Lifestyle Behaviors in Police Academy Trainees</p>
      </button>
    </h3>
    <div id="flush-collapse10.1101/2023.07.07.23292363" class="accordion-collapse collapse" aria-labelledby="flush-heading10.1101/2023.07.07.23292363" data-bs-parent="#accordionFlushExample">
      <div class="accordion-body">
        <p class="author">Authors: Erickson, M.; North, R.; Counts, J.; Wang, W.; Porter Starr, K. N.; Wideman, L.; Pieper, C.; Dunn, J.; Kraus, W. E.</p>
        <p class="info">Score: 2.1, Published: 2023-07-08 </p>
        <p class="info">DOI: <a href='https://doi.org/10.1101/2023.07.07.23292363' target='https://doi.org/10.1101/2023.07.07.23292363'> 10.1101/2023.07.07.23292363</a></p>
        <p class="abstract">Study ObjectiveShiftwork increases risk for numerous chronic diseases, which is hypothesized to be linked to disruption of circadian timing of lifestyle behaviors. However, empirical data on timing of lifestyle behaviors in real-world shift workers are lacking. To address this, we characterized the regularity of timing of lifestyle behaviors in shift-working police trainees.

MethodsUsing a two-group observational study design (N=18), we compared lifestyle behavior timing during 6 weeks of in-class training during dayshift, followed by 6 weeks of field-based training during either dayshift or nightshift. Lifestyle behavior timing, including sleep/wake patterns, physical activity, and meals, was captured using wearable activity trackers and mobile devices. The regularity of lifestyle behavior timing was quantified as an index score, which reflects day-to-day stability on a 24h time scale: Sleep Regularity Index (SRI), Physical Activity Regularity Index (PARI) and Mealtime Regularity Index (MRI). Logistic regression was applied to these indices to develop a composite score, termed the Behavior Regularity Index (BRI).

ResultsTransitioning from dayshift to nightshift significantly worsened the BRI, relative to maintaining a dayshift schedule. Specifically, nightshift led to more irregular sleep/wake timing and meal timing; physical activity timing was not impacted. In contrast, maintaining a dayshift schedule did not impact regularity indices.

ConclusionNightshift imposed irregular timing of lifestyle behaviors, which is consistent with the hypothesis that circadian disruption contributes to chronic disease risk in shift workers. How to mitigate the negative impact of shiftwork on human health as mediated by irregular timing of sleep/wake patterns and meals deserves exploration.</p>
      </div>
    </div>
  </div><div class="accordion-item">
    <h3 class="accordion-header" id="flush-heading10.1101/2023.06.21.23291717">
      <button class="accordion-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#flush-collapse10.1101/2023.06.21.23291717" aria-expanded="false" aria-controls="flush-collapse10.1101/2023.06.21.23291717">
        <p class="paperTitle">Machine learning in medicine using JavaScript: building web apps using TensorFlow.js for interpreting biomedical datasets</p>
      </button>
    </h3>
    <div id="flush-collapse10.1101/2023.06.21.23291717" class="accordion-collapse collapse" aria-labelledby="flush-heading10.1101/2023.06.21.23291717" data-bs-parent="#accordionFlushExample">
      <div class="accordion-body">
        <p class="author">Authors: Pires, J. G.</p>
        <p class="info">Score: 3.2, Published: 2023-07-09 </p>
        <p class="info">DOI: <a href='https://doi.org/10.1101/2023.06.21.23291717' target='https://doi.org/10.1101/2023.06.21.23291717'> 10.1101/2023.06.21.23291717</a></p>
        <p class="abstract">IntroductionContributions to medicine may come from different areas; and most areas are full of researchers wanting to support. Physists may help with theory, such as for nuclear medicine. Engineers with machineries, such as dialysis machine. Mathematicians with models, such as pharmacokinetics. And computer scientists with codes such as bioinformatics.

MethodWe have used TensorFlow.js for modeling using neural networks biomedical datasets from Kaggle. We have modeled three datasets: diabetes detection, surgery complications, and heart failure. We have used Angular coded in TypeScript for the implementation of the models. Using TensorFlow.js, we have built Multilayer Perceptrons (MPLs) for modelling our datasets. We have employed the training and the validation curves to make sure the model learnt, and we have used accuracy as a measure of goodness of each model.

Results and discussionWe have built a couple of examples using TensorFlow.js as machine learning platform. Even though python and R are dominant at the moment, JavaScript and derivatives are growing fast, offering basically the same performance, and some extra features associated with JavaScript. Kaggle, the public platform from where we downloaded our datasets, offers a huge amount of datasets for biomedical cases, thus, the reader can easily test what we have discussed, using the same codes, with minor chances, on any case they may be interested in. We were able to find 92% of accuracy for diabetes detection, 100% for surgery complications, and 70% for heart failure. The possibilities are unlimited, and we believe that it is a nice option for researchers aiming at web applications, especially, focused on medicine.

ResumoO_ST_ABSPalavras-ChaveC_ST_ABSCC BY-NC-ND 4.0 - This work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International License.</p>
      </div>
    </div>
  </div>
</div>









<script src="/js/bundle.min.js" defer></script>



  </div>

  <footer class="post-footer">
    <ul class="post-tags">
    </ul>
  </footer>
</article>
    </main>
    
<footer class="footer">
    <span>&copy; 2023 <a href="https://trxiv.yorks0n.com">TRxiv2</a></span>
    <span>
        Â· Made by Yorkson
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
</body>

</html>
