<!DOCTYPE html>
<html lang="en" dir="auto">

<head>
<head>
    <title>health informatics</title>
    <meta charset="utf-8">
    <meta name="description"
        content="Website meta description for google search results go here" />
    <meta name="dc.relation" content="https://trxiv.yorks0n.com" />
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta name="theme-color" content="#1A94D2" />

    

    
    
    
    <link rel="stylesheet" href="/css/main.min.css" media="screen">

</head>


<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>health informatics | TRxiv2</title>
<meta name="keywords" content="">
<meta name="description" content="Beyond the hype: large language models propagate race-based medicine
Authors: Omiye, J. A.; Lester, J.; Spichak, S.; Rotemberg, V.; Daneshjou, R.
Score: 63.0, Published: 2023-07-05 DOI: 10.1101/2023.07.03.23292192
ImportanceLarge language models (LLMs) are being integrated into healthcare systems; but these models recapitulate harmful, race-based medicine. ObjectiveThe objective of this study is to assess whether four commercially available large language models (LLMs) propagate harmful, inaccurate, race-based content when responding to eight different scenarios that historically included race-based medicine or widespread misconceptions around race.">
<meta name="author" content="">
<link rel="canonical" href="https://trxiv.yorks0n.com/posts/health-informatics/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.904bd1e751cdd2a584fa6bed3fa1166dfd8ec9949ebfd0c4d69c5add5e17c23d.css" integrity="sha256-kEvR51HN0qWE&#43;mvtP6EWbf2OyZSev9DE1pxa3V4Xwj0=" rel="preload stylesheet" as="style">
<script defer crossorigin="anonymous" src="/assets/js/highlight.f413e19d0714851f6474e7ee9632408e58ac146fbdbe62747134bea2fa3415e0.js" integrity="sha256-9BPhnQcUhR9kdOfuljJAjlisFG&#43;9vmJ0cTS&#43;ovo0FeA="
    onload="hljs.initHighlightingOnLoad();"></script>
<link rel="icon" href="https://trxiv.yorks0n.com/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="https://trxiv.yorks0n.com/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://trxiv.yorks0n.com/favicon-32x32.png">
<link rel="apple-touch-icon" href="https://trxiv.yorks0n.com/apple-touch-icon.png">
<link rel="mask-icon" href="https://trxiv.yorks0n.com/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --hljs-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript><meta property="og:title" content="health informatics" />
<meta property="og:description" content="Beyond the hype: large language models propagate race-based medicine
Authors: Omiye, J. A.; Lester, J.; Spichak, S.; Rotemberg, V.; Daneshjou, R.
Score: 63.0, Published: 2023-07-05 DOI: 10.1101/2023.07.03.23292192
ImportanceLarge language models (LLMs) are being integrated into healthcare systems; but these models recapitulate harmful, race-based medicine. ObjectiveThe objective of this study is to assess whether four commercially available large language models (LLMs) propagate harmful, inaccurate, race-based content when responding to eight different scenarios that historically included race-based medicine or widespread misconceptions around race." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://trxiv.yorks0n.com/posts/health-informatics/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-07-16T10:39:40+00:00" />
<meta property="article:modified_time" content="2023-07-16T10:39:40+00:00" />

<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="health informatics"/>
<meta name="twitter:description" content="Beyond the hype: large language models propagate race-based medicine
Authors: Omiye, J. A.; Lester, J.; Spichak, S.; Rotemberg, V.; Daneshjou, R.
Score: 63.0, Published: 2023-07-05 DOI: 10.1101/2023.07.03.23292192
ImportanceLarge language models (LLMs) are being integrated into healthcare systems; but these models recapitulate harmful, race-based medicine. ObjectiveThe objective of this study is to assess whether four commercially available large language models (LLMs) propagate harmful, inaccurate, race-based content when responding to eight different scenarios that historically included race-based medicine or widespread misconceptions around race."/>


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "Posts",
      "item": "https://trxiv.yorks0n.com/posts/"
    }, 
    {
      "@type": "ListItem",
      "position":  3 ,
      "name": "health informatics",
      "item": "https://trxiv.yorks0n.com/posts/health-informatics/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "health informatics",
  "name": "health informatics",
  "description": "Beyond the hype: large language models propagate race-based medicine\nAuthors: Omiye, J. A.; Lester, J.; Spichak, S.; Rotemberg, V.; Daneshjou, R.\nScore: 63.0, Published: 2023-07-05 DOI: 10.1101/2023.07.03.23292192\nImportanceLarge language models (LLMs) are being integrated into healthcare systems; but these models recapitulate harmful, race-based medicine. ObjectiveThe objective of this study is to assess whether four commercially available large language models (LLMs) propagate harmful, inaccurate, race-based content when responding to eight different scenarios that historically included race-based medicine or widespread misconceptions around race.",
  "keywords": [
    
  ],
  "articleBody": " Beyond the hype: large language models propagate race-based medicine\nAuthors: Omiye, J. A.; Lester, J.; Spichak, S.; Rotemberg, V.; Daneshjou, R.\nScore: 63.0, Published: 2023-07-05 DOI: 10.1101/2023.07.03.23292192\nImportanceLarge language models (LLMs) are being integrated into healthcare systems; but these models recapitulate harmful, race-based medicine. ObjectiveThe objective of this study is to assess whether four commercially available large language models (LLMs) propagate harmful, inaccurate, race-based content when responding to eight different scenarios that historically included race-based medicine or widespread misconceptions around race. Evidence ReviewQuestions were derived from discussion among 4 physician experts and prior work on race-based medical misconceptions of medical trainees. FindingsWe assessed four large language models with eight different questions that were interrogated five times each with a total of forty responses per a model. All models had examples of perpetuating race-based medicine in their responses. Models were not always consistent in their responses when asked the same question repeatedly. Conclusions and RelevanceLLMs are being proposed for use in the healthcare setting, with some models already connecting to electronic health record systems. However, this study shows that based on our findings, these LLMs could potentially cause harm by perpetuating debunked, racist concepts.\nLeveraging Generative AI to Prioritize Drug Repurposing Candidates: Validating Identified Candidates for Alzheimer's Disease in Real-World Clinical Datasets\nAuthors: Wei, W.-Q.; Yan, C.; Grabowska, M. E.; Dickson, A. L.; Li, B.; Wen, Z.; Roden, D. M.; Stein, C. M.; Embi, P. J.; Peterson, J. F.; Feng, Q.; Malin, B. A.\nScore: 4.2, Published: 2023-07-08 DOI: 10.1101/2023.07.07.23292388\nDrug repurposing represents an attractive alternative to the costly and time-consuming process of new drug development, particularly for serious, widespread conditions with limited effective treatments, such as Alzheimers disease (AD). Emerging generative artificial intelligence (GAI) technologies like ChatGPT offer the promise of expediting the review and summary of scientific knowledge. To examine the feasibility of using GAI for identifying drug repurposing candidates, we iteratively tasked ChatGPT with proposing the twenty most promising drugs for repurposing in AD, and tested the top ten for risk of incident AD in exposed and unexposed individuals over age 65 in two large clinical datasets: 1) Vanderbilt University Medical Center and 2) the All of Us Research Program. Among the candidates suggested by ChatGPT, metformin, simvastatin, and losartan were associated with lower AD risk in meta-analysis. These findings suggest GAI technologies can assimilate scientific insights from an extensive Internet-based search space, helping to prioritize drug repurposing candidates and facilitate the treatment of diseases.\nThe Medical Action Ontology: A Tool for Annotating and Analyzing Treatments and Clinical Management of Human Disease\nAuthors: Carmody, L. C.; Gargano, M. A.; Toro, S.; Vasilevsky, N. A.; Adam, M. P.; Blau, H.; Chan, L. E.; Gomez-Andres, D.; Horvath, R.; Ladewig, M. S.; Lewis-Smith, D.; Lochmueller, H.; Matentzoglu, N. A.; Munoz-Torres, M. C.; Schuetz, C.; Kraus, M. L.; Seitz, B.; Similuk, M. N.; Sparks, T.; Strauss, T.; Swietlik, E. M.; Thompson, R.; Zhang, X. A.; Mungall, C. J.; Haendel, M. A.; Robinson, P. N.\nScore: 4.0, Published: 2023-07-13 DOI: 10.1101/2023.07.13.23292612\nNavigating the vast landscape of clinical literature to find optimal treatments and management strategies can be a challenging task, especially for rare diseases. To address this task, we introduce the Medical Action Ontology (MAxO), the first ontology specifically designed to organize medical procedures, therapies, and interventions in a structured way. Currently, MAxO contains 1757 medical action terms added through a combination of manual and semi-automated processes. MAxO was developed with logical structures that make it compatible with several other ontologies within the Open Biological and Biomedical Ontologies (OBO) Foundry. These cover a wide range of biomedical domains, from human anatomy and investigations to the chemical and protein entities involved in biological processes. We have created a database of over 16000 annotations that describe diagnostic modalities for specific phenotypic abnormalities as defined by the Human Phenotype Ontology (HPO). Additionally, 413 annotations are provided for medical actions for 189 rare diseases. We have developed a web application called POET (https://poet.jax.org/) for the community to use to contribute MAxO annotations. MAxO provides a computational representation of treatments and other actions taken for the clinical management of patients. The development of MAxO is closely coupled to the Mondo Disease Ontology (Mondo) and the Human Phenotype Ontology (HPO) and expands the scope of our computational modeling of diseases and phenotypic features to include diagnostics and therapeutic actions. MAxO is available under the open-source CC-BY 4.0 license (https://github.com/monarch-initiative/MAxO).\nAssessing GPT-3.5 and GPT-4 in Generating International Classification of Diseases Billing Codes\nAuthors: Soroush, A.; Glicksberg, B. S.; Zimlichman, E.; Barash, Y.; Freeman, R. M.; Charney, A.; Nadkarni, G.; Klang, E.\nScore: 3.6, Published: 2023-07-11 DOI: 10.1101/2023.07.07.23292391\nBackgroundLarge Language Models (LLMs) like GPT-3.5 and GPT-4 are increasingly entering the healthcare domain as a proposed means to assist with administrative tasks. To ensure safe and effective use with billing coding tasks, it is crucial to assess these models ability to generate the correct International Classification of Diseases (ICD) codes from text descriptions. ObjectivesWe aimed to evaluate GPT-3.5 and GPT-4s capability to generate correct ICD billing codes, using the ICD-9-CM (2014) and ICD-10-CM and PCS (2023) systems. MethodsWe randomly selected 100 unique codes from each of the most recent versions of the ICD-9-CM, ICD-10-CM, and ICD-10-PCS billing code sets published by the Centers for Medicare and Medicaid Services. Using the ChatGPT interface (GPT-3.5 and GPT-4), we prompted for the ICD codes that corresponding to each provided code description. Outputs were compared with the actual billing codes across several performance measures. Errors were qualitatively and quantitatively assessed for any underlying patterns. ResultsGPT-4 and GPT-3.5 demonstrated varied performance across each ICD system. In ICD-9-CM, GPT-4 and GPT-3.5 achieved an exact match rate of 22% and 10%, respectively. 13% (GPT-4) and 10% (GPT-3.5) of generated ICD-10-CM codes were exact matches. Notably, both models struggled considerably with the procedurally focused ICD-10-PCS, with neither GPT-4 or GPT-3.5 producing any exactly matched codes. A substantial number of incorrect codes had semantic similarity with the actual codes for ICD-9-CM (GPT-4: 60.3%, GPT-3.5: 51.1%) and ICD-10-CM (GPT-4: 70.1%, GPT-3.5: 61.1%), in contrast to ICD-10-PCS (GPT-4: 30.0%, GPT-3.5: 16.0%). ConclusionOur evaluation of GPT-3.5 and GPT-4s proficiency in generating ICD billing codes from ICD-9-CM, ICD-10-CM and ICD-10-PCS code descriptions reveals an inadequate level of performance. While the models appear to exhibit a general conceptual understanding of the codes and their descriptions, they have a propensity for hallucinating key details, suggesting underlying technological limitations of the base LLMs. This suggests a need for more rigorous LLM augmentation strategies and validation prior to their implementation in healthcare contexts, particularly in tasks such as ICD coding which require significant digit-level precision.\nAutomatic Detection and Assessment of Freezing of Gait Manifestations\nAuthors: Yang, P.-K.; Filtjens, B.; Ginis, P.; Goris, M.; Nieuwboer, A.; Gilat, M.; Slaets, P.; Vanrumste, B.\nScore: 3.0, Published: 2023-07-12 DOI: 10.1101/2023.07.10.23292437\nFreezing of gait (FOG) is an episodic and highly disabling symptom of Parkinsons disease (PD). Although described as a single phenomenon, FOG is not univocal and can express as different manifestations, such as trembling in place or complete akinesia. We aimed to analyze the utility of deep learning trained on inertial measurement unit data to classify FOG into both manifestations. We developed a temporal convolutional neural network, which we compared to three state-of-the-art FOG detection algorithms that were adapted to the FOG manifestation detection task. Next, we investigated its performance in distinguishing between the two manifestations and other forms of movement cessation (e.g., volitional stopping and sitting) based on gold-standard video annotations. Experiments were conducted on a dataset of twelve PD patients with FOG that completed a FOG-provoking protocol, including the timed-up-and-go and 360-degree turning-in-place tasks during ON and OFF anti-Parkinsonian medication. The results showed that our model enables accurate detection of FOG manifestations with an 11.43% higher F1 score than the second-best model. Assessment of FOG manifestation severity was moderately strong for trembling in place (Intra-class Correlation Coefficient (ICC)=0.64, [0.16,0.88]) and strong for complete akinesia (ICC=0.87, [0.63,0.96]). Remarkably, our results show that complete akinesia can be distinguished from volitional stopping. In conclusion, we established that FOG manifestations could be accurately detected and assessed with deep learning. Future work should establish whether these results hold firm for a more extensive and varied verification cohort.\nOn the limitations of large language models in clinical diagnosis\nAuthors: Reese, J.; Danis, D.; Caufield, J. H.; Casiraghi, E.; Valentini, G.; Mungall, C. J.; Robinson, P. N.\nScore: 2.1, Published: 2023-07-14 DOI: 10.1101/2023.07.13.23292613\nBackground: The potential of large language models (LLM) such as GPT to support complex tasks such as differential diagnosis has been a subject of debate, with some ascribing near sentient abilities to the models and others claiming that LLMs merely perform \"autocomplete on steroids\". A recent study reported that the Generative Pretrained Transformer 4 (GPT-4) model performed well in complex differential diagnostic reasoning. The authors assessed the performance of GPT-4 in identifying the correct diagnosis in a series of case records from the New England Journal of Medicine. The authors constructed prompts based on the clinical presentation section of the case reports, and compared the results of GPT-4 to the actual diagnosis. GPT-4 returned the correct diagnosis as a part of its response in 64% of cases, with the correct diagnosis being at rank 1 in 39% of cases. However, such concise but comprehensive narratives of the clinical course are not typically available in electronic health records (EHRs). Further, if they were available, EHR records contain identifying information whose transmission is prohibited by Health Insurance Portability and Accountability Act (HIPAA) regulations. Methods: To assess the expected performance of GPT on comparable datasets that can be generated by text mining and by design cannot contain identifiable information, we parsed the texts of the case reports and extracted Human Phenotype Ontology (HPO) terms, from which prompts for GPT were constructed that contain largely the same clinical abnormalities but lack the surrounding narrative. Results: While the performance of GPT-4 on the original narrative-based text was good, with the final diagnosis being included in its differential in 29/75 cases (38.7%; rank 1 in 17.3% of cases; mean rank of 3.4), the performance of GPT-4 on the feature-based approach that includes the major clinical abnormalities without additional narrative texas substantially worse, with GPT-4 including the final diagnosis in its differential in 8/75 cases (10.7%; rank 1 in 4.0% of cases; mean rank of 3.9). Interpretation: We consider the feature-based queries to be a more appropriate test of the performance of GPT-4 in diagnostic tasks, since it is unlikely that the narrative approach can be used in actual clinical practice. Future research and algorithmic development is needed to determine the optimal approach to leveraging LLMs for clinical diagnosis.\nEvaluating ChatGPT in Information Extraction: A Case Study of Extracting Cognitive Exam Dates and Scores\nAuthors: Jethani, N.; Jones, S.; Genes, N.; Major, V. J.; Jaffe, I. S.; Cardillo, A. B.; Heilenbach, N.; Ali, N. F.; Bonanni, L. J.; Clayburn, A. J.; Khera, Z.; Sadler, E. C.; Prasad, J.; Schlacter, J.; Liu, K.; Silva, B.; Montgomery, S.; Kim, E. J.; Lester, J.; Hill, T. M.; Avoricani, A.; Chervonski, E.; Davydov, J.; Small, W.; Chakravartty, E.; Grover, H.; Dodson, J. A.; Brody, A. A.; Aphinyanaphongs, Y.; Razavian, N.\nScore: 2.1, Published: 2023-07-12 DOI: 10.1101/2023.07.10.23292373\nBackgroundLarge language models (LLMs) provide powerful natural language processing (NLP) capabilities in medical and clinical tasks. Evaluating LLM performance is crucial due to potential false results. In this study, we assessed ChatGPT, a state-of-the-art LLM, in extracting information from clinical notes, focusing on cognitive tests, specifically the Mini Mental State Exam (MMSE) and the Cognitive Dementia Rating (CDR). We tasked ChatGPT with extracting MMSE and CDR scores and corresponding dates from clinical notes. MethodsOur cohort had 135,307 clinical notes (Jan 12th, 2010 to May 24th, 2023) mentioning MMSE, CDR, or Montreal Cognitive Assessment (MoCA). After applying inclusion criteria and excluding notes with only MoCA, 34,465 notes remained. Among them, 765 were randomly selected and underwent analysis by ChatGPT. 22 medically-trained experts reviewed ChatGPTs responses and provided ground truth. ChatGPT (GPT-4, version \"2023-03-15-preview\") was used on the 765 notes to extract MMSE and CDR instances with corresponding dates. Inference was successful for 742 notes. We used 20 notes for fine-tuning and training the reviewers. The remaining 722 were assigned to reviewers, with 309 assigned to two reviewers simultaneously. Inter-rater-agreement (Fleiss Kappa), precision, recall, true/false negative rates, and accuracy were calculated. ResultsFor MMSE information extraction, ChatGPT achieved 83% accuracy. It demonstrated high sensitivity with a Macro-recall of 89.7% and outstanding true-negative rates of 96%. The precision for MMSE was also high at 82.7%. In the case of CDR information extraction, ChatGPT achieved 89% accuracy. It showed excellent sensitivity with a Macro-recall of 91.3% and a perfect true-negative rate of 100%. However, the precision for CDR was lower at 57%. Analyzing the ground truth data, it was found that 89.1% of the notes included an MMSE documentation, whereas only 14.3% had a CDR documentation, which affected the precision of CDR extraction. Inter-rater-agreement was substantial, supporting the validity of our findings. Reviewers considered ChatGPTs responses correct (96% for MMSE, 98% for CDR) and complete (84% for MMSE, 83% for CDR). ConclusionChatGPT demonstrates overall accuracy in extracting MMSE and CDR scores and dates, potentially benefiting dementia research and clinical care. Prior probability of the information appearing in the text impacted ChatGPTs precision. Rigorous evaluation of LLMs for diverse medical tasks is crucial to understand their capabilities and limitations.\nMachine learning in medicine using JavaScript: building web apps using TensorFlow.js for interpreting biomedical datasets\nAuthors: Pires, J. G.\nScore: 3.2, Published: 2023-07-09 DOI: 10.1101/2023.06.21.23291717\nIntroductionContributions to medicine may come from different areas; and most areas are full of researchers wanting to support. Physists may help with theory, such as for nuclear medicine. Engineers with machineries, such as dialysis machine. Mathematicians with models, such as pharmacokinetics. And computer scientists with codes such as bioinformatics. MethodWe have used TensorFlow.js for modeling using neural networks biomedical datasets from Kaggle. We have modeled three datasets: diabetes detection, surgery complications, and heart failure. We have used Angular coded in TypeScript for the implementation of the models. Using TensorFlow.js, we have built Multilayer Perceptrons (MPLs) for modelling our datasets. We have employed the training and the validation curves to make sure the model learnt, and we have used accuracy as a measure of goodness of each model. Results and discussionWe have built a couple of examples using TensorFlow.js as machine learning platform. Even though python and R are dominant at the moment, JavaScript and derivatives are growing fast, offering basically the same performance, and some extra features associated with JavaScript. Kaggle, the public platform from where we downloaded our datasets, offers a huge amount of datasets for biomedical cases, thus, the reader can easily test what we have discussed, using the same codes, with minor chances, on any case they may be interested in. We were able to find 92% of accuracy for diabetes detection, 100% for surgery complications, and 70% for heart failure. The possibilities are unlimited, and we believe that it is a nice option for researchers aiming at web applications, especially, focused on medicine. ResumoO_ST_ABSPalavras-ChaveC_ST_ABSCC BY-NC-ND 4.0 - This work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International License.\nNightshift Imposes Irregular Lifestyle Behaviors in Police Academy Trainees\nAuthors: Erickson, M.; North, R.; Counts, J.; Wang, W.; Porter Starr, K. N.; Wideman, L.; Pieper, C.; Dunn, J.; Kraus, W. E.\nScore: 1.9, Published: 2023-07-08 DOI: 10.1101/2023.07.07.23292363\nStudy ObjectiveShiftwork increases risk for numerous chronic diseases, which is hypothesized to be linked to disruption of circadian timing of lifestyle behaviors. However, empirical data on timing of lifestyle behaviors in real-world shift workers are lacking. To address this, we characterized the regularity of timing of lifestyle behaviors in shift-working police trainees. MethodsUsing a two-group observational study design (N=18), we compared lifestyle behavior timing during 6 weeks of in-class training during dayshift, followed by 6 weeks of field-based training during either dayshift or nightshift. Lifestyle behavior timing, including sleep/wake patterns, physical activity, and meals, was captured using wearable activity trackers and mobile devices. The regularity of lifestyle behavior timing was quantified as an index score, which reflects day-to-day stability on a 24h time scale: Sleep Regularity Index (SRI), Physical Activity Regularity Index (PARI) and Mealtime Regularity Index (MRI). Logistic regression was applied to these indices to develop a composite score, termed the Behavior Regularity Index (BRI). ResultsTransitioning from dayshift to nightshift significantly worsened the BRI, relative to maintaining a dayshift schedule. Specifically, nightshift led to more irregular sleep/wake timing and meal timing; physical activity timing was not impacted. In contrast, maintaining a dayshift schedule did not impact regularity indices. ConclusionNightshift imposed irregular timing of lifestyle behaviors, which is consistent with the hypothesis that circadian disruption contributes to chronic disease risk in shift workers. How to mitigate the negative impact of shiftwork on human health as mediated by irregular timing of sleep/wake patterns and meals deserves exploration.\n",
  "wordCount" : "2805",
  "inLanguage": "en",
  "datePublished": "2023-07-16T10:39:40Z",
  "dateModified": "2023-07-16T10:39:40Z",
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://trxiv.yorks0n.com/posts/health-informatics/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "TRxiv2",
    "logo": {
      "@type": "ImageObject",
      "url": "https://trxiv.yorks0n.com/favicon.ico"
    }
  }
}
</script>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://trxiv.yorks0n.com" accesskey="h" title="TRxiv2 (Alt + H)">TRxiv2</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
        </ul>
    </nav>
</header>
<main class="main">
<article class="post-single">
  <header class="post-header">
    
    <h1 class="post-title">
      health informatics
    </h1>
    <div class="post-meta"><span>updated on July 16, 2023</span>

</div>
  </header> 
  <div class="post-content"><div class="accordion accordion-flush" id="accordionFlushExample"><div class="accordion-item">
    <h3 class="accordion-header" id="flush-heading10.1101/2023.07.03.23292192">
      <button class="accordion-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#flush-collapse10.1101/2023.07.03.23292192" aria-expanded="false" aria-controls="flush-collapse10.1101/2023.07.03.23292192">
        <p class="paperTitle">Beyond the hype: large language models propagate race-based medicine</p>
      </button>
    </h3>
    <div id="flush-collapse10.1101/2023.07.03.23292192" class="accordion-collapse collapse" aria-labelledby="flush-heading10.1101/2023.07.03.23292192" data-bs-parent="#accordionFlushExample">
      <div class="accordion-body">
        <p class="author">Authors: Omiye, J. A.; Lester, J.; Spichak, S.; Rotemberg, V.; Daneshjou, R.</p>
        <p class="info">Score: 63.0, Published: 2023-07-05 </p>
        <p class="info">DOI: <a href='https://doi.org/10.1101/2023.07.03.23292192' target='https://doi.org/10.1101/2023.07.03.23292192'> 10.1101/2023.07.03.23292192</a></p>
        <p class="abstract">ImportanceLarge language models (LLMs) are being integrated into healthcare systems; but these models recapitulate harmful, race-based medicine.

ObjectiveThe objective of this study is to assess whether four commercially available large language models (LLMs) propagate harmful, inaccurate, race-based content when responding to eight different scenarios that historically included race-based medicine or widespread misconceptions around race.

Evidence ReviewQuestions were derived from discussion among 4 physician experts and prior work on race-based medical misconceptions of medical trainees.

FindingsWe assessed four large language models with eight different questions that were interrogated five times each with a total of forty responses per a model. All models had examples of perpetuating race-based medicine in their responses. Models were not always consistent in their responses when asked the same question repeatedly.

Conclusions and RelevanceLLMs are being proposed for use in the healthcare setting, with some models already connecting to electronic health record systems. However, this study shows that based on our findings, these LLMs could potentially cause harm by perpetuating debunked, racist concepts.</p>
      </div>
    </div>
  </div><div class="accordion-item">
    <h3 class="accordion-header" id="flush-heading10.1101/2023.07.07.23292388">
      <button class="accordion-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#flush-collapse10.1101/2023.07.07.23292388" aria-expanded="false" aria-controls="flush-collapse10.1101/2023.07.07.23292388">
        <p class="paperTitle">Leveraging Generative AI to Prioritize Drug Repurposing Candidates: Validating Identified Candidates for Alzheimer&#39;s Disease in Real-World Clinical Datasets</p>
      </button>
    </h3>
    <div id="flush-collapse10.1101/2023.07.07.23292388" class="accordion-collapse collapse" aria-labelledby="flush-heading10.1101/2023.07.07.23292388" data-bs-parent="#accordionFlushExample">
      <div class="accordion-body">
        <p class="author">Authors: Wei, W.-Q.; Yan, C.; Grabowska, M. E.; Dickson, A. L.; Li, B.; Wen, Z.; Roden, D. M.; Stein, C. M.; Embi, P. J.; Peterson, J. F.; Feng, Q.; Malin, B. A.</p>
        <p class="info">Score: 4.2, Published: 2023-07-08 </p>
        <p class="info">DOI: <a href='https://doi.org/10.1101/2023.07.07.23292388' target='https://doi.org/10.1101/2023.07.07.23292388'> 10.1101/2023.07.07.23292388</a></p>
        <p class="abstract">Drug repurposing represents an attractive alternative to the costly and time-consuming process of new drug development, particularly for serious, widespread conditions with limited effective treatments, such as Alzheimers disease (AD). Emerging generative artificial intelligence (GAI) technologies like ChatGPT offer the promise of expediting the review and summary of scientific knowledge. To examine the feasibility of using GAI for identifying drug repurposing candidates, we iteratively tasked ChatGPT with proposing the twenty most promising drugs for repurposing in AD, and tested the top ten for risk of incident AD in exposed and unexposed individuals over age 65 in two large clinical datasets: 1) Vanderbilt University Medical Center and 2) the All of Us Research Program. Among the candidates suggested by ChatGPT, metformin, simvastatin, and losartan were associated with lower AD risk in meta-analysis. These findings suggest GAI technologies can assimilate scientific insights from an extensive Internet-based search space, helping to prioritize drug repurposing candidates and facilitate the treatment of diseases.</p>
      </div>
    </div>
  </div><div class="accordion-item">
    <h3 class="accordion-header" id="flush-heading10.1101/2023.07.13.23292612">
      <button class="accordion-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#flush-collapse10.1101/2023.07.13.23292612" aria-expanded="false" aria-controls="flush-collapse10.1101/2023.07.13.23292612">
        <p class="paperTitle">The Medical Action Ontology: A Tool for Annotating and Analyzing Treatments and Clinical Management of Human Disease</p>
      </button>
    </h3>
    <div id="flush-collapse10.1101/2023.07.13.23292612" class="accordion-collapse collapse" aria-labelledby="flush-heading10.1101/2023.07.13.23292612" data-bs-parent="#accordionFlushExample">
      <div class="accordion-body">
        <p class="author">Authors: Carmody, L. C.; Gargano, M. A.; Toro, S.; Vasilevsky, N. A.; Adam, M. P.; Blau, H.; Chan, L. E.; Gomez-Andres, D.; Horvath, R.; Ladewig, M. S.; Lewis-Smith, D.; Lochmueller, H.; Matentzoglu, N. A.; Munoz-Torres, M. C.; Schuetz, C.; Kraus, M. L.; Seitz, B.; Similuk, M. N.; Sparks, T.; Strauss, T.; Swietlik, E. M.; Thompson, R.; Zhang, X. A.; Mungall, C. J.; Haendel, M. A.; Robinson, P. N.</p>
        <p class="info">Score: 4.0, Published: 2023-07-13 </p>
        <p class="info">DOI: <a href='https://doi.org/10.1101/2023.07.13.23292612' target='https://doi.org/10.1101/2023.07.13.23292612'> 10.1101/2023.07.13.23292612</a></p>
        <p class="abstract">Navigating the vast landscape of clinical literature to find optimal treatments and management strategies can be a challenging task, especially for rare diseases. To address this task, we introduce the Medical Action Ontology (MAxO), the first ontology specifically designed to organize medical procedures, therapies, and interventions in a structured way. Currently, MAxO contains 1757 medical action terms added through a combination of manual and semi-automated processes. MAxO was developed with logical structures that make it compatible with several other ontologies within the Open Biological and Biomedical Ontologies (OBO) Foundry. These cover a wide range of biomedical domains, from human anatomy and investigations to the chemical and protein entities involved in biological processes. We have created a database of over 16000 annotations that describe diagnostic modalities for specific phenotypic abnormalities as defined by the Human Phenotype Ontology (HPO). Additionally, 413 annotations are provided for medical actions for 189 rare diseases. We have developed a web application called POET (https://poet.jax.org/) for the community to use to contribute MAxO annotations. MAxO provides a computational representation of treatments and other actions taken for the clinical management of patients. The development of MAxO is closely coupled to the Mondo Disease Ontology (Mondo) and the Human Phenotype Ontology (HPO) and expands the scope of our computational modeling of diseases and phenotypic features to include diagnostics and therapeutic actions. MAxO is available under the open-source CC-BY 4.0 license (https://github.com/monarch-initiative/MAxO).</p>
      </div>
    </div>
  </div><div class="accordion-item">
    <h3 class="accordion-header" id="flush-heading10.1101/2023.07.07.23292391">
      <button class="accordion-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#flush-collapse10.1101/2023.07.07.23292391" aria-expanded="false" aria-controls="flush-collapse10.1101/2023.07.07.23292391">
        <p class="paperTitle">Assessing GPT-3.5 and GPT-4 in Generating International Classification of Diseases Billing Codes</p>
      </button>
    </h3>
    <div id="flush-collapse10.1101/2023.07.07.23292391" class="accordion-collapse collapse" aria-labelledby="flush-heading10.1101/2023.07.07.23292391" data-bs-parent="#accordionFlushExample">
      <div class="accordion-body">
        <p class="author">Authors: Soroush, A.; Glicksberg, B. S.; Zimlichman, E.; Barash, Y.; Freeman, R. M.; Charney, A.; Nadkarni, G.; Klang, E.</p>
        <p class="info">Score: 3.6, Published: 2023-07-11 </p>
        <p class="info">DOI: <a href='https://doi.org/10.1101/2023.07.07.23292391' target='https://doi.org/10.1101/2023.07.07.23292391'> 10.1101/2023.07.07.23292391</a></p>
        <p class="abstract">BackgroundLarge Language Models (LLMs) like GPT-3.5 and GPT-4 are increasingly entering the healthcare domain as a proposed means to assist with administrative tasks. To ensure safe and effective use with billing coding tasks, it is crucial to assess these models ability to generate the correct International Classification of Diseases (ICD) codes from text descriptions.

ObjectivesWe aimed to evaluate GPT-3.5 and GPT-4s capability to generate correct ICD billing codes, using the ICD-9-CM (2014) and ICD-10-CM and PCS (2023) systems.

MethodsWe randomly selected 100 unique codes from each of the most recent versions of the ICD-9-CM, ICD-10-CM, and ICD-10-PCS billing code sets published by the Centers for Medicare and Medicaid Services. Using the ChatGPT interface (GPT-3.5 and GPT-4), we prompted for the ICD codes that corresponding to each provided code description. Outputs were compared with the actual billing codes across several performance measures. Errors were qualitatively and quantitatively assessed for any underlying patterns.

ResultsGPT-4 and GPT-3.5 demonstrated varied performance across each ICD system. In ICD-9-CM, GPT-4 and GPT-3.5 achieved an exact match rate of 22% and 10%, respectively. 13% (GPT-4) and 10% (GPT-3.5) of generated ICD-10-CM codes were exact matches. Notably, both models struggled considerably with the procedurally focused ICD-10-PCS, with neither GPT-4 or GPT-3.5 producing any exactly matched codes. A substantial number of incorrect codes had semantic similarity with the actual codes for ICD-9-CM (GPT-4: 60.3%, GPT-3.5: 51.1%) and ICD-10-CM (GPT-4: 70.1%, GPT-3.5: 61.1%), in contrast to ICD-10-PCS (GPT-4: 30.0%, GPT-3.5: 16.0%).

ConclusionOur evaluation of GPT-3.5 and GPT-4s proficiency in generating ICD billing codes from ICD-9-CM, ICD-10-CM and ICD-10-PCS code descriptions reveals an inadequate level of performance. While the models appear to exhibit a general conceptual understanding of the codes and their descriptions, they have a propensity for hallucinating key details, suggesting underlying technological limitations of the base LLMs. This suggests a need for more rigorous LLM augmentation strategies and validation prior to their implementation in healthcare contexts, particularly in tasks such as ICD coding which require significant digit-level precision.</p>
      </div>
    </div>
  </div><div class="accordion-item">
    <h3 class="accordion-header" id="flush-heading10.1101/2023.07.10.23292437">
      <button class="accordion-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#flush-collapse10.1101/2023.07.10.23292437" aria-expanded="false" aria-controls="flush-collapse10.1101/2023.07.10.23292437">
        <p class="paperTitle">Automatic Detection and Assessment of Freezing of Gait Manifestations</p>
      </button>
    </h3>
    <div id="flush-collapse10.1101/2023.07.10.23292437" class="accordion-collapse collapse" aria-labelledby="flush-heading10.1101/2023.07.10.23292437" data-bs-parent="#accordionFlushExample">
      <div class="accordion-body">
        <p class="author">Authors: Yang, P.-K.; Filtjens, B.; Ginis, P.; Goris, M.; Nieuwboer, A.; Gilat, M.; Slaets, P.; Vanrumste, B.</p>
        <p class="info">Score: 3.0, Published: 2023-07-12 </p>
        <p class="info">DOI: <a href='https://doi.org/10.1101/2023.07.10.23292437' target='https://doi.org/10.1101/2023.07.10.23292437'> 10.1101/2023.07.10.23292437</a></p>
        <p class="abstract">Freezing of gait (FOG) is an episodic and highly disabling symptom of Parkinsons disease (PD). Although described as a single phenomenon, FOG is not univocal and can express as different manifestations, such as trembling in place or complete akinesia. We aimed to analyze the utility of deep learning trained on inertial measurement unit data to classify FOG into both manifestations. We developed a temporal convolutional neural network, which we compared to three state-of-the-art FOG detection algorithms that were adapted to the FOG manifestation detection task. Next, we investigated its performance in distinguishing between the two manifestations and other forms of movement cessation (e.g., volitional stopping and sitting) based on gold-standard video annotations. Experiments were conducted on a dataset of twelve PD patients with FOG that completed a FOG-provoking protocol, including the timed-up-and-go and 360-degree turning-in-place tasks during ON and OFF anti-Parkinsonian medication. The results showed that our model enables accurate detection of FOG manifestations with an 11.43% higher F1 score than the second-best model. Assessment of FOG manifestation severity was moderately strong for trembling in place (Intra-class Correlation Coefficient (ICC)=0.64, [0.16,0.88]) and strong for complete akinesia (ICC=0.87, [0.63,0.96]). Remarkably, our results show that complete akinesia can be distinguished from volitional stopping. In conclusion, we established that FOG manifestations could be accurately detected and assessed with deep learning. Future work should establish whether these results hold firm for a more extensive and varied verification cohort.</p>
      </div>
    </div>
  </div><div class="accordion-item">
    <h3 class="accordion-header" id="flush-heading10.1101/2023.07.13.23292613">
      <button class="accordion-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#flush-collapse10.1101/2023.07.13.23292613" aria-expanded="false" aria-controls="flush-collapse10.1101/2023.07.13.23292613">
        <p class="paperTitle">On the limitations of large language models in clinical diagnosis</p>
      </button>
    </h3>
    <div id="flush-collapse10.1101/2023.07.13.23292613" class="accordion-collapse collapse" aria-labelledby="flush-heading10.1101/2023.07.13.23292613" data-bs-parent="#accordionFlushExample">
      <div class="accordion-body">
        <p class="author">Authors: Reese, J.; Danis, D.; Caufield, J. H.; Casiraghi, E.; Valentini, G.; Mungall, C. J.; Robinson, P. N.</p>
        <p class="info">Score: 2.1, Published: 2023-07-14 </p>
        <p class="info">DOI: <a href='https://doi.org/10.1101/2023.07.13.23292613' target='https://doi.org/10.1101/2023.07.13.23292613'> 10.1101/2023.07.13.23292613</a></p>
        <p class="abstract">Background: The potential of large language models (LLM) such as GPT to support complex tasks such as differential diagnosis has been a subject of debate, with some ascribing near sentient abilities to the models and others claiming that LLMs merely perform &#34;autocomplete on steroids&#34;. A recent study reported that the Generative Pretrained Transformer 4 (GPT-4) model performed well in complex differential diagnostic reasoning. The authors assessed the performance of GPT-4 in identifying the correct diagnosis in a series of case records from the New England Journal of Medicine. The authors constructed prompts based on the clinical presentation section of the case reports, and compared the results of GPT-4 to the actual diagnosis. GPT-4 returned the correct diagnosis as a part of its response in 64% of cases, with the correct diagnosis being at rank 1 in 39% of cases. However, such concise but comprehensive narratives of the clinical course are not typically available in electronic health records (EHRs). Further, if they were available, EHR records contain identifying information whose transmission is prohibited by Health Insurance Portability and Accountability Act (HIPAA) regulations. Methods: To assess the expected performance of GPT on comparable datasets that can be generated by text mining and by design cannot contain identifiable information, we parsed the texts of the case reports and extracted Human Phenotype Ontology (HPO) terms, from which prompts for GPT were constructed that contain largely the same clinical abnormalities but lack the surrounding narrative. Results: While the performance of GPT-4 on the original narrative-based text was good, with the final diagnosis being included in its differential in 29/75 cases (38.7%; rank 1 in 17.3% of cases; mean rank of 3.4), the performance of GPT-4 on the feature-based approach that includes the major clinical abnormalities without additional narrative texas substantially worse, with GPT-4 including the final diagnosis in its differential in 8/75 cases (10.7%; rank 1 in 4.0% of cases; mean rank of 3.9). Interpretation: We consider the feature-based queries to be a more appropriate test of the performance of GPT-4 in diagnostic tasks, since it is unlikely that the narrative approach can be used in actual clinical practice. Future research and algorithmic development is needed to determine the optimal approach to leveraging LLMs for clinical diagnosis.</p>
      </div>
    </div>
  </div><div class="accordion-item">
    <h3 class="accordion-header" id="flush-heading10.1101/2023.07.10.23292373">
      <button class="accordion-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#flush-collapse10.1101/2023.07.10.23292373" aria-expanded="false" aria-controls="flush-collapse10.1101/2023.07.10.23292373">
        <p class="paperTitle">Evaluating ChatGPT in Information Extraction: A Case Study of Extracting Cognitive Exam Dates and Scores</p>
      </button>
    </h3>
    <div id="flush-collapse10.1101/2023.07.10.23292373" class="accordion-collapse collapse" aria-labelledby="flush-heading10.1101/2023.07.10.23292373" data-bs-parent="#accordionFlushExample">
      <div class="accordion-body">
        <p class="author">Authors: Jethani, N.; Jones, S.; Genes, N.; Major, V. J.; Jaffe, I. S.; Cardillo, A. B.; Heilenbach, N.; Ali, N. F.; Bonanni, L. J.; Clayburn, A. J.; Khera, Z.; Sadler, E. C.; Prasad, J.; Schlacter, J.; Liu, K.; Silva, B.; Montgomery, S.; Kim, E. J.; Lester, J.; Hill, T. M.; Avoricani, A.; Chervonski, E.; Davydov, J.; Small, W.; Chakravartty, E.; Grover, H.; Dodson, J. A.; Brody, A. A.; Aphinyanaphongs, Y.; Razavian, N.</p>
        <p class="info">Score: 2.1, Published: 2023-07-12 </p>
        <p class="info">DOI: <a href='https://doi.org/10.1101/2023.07.10.23292373' target='https://doi.org/10.1101/2023.07.10.23292373'> 10.1101/2023.07.10.23292373</a></p>
        <p class="abstract">BackgroundLarge language models (LLMs) provide powerful natural language processing (NLP) capabilities in medical and clinical tasks. Evaluating LLM performance is crucial due to potential false results. In this study, we assessed ChatGPT, a state-of-the-art LLM, in extracting information from clinical notes, focusing on cognitive tests, specifically the Mini Mental State Exam (MMSE) and the Cognitive Dementia Rating (CDR). We tasked ChatGPT with extracting MMSE and CDR scores and corresponding dates from clinical notes.

MethodsOur cohort had 135,307 clinical notes (Jan 12th, 2010 to May 24th, 2023) mentioning MMSE, CDR, or Montreal Cognitive Assessment (MoCA). After applying inclusion criteria and excluding notes with only MoCA, 34,465 notes remained. Among them, 765 were randomly selected and underwent analysis by ChatGPT. 22 medically-trained experts reviewed ChatGPTs responses and provided ground truth. ChatGPT (GPT-4, version &#34;2023-03-15-preview&#34;) was used on the 765 notes to extract MMSE and CDR instances with corresponding dates. Inference was successful for 742 notes. We used 20 notes for fine-tuning and training the reviewers. The remaining 722 were assigned to reviewers, with 309 assigned to two reviewers simultaneously. Inter-rater-agreement (Fleiss Kappa), precision, recall, true/false negative rates, and accuracy were calculated.

ResultsFor MMSE information extraction, ChatGPT achieved 83% accuracy. It demonstrated high sensitivity with a Macro-recall of 89.7% and outstanding true-negative rates of 96%. The precision for MMSE was also high at 82.7%. In the case of CDR information extraction, ChatGPT achieved 89% accuracy. It showed excellent sensitivity with a Macro-recall of 91.3% and a perfect true-negative rate of 100%. However, the precision for CDR was lower at 57%. Analyzing the ground truth data, it was found that 89.1% of the notes included an MMSE documentation, whereas only 14.3% had a CDR documentation, which affected the precision of CDR extraction. Inter-rater-agreement was substantial, supporting the validity of our findings. Reviewers considered ChatGPTs responses correct (96% for MMSE, 98% for CDR) and complete (84% for MMSE, 83% for CDR).

ConclusionChatGPT demonstrates overall accuracy in extracting MMSE and CDR scores and dates, potentially benefiting dementia research and clinical care. Prior probability of the information appearing in the text impacted ChatGPTs precision. Rigorous evaluation of LLMs for diverse medical tasks is crucial to understand their capabilities and limitations.</p>
      </div>
    </div>
  </div><div class="accordion-item">
    <h3 class="accordion-header" id="flush-heading10.1101/2023.06.21.23291717">
      <button class="accordion-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#flush-collapse10.1101/2023.06.21.23291717" aria-expanded="false" aria-controls="flush-collapse10.1101/2023.06.21.23291717">
        <p class="paperTitle">Machine learning in medicine using JavaScript: building web apps using TensorFlow.js for interpreting biomedical datasets</p>
      </button>
    </h3>
    <div id="flush-collapse10.1101/2023.06.21.23291717" class="accordion-collapse collapse" aria-labelledby="flush-heading10.1101/2023.06.21.23291717" data-bs-parent="#accordionFlushExample">
      <div class="accordion-body">
        <p class="author">Authors: Pires, J. G.</p>
        <p class="info">Score: 3.2, Published: 2023-07-09 </p>
        <p class="info">DOI: <a href='https://doi.org/10.1101/2023.06.21.23291717' target='https://doi.org/10.1101/2023.06.21.23291717'> 10.1101/2023.06.21.23291717</a></p>
        <p class="abstract">IntroductionContributions to medicine may come from different areas; and most areas are full of researchers wanting to support. Physists may help with theory, such as for nuclear medicine. Engineers with machineries, such as dialysis machine. Mathematicians with models, such as pharmacokinetics. And computer scientists with codes such as bioinformatics.

MethodWe have used TensorFlow.js for modeling using neural networks biomedical datasets from Kaggle. We have modeled three datasets: diabetes detection, surgery complications, and heart failure. We have used Angular coded in TypeScript for the implementation of the models. Using TensorFlow.js, we have built Multilayer Perceptrons (MPLs) for modelling our datasets. We have employed the training and the validation curves to make sure the model learnt, and we have used accuracy as a measure of goodness of each model.

Results and discussionWe have built a couple of examples using TensorFlow.js as machine learning platform. Even though python and R are dominant at the moment, JavaScript and derivatives are growing fast, offering basically the same performance, and some extra features associated with JavaScript. Kaggle, the public platform from where we downloaded our datasets, offers a huge amount of datasets for biomedical cases, thus, the reader can easily test what we have discussed, using the same codes, with minor chances, on any case they may be interested in. We were able to find 92% of accuracy for diabetes detection, 100% for surgery complications, and 70% for heart failure. The possibilities are unlimited, and we believe that it is a nice option for researchers aiming at web applications, especially, focused on medicine.

ResumoO_ST_ABSPalavras-ChaveC_ST_ABSCC BY-NC-ND 4.0 - This work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International License.</p>
      </div>
    </div>
  </div><div class="accordion-item">
    <h3 class="accordion-header" id="flush-heading10.1101/2023.07.07.23292363">
      <button class="accordion-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#flush-collapse10.1101/2023.07.07.23292363" aria-expanded="false" aria-controls="flush-collapse10.1101/2023.07.07.23292363">
        <p class="paperTitle">Nightshift Imposes Irregular Lifestyle Behaviors in Police Academy Trainees</p>
      </button>
    </h3>
    <div id="flush-collapse10.1101/2023.07.07.23292363" class="accordion-collapse collapse" aria-labelledby="flush-heading10.1101/2023.07.07.23292363" data-bs-parent="#accordionFlushExample">
      <div class="accordion-body">
        <p class="author">Authors: Erickson, M.; North, R.; Counts, J.; Wang, W.; Porter Starr, K. N.; Wideman, L.; Pieper, C.; Dunn, J.; Kraus, W. E.</p>
        <p class="info">Score: 1.9, Published: 2023-07-08 </p>
        <p class="info">DOI: <a href='https://doi.org/10.1101/2023.07.07.23292363' target='https://doi.org/10.1101/2023.07.07.23292363'> 10.1101/2023.07.07.23292363</a></p>
        <p class="abstract">Study ObjectiveShiftwork increases risk for numerous chronic diseases, which is hypothesized to be linked to disruption of circadian timing of lifestyle behaviors. However, empirical data on timing of lifestyle behaviors in real-world shift workers are lacking. To address this, we characterized the regularity of timing of lifestyle behaviors in shift-working police trainees.

MethodsUsing a two-group observational study design (N=18), we compared lifestyle behavior timing during 6 weeks of in-class training during dayshift, followed by 6 weeks of field-based training during either dayshift or nightshift. Lifestyle behavior timing, including sleep/wake patterns, physical activity, and meals, was captured using wearable activity trackers and mobile devices. The regularity of lifestyle behavior timing was quantified as an index score, which reflects day-to-day stability on a 24h time scale: Sleep Regularity Index (SRI), Physical Activity Regularity Index (PARI) and Mealtime Regularity Index (MRI). Logistic regression was applied to these indices to develop a composite score, termed the Behavior Regularity Index (BRI).

ResultsTransitioning from dayshift to nightshift significantly worsened the BRI, relative to maintaining a dayshift schedule. Specifically, nightshift led to more irregular sleep/wake timing and meal timing; physical activity timing was not impacted. In contrast, maintaining a dayshift schedule did not impact regularity indices.

ConclusionNightshift imposed irregular timing of lifestyle behaviors, which is consistent with the hypothesis that circadian disruption contributes to chronic disease risk in shift workers. How to mitigate the negative impact of shiftwork on human health as mediated by irregular timing of sleep/wake patterns and meals deserves exploration.</p>
      </div>
    </div>
  </div>
</div>









<script src="/js/bundle.min.js" defer></script>



  </div>

  <footer class="post-footer">
    <ul class="post-tags">
    </ul>
  </footer>
</article>
    </main>
    
<footer class="footer">
    <span>&copy; 2023 <a href="https://trxiv.yorks0n.com">TRxiv2</a></span>
    <span>
         Made by Yorkson
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
</body>

</html>
