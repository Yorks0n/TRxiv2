<!DOCTYPE html>
<html lang="en" dir="auto">

<head>
<head>
    <title>health informatics</title>
    <meta charset="utf-8">
    <meta name="description"
        content="Website meta description for google search results go here" />
    <meta name="dc.relation" content="https://trxiv.yorks0n.com" />
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta name="theme-color" content="#1A94D2" />

    

    
    
    
    <link rel="stylesheet" href="/css/main.min.css" media="screen">

</head>


<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>health informatics | TRxiv2</title>
<meta name="keywords" content="">
<meta name="description" content="Leveraging Large Language Models for Generating Responses to Patient Messages
Authors: Liu, S.; McCoy, A. B.; Wright, A. P.; Carew, B.; Genkins, J. Z.; Huang, S. S.; Peterson, J. F.; Steitz, B.; Wright, A.
Score: 18.5, Published: 2023-07-16 DOI: 10.1101/2023.07.14.23292669
ObjectiveThis study aimed to develop and assess the performance of fine-tuned large language models for generating responses to patient messages sent via an electronic health record patient portal. MethodsUtilizing a dataset of messages and responses extracted from the patient portal at a large academic medical center, we developed a model (CLAIR-Short) based on a pre-trained large language model (LLaMA-65B).">
<meta name="author" content="">
<link rel="canonical" href="https://trxiv.yorks0n.com/posts/health-informatics/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.904bd1e751cdd2a584fa6bed3fa1166dfd8ec9949ebfd0c4d69c5add5e17c23d.css" integrity="sha256-kEvR51HN0qWE&#43;mvtP6EWbf2OyZSev9DE1pxa3V4Xwj0=" rel="preload stylesheet" as="style">
<script defer crossorigin="anonymous" src="/assets/js/highlight.f413e19d0714851f6474e7ee9632408e58ac146fbdbe62747134bea2fa3415e0.js" integrity="sha256-9BPhnQcUhR9kdOfuljJAjlisFG&#43;9vmJ0cTS&#43;ovo0FeA="
    onload="hljs.initHighlightingOnLoad();"></script>
<link rel="icon" href="https://trxiv.yorks0n.com/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="https://trxiv.yorks0n.com/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://trxiv.yorks0n.com/favicon-32x32.png">
<link rel="apple-touch-icon" href="https://trxiv.yorks0n.com/apple-touch-icon.png">
<link rel="mask-icon" href="https://trxiv.yorks0n.com/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --hljs-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript><meta property="og:title" content="health informatics" />
<meta property="og:description" content="Leveraging Large Language Models for Generating Responses to Patient Messages
Authors: Liu, S.; McCoy, A. B.; Wright, A. P.; Carew, B.; Genkins, J. Z.; Huang, S. S.; Peterson, J. F.; Steitz, B.; Wright, A.
Score: 18.5, Published: 2023-07-16 DOI: 10.1101/2023.07.14.23292669
ObjectiveThis study aimed to develop and assess the performance of fine-tuned large language models for generating responses to patient messages sent via an electronic health record patient portal. MethodsUtilizing a dataset of messages and responses extracted from the patient portal at a large academic medical center, we developed a model (CLAIR-Short) based on a pre-trained large language model (LLaMA-65B)." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://trxiv.yorks0n.com/posts/health-informatics/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-07-23T10:36:34+00:00" />
<meta property="article:modified_time" content="2023-07-23T10:36:34+00:00" />

<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="health informatics"/>
<meta name="twitter:description" content="Leveraging Large Language Models for Generating Responses to Patient Messages
Authors: Liu, S.; McCoy, A. B.; Wright, A. P.; Carew, B.; Genkins, J. Z.; Huang, S. S.; Peterson, J. F.; Steitz, B.; Wright, A.
Score: 18.5, Published: 2023-07-16 DOI: 10.1101/2023.07.14.23292669
ObjectiveThis study aimed to develop and assess the performance of fine-tuned large language models for generating responses to patient messages sent via an electronic health record patient portal. MethodsUtilizing a dataset of messages and responses extracted from the patient portal at a large academic medical center, we developed a model (CLAIR-Short) based on a pre-trained large language model (LLaMA-65B)."/>


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "Posts",
      "item": "https://trxiv.yorks0n.com/posts/"
    }, 
    {
      "@type": "ListItem",
      "position":  3 ,
      "name": "health informatics",
      "item": "https://trxiv.yorks0n.com/posts/health-informatics/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "health informatics",
  "name": "health informatics",
  "description": "Leveraging Large Language Models for Generating Responses to Patient Messages\nAuthors: Liu, S.; McCoy, A. B.; Wright, A. P.; Carew, B.; Genkins, J. Z.; Huang, S. S.; Peterson, J. F.; Steitz, B.; Wright, A.\nScore: 18.5, Published: 2023-07-16 DOI: 10.1101/2023.07.14.23292669\nObjectiveThis study aimed to develop and assess the performance of fine-tuned large language models for generating responses to patient messages sent via an electronic health record patient portal. MethodsUtilizing a dataset of messages and responses extracted from the patient portal at a large academic medical center, we developed a model (CLAIR-Short) based on a pre-trained large language model (LLaMA-65B).",
  "keywords": [
    
  ],
  "articleBody": " Leveraging Large Language Models for Generating Responses to Patient Messages\nAuthors: Liu, S.; McCoy, A. B.; Wright, A. P.; Carew, B.; Genkins, J. Z.; Huang, S. S.; Peterson, J. F.; Steitz, B.; Wright, A.\nScore: 18.5, Published: 2023-07-16 DOI: 10.1101/2023.07.14.23292669\nObjectiveThis study aimed to develop and assess the performance of fine-tuned large language models for generating responses to patient messages sent via an electronic health record patient portal. MethodsUtilizing a dataset of messages and responses extracted from the patient portal at a large academic medical center, we developed a model (CLAIR-Short) based on a pre-trained large language model (LLaMA-65B). In addition, we used the OpenAI API to update physician responses from an open-source dataset into a format with informative paragraphs that offered patient education while emphasizing empathy and professionalism. By combining with this dataset, we further fine-tuned our model (CLAIR-Long). To evaluate the fine-tuned models, we used ten representative patient portal questions in primary care to generate responses. We asked primary care physicians to review generated responses from our models and ChatGPT and rated them for empathy, responsiveness, accuracy, and usefulness. ResultsThe dataset consisted of a total of 499,794 pairs of patient messages and corresponding responses from the patient portal, with 5,000 patient messages and ChatGPT-updated responses from an online platform. Four primary care physicians participated in the survey. CLAIR-Short exhibited the ability to generate concise responses similar to providers responses. CLAIR-Long responses provided increased patient educational content compared to CLAIR-Short and were rated similarly to ChatGPTs responses, receiving positive evaluations for responsiveness, empathy, and accuracy, while receiving a neutral rating for usefulness. ConclusionLeveraging large language models to generate responses to patient messages demonstrates significant potential in facilitating communication between patients and primary care providers.\nCoding Inequity: Assessing GPT-4's Potential for Perpetuating Racial and Gender Biases in Healthcare\nAuthors: Zack, T.; Lehman, E.; Suzgun, M.; Rodriguez, J. A.; Celi, L. A.; Gichoya, J.; Jurafsky, D.; Szolovits, P.; Bates, D. W.; Abdulnour, R.-E. E.; Butte, A. J.; Alsentzer, E.\nScore: 9.8, Published: 2023-07-17 DOI: 10.1101/2023.07.13.23292577\nBackgroundLarge language models (LLMs) such as GPT-4 hold great promise as transformative tools in healthcare, ranging from automating administrative tasks to augmenting clinical decision- making. However, these models also pose a serious danger of perpetuating biases and delivering incorrect medical diagnoses, which can have a direct, harmful impact on medical care. MethodsUsing the Azure OpenAI API, we tested whether GPT-4 encodes racial and gender biases and examined the impact of such biases on four potential applications of LLMs in the clinical domain--namely, medical education, diagnostic reasoning, plan generation, and patient assessment. We conducted experiments with prompts designed to resemble typical use of GPT-4 within clinical and medical education applications. We used clinical vignettes from NEJM Healer and from published research on implicit bias in healthcare. GPT-4 estimates of the demographic distribution of medical conditions were compared to true U.S. prevalence estimates. Differential diagnosis and treatment planning were evaluated across demographic groups using standard statistical tests for significance between groups. FindingsWe find that GPT-4 does not appropriately model the demographic diversity of medical conditions, consistently producing clinical vignettes that stereotype demographic presentations. The differential diagnoses created by GPT-4 for standardized clinical vignettes were more likely to include diagnoses that stereotype certain races, ethnicities, and gender identities. Assessment and plans created by the model showed significant association between demographic attributes and recommendations for more expensive procedures as well as differences in patient perception. InterpretationOur findings highlight the urgent need for comprehensive and transparent bias assessments of LLM tools like GPT-4 for every intended use case before they are integrated into clinical care. We discuss the potential sources of these biases and potential mitigation strategies prior to clinical implementation.\nAssessing GPT-3.5 and GPT-4 in Generating International Classification of Diseases Billing Codes\nAuthors: Soroush, A.; Glicksberg, B. S.; Zimlichman, E.; Barash, Y.; Freeman, R. M.; Charney, A.; Nadkarni, G.; Klang, E.\nScore: 4.6, Published: 2023-07-11 DOI: 10.1101/2023.07.07.23292391\nBackgroundLarge Language Models (LLMs) like GPT-3.5 and GPT-4 are increasingly entering the healthcare domain as a proposed means to assist with administrative tasks. To ensure safe and effective use with billing coding tasks, it is crucial to assess these models ability to generate the correct International Classification of Diseases (ICD) codes from text descriptions. ObjectivesWe aimed to evaluate GPT-3.5 and GPT-4s capability to generate correct ICD billing codes, using the ICD-9-CM (2014) and ICD-10-CM and PCS (2023) systems. MethodsWe randomly selected 100 unique codes from each of the most recent versions of the ICD-9-CM, ICD-10-CM, and ICD-10-PCS billing code sets published by the Centers for Medicare and Medicaid Services. Using the ChatGPT interface (GPT-3.5 and GPT-4), we prompted for the ICD codes that corresponding to each provided code description. Outputs were compared with the actual billing codes across several performance measures. Errors were qualitatively and quantitatively assessed for any underlying patterns. ResultsGPT-4 and GPT-3.5 demonstrated varied performance across each ICD system. In ICD-9-CM, GPT-4 and GPT-3.5 achieved an exact match rate of 22% and 10%, respectively. 13% (GPT-4) and 10% (GPT-3.5) of generated ICD-10-CM codes were exact matches. Notably, both models struggled considerably with the procedurally focused ICD-10-PCS, with neither GPT-4 or GPT-3.5 producing any exactly matched codes. A substantial number of incorrect codes had semantic similarity with the actual codes for ICD-9-CM (GPT-4: 60.3%, GPT-3.5: 51.1%) and ICD-10-CM (GPT-4: 70.1%, GPT-3.5: 61.1%), in contrast to ICD-10-PCS (GPT-4: 30.0%, GPT-3.5: 16.0%). ConclusionOur evaluation of GPT-3.5 and GPT-4s proficiency in generating ICD billing codes from ICD-9-CM, ICD-10-CM and ICD-10-PCS code descriptions reveals an inadequate level of performance. While the models appear to exhibit a general conceptual understanding of the codes and their descriptions, they have a propensity for hallucinating key details, suggesting underlying technological limitations of the base LLMs. This suggests a need for more rigorous LLM augmentation strategies and validation prior to their implementation in healthcare contexts, particularly in tasks such as ICD coding which require significant digit-level precision.\nBeyond the hype: large language models propagate race-based medicine\nAuthors: Omiye, J. A.; Lester, J.; Spichak, S.; Rotemberg, V.; Daneshjou, R.\nScore: 63.3, Published: 2023-07-05 DOI: 10.1101/2023.07.03.23292192\nImportanceLarge language models (LLMs) are being integrated into healthcare systems; but these models recapitulate harmful, race-based medicine. ObjectiveThe objective of this study is to assess whether four commercially available large language models (LLMs) propagate harmful, inaccurate, race-based content when responding to eight different scenarios that historically included race-based medicine or widespread misconceptions around race. Evidence ReviewQuestions were derived from discussion among 4 physician experts and prior work on race-based medical misconceptions of medical trainees. FindingsWe assessed four large language models with eight different questions that were interrogated five times each with a total of forty responses per a model. All models had examples of perpetuating race-based medicine in their responses. Models were not always consistent in their responses when asked the same question repeatedly. Conclusions and RelevanceLLMs are being proposed for use in the healthcare setting, with some models already connecting to electronic health record systems. However, this study shows that based on our findings, these LLMs could potentially cause harm by perpetuating debunked, racist concepts.\nMachine learning in medicine using JavaScript: building web apps using TensorFlow.js for interpreting biomedical datasets\nAuthors: Pires, J. G.\nScore: 3.2, Published: 2023-07-09 DOI: 10.1101/2023.06.21.23291717\nIntroductionContributions to medicine may come from different areas; and most areas are full of researchers wanting to support. Physists may help with theory, such as for nuclear medicine. Engineers with machineries, such as dialysis machine. Mathematicians with models, such as pharmacokinetics. And computer scientists with codes such as bioinformatics. MethodWe have used TensorFlow.js for modeling using neural networks biomedical datasets from Kaggle. We have modeled three datasets: diabetes detection, surgery complications, and heart failure. We have used Angular coded in TypeScript for the implementation of the models. Using TensorFlow.js, we have built Multilayer Perceptrons (MPLs) for modelling our datasets. We have employed the training and the validation curves to make sure the model learnt, and we have used accuracy as a measure of goodness of each model. Results and discussionWe have built a couple of examples using TensorFlow.js as machine learning platform. Even though python and R are dominant at the moment, JavaScript and derivatives are growing fast, offering basically the same performance, and some extra features associated with JavaScript. Kaggle, the public platform from where we downloaded our datasets, offers a huge amount of datasets for biomedical cases, thus, the reader can easily test what we have discussed, using the same codes, with minor chances, on any case they may be interested in. We were able to find 92% of accuracy for diabetes detection, 100% for surgery complications, and 70% for heart failure. The possibilities are unlimited, and we believe that it is a nice option for researchers aiming at web applications, especially, focused on medicine. ResumoO_ST_ABSPalavras-ChaveC_ST_ABSCC BY-NC-ND 4.0 - This work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International License.\n",
  "wordCount" : "1467",
  "inLanguage": "en",
  "datePublished": "2023-07-23T10:36:34Z",
  "dateModified": "2023-07-23T10:36:34Z",
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://trxiv.yorks0n.com/posts/health-informatics/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "TRxiv2",
    "logo": {
      "@type": "ImageObject",
      "url": "https://trxiv.yorks0n.com/favicon.ico"
    }
  }
}
</script>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://trxiv.yorks0n.com" accesskey="h" title="TRxiv2 (Alt + H)">TRxiv2</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
        </ul>
    </nav>
</header>
<main class="main">
<article class="post-single">
  <header class="post-header">
    
    <h1 class="post-title">
      health informatics
    </h1>
    <div class="post-meta"><span>updated on July 23, 2023</span>

</div>
  </header> 
  <div class="post-content"><div class="accordion accordion-flush" id="accordionFlushExample"><div class="accordion-item">
    <h3 class="accordion-header" id="flush-heading10.1101/2023.07.14.23292669">
      <button class="accordion-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#flush-collapse10.1101/2023.07.14.23292669" aria-expanded="false" aria-controls="flush-collapse10.1101/2023.07.14.23292669">
        <p class="paperTitle">Leveraging Large Language Models for Generating Responses to Patient Messages</p>
      </button>
    </h3>
    <div id="flush-collapse10.1101/2023.07.14.23292669" class="accordion-collapse collapse" aria-labelledby="flush-heading10.1101/2023.07.14.23292669" data-bs-parent="#accordionFlushExample">
      <div class="accordion-body">
        <p class="author">Authors: Liu, S.; McCoy, A. B.; Wright, A. P.; Carew, B.; Genkins, J. Z.; Huang, S. S.; Peterson, J. F.; Steitz, B.; Wright, A.</p>
        <p class="info">Score: 18.5, Published: 2023-07-16 </p>
        <p class="info">DOI: <a href='https://doi.org/10.1101/2023.07.14.23292669' target='https://doi.org/10.1101/2023.07.14.23292669'> 10.1101/2023.07.14.23292669</a></p>
        <p class="abstract">ObjectiveThis study aimed to develop and assess the performance of fine-tuned large language models for generating responses to patient messages sent via an electronic health record patient portal.

MethodsUtilizing a dataset of messages and responses extracted from the patient portal at a large academic medical center, we developed a model (CLAIR-Short) based on a pre-trained large language model (LLaMA-65B). In addition, we used the OpenAI API to update physician responses from an open-source dataset into a format with informative paragraphs that offered patient education while emphasizing empathy and professionalism. By combining with this dataset, we further fine-tuned our model (CLAIR-Long). To evaluate the fine-tuned models, we used ten representative patient portal questions in primary care to generate responses. We asked primary care physicians to review generated responses from our models and ChatGPT and rated them for empathy, responsiveness, accuracy, and usefulness.

ResultsThe dataset consisted of a total of 499,794 pairs of patient messages and corresponding responses from the patient portal, with 5,000 patient messages and ChatGPT-updated responses from an online platform. Four primary care physicians participated in the survey. CLAIR-Short exhibited the ability to generate concise responses similar to providers responses. CLAIR-Long responses provided increased patient educational content compared to CLAIR-Short and were rated similarly to ChatGPTs responses, receiving positive evaluations for responsiveness, empathy, and accuracy, while receiving a neutral rating for usefulness.

ConclusionLeveraging large language models to generate responses to patient messages demonstrates significant potential in facilitating communication between patients and primary care providers.</p>
      </div>
    </div>
  </div><div class="accordion-item">
    <h3 class="accordion-header" id="flush-heading10.1101/2023.07.13.23292577">
      <button class="accordion-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#flush-collapse10.1101/2023.07.13.23292577" aria-expanded="false" aria-controls="flush-collapse10.1101/2023.07.13.23292577">
        <p class="paperTitle">Coding Inequity: Assessing GPT-4&#39;s Potential for Perpetuating Racial and Gender Biases in Healthcare</p>
      </button>
    </h3>
    <div id="flush-collapse10.1101/2023.07.13.23292577" class="accordion-collapse collapse" aria-labelledby="flush-heading10.1101/2023.07.13.23292577" data-bs-parent="#accordionFlushExample">
      <div class="accordion-body">
        <p class="author">Authors: Zack, T.; Lehman, E.; Suzgun, M.; Rodriguez, J. A.; Celi, L. A.; Gichoya, J.; Jurafsky, D.; Szolovits, P.; Bates, D. W.; Abdulnour, R.-E. E.; Butte, A. J.; Alsentzer, E.</p>
        <p class="info">Score: 9.8, Published: 2023-07-17 </p>
        <p class="info">DOI: <a href='https://doi.org/10.1101/2023.07.13.23292577' target='https://doi.org/10.1101/2023.07.13.23292577'> 10.1101/2023.07.13.23292577</a></p>
        <p class="abstract">BackgroundLarge language models (LLMs) such as GPT-4 hold great promise as transformative tools in healthcare, ranging from automating administrative tasks to augmenting clinical decision- making. However, these models also pose a serious danger of perpetuating biases and delivering incorrect medical diagnoses, which can have a direct, harmful impact on medical care.

MethodsUsing the Azure OpenAI API, we tested whether GPT-4 encodes racial and gender biases and examined the impact of such biases on four potential applications of LLMs in the clinical domain--namely, medical education, diagnostic reasoning, plan generation, and patient assessment. We conducted experiments with prompts designed to resemble typical use of GPT-4 within clinical and medical education applications. We used clinical vignettes from NEJM Healer and from published research on implicit bias in healthcare. GPT-4 estimates of the demographic distribution of medical conditions were compared to true U.S. prevalence estimates. Differential diagnosis and treatment planning were evaluated across demographic groups using standard statistical tests for significance between groups.

FindingsWe find that GPT-4 does not appropriately model the demographic diversity of medical conditions, consistently producing clinical vignettes that stereotype demographic presentations. The differential diagnoses created by GPT-4 for standardized clinical vignettes were more likely to include diagnoses that stereotype certain races, ethnicities, and gender identities. Assessment and plans created by the model showed significant association between demographic attributes and recommendations for more expensive procedures as well as differences in patient perception.

InterpretationOur findings highlight the urgent need for comprehensive and transparent bias assessments of LLM tools like GPT-4 for every intended use case before they are integrated into clinical care. We discuss the potential sources of these biases and potential mitigation strategies prior to clinical implementation.</p>
      </div>
    </div>
  </div><div class="accordion-item">
    <h3 class="accordion-header" id="flush-heading10.1101/2023.07.07.23292391">
      <button class="accordion-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#flush-collapse10.1101/2023.07.07.23292391" aria-expanded="false" aria-controls="flush-collapse10.1101/2023.07.07.23292391">
        <p class="paperTitle">Assessing GPT-3.5 and GPT-4 in Generating International Classification of Diseases Billing Codes</p>
      </button>
    </h3>
    <div id="flush-collapse10.1101/2023.07.07.23292391" class="accordion-collapse collapse" aria-labelledby="flush-heading10.1101/2023.07.07.23292391" data-bs-parent="#accordionFlushExample">
      <div class="accordion-body">
        <p class="author">Authors: Soroush, A.; Glicksberg, B. S.; Zimlichman, E.; Barash, Y.; Freeman, R. M.; Charney, A.; Nadkarni, G.; Klang, E.</p>
        <p class="info">Score: 4.6, Published: 2023-07-11 </p>
        <p class="info">DOI: <a href='https://doi.org/10.1101/2023.07.07.23292391' target='https://doi.org/10.1101/2023.07.07.23292391'> 10.1101/2023.07.07.23292391</a></p>
        <p class="abstract">BackgroundLarge Language Models (LLMs) like GPT-3.5 and GPT-4 are increasingly entering the healthcare domain as a proposed means to assist with administrative tasks. To ensure safe and effective use with billing coding tasks, it is crucial to assess these models ability to generate the correct International Classification of Diseases (ICD) codes from text descriptions.

ObjectivesWe aimed to evaluate GPT-3.5 and GPT-4s capability to generate correct ICD billing codes, using the ICD-9-CM (2014) and ICD-10-CM and PCS (2023) systems.

MethodsWe randomly selected 100 unique codes from each of the most recent versions of the ICD-9-CM, ICD-10-CM, and ICD-10-PCS billing code sets published by the Centers for Medicare and Medicaid Services. Using the ChatGPT interface (GPT-3.5 and GPT-4), we prompted for the ICD codes that corresponding to each provided code description. Outputs were compared with the actual billing codes across several performance measures. Errors were qualitatively and quantitatively assessed for any underlying patterns.

ResultsGPT-4 and GPT-3.5 demonstrated varied performance across each ICD system. In ICD-9-CM, GPT-4 and GPT-3.5 achieved an exact match rate of 22% and 10%, respectively. 13% (GPT-4) and 10% (GPT-3.5) of generated ICD-10-CM codes were exact matches. Notably, both models struggled considerably with the procedurally focused ICD-10-PCS, with neither GPT-4 or GPT-3.5 producing any exactly matched codes. A substantial number of incorrect codes had semantic similarity with the actual codes for ICD-9-CM (GPT-4: 60.3%, GPT-3.5: 51.1%) and ICD-10-CM (GPT-4: 70.1%, GPT-3.5: 61.1%), in contrast to ICD-10-PCS (GPT-4: 30.0%, GPT-3.5: 16.0%).

ConclusionOur evaluation of GPT-3.5 and GPT-4s proficiency in generating ICD billing codes from ICD-9-CM, ICD-10-CM and ICD-10-PCS code descriptions reveals an inadequate level of performance. While the models appear to exhibit a general conceptual understanding of the codes and their descriptions, they have a propensity for hallucinating key details, suggesting underlying technological limitations of the base LLMs. This suggests a need for more rigorous LLM augmentation strategies and validation prior to their implementation in healthcare contexts, particularly in tasks such as ICD coding which require significant digit-level precision.</p>
      </div>
    </div>
  </div><div class="accordion-item">
    <h3 class="accordion-header" id="flush-heading10.1101/2023.07.03.23292192">
      <button class="accordion-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#flush-collapse10.1101/2023.07.03.23292192" aria-expanded="false" aria-controls="flush-collapse10.1101/2023.07.03.23292192">
        <p class="paperTitle">Beyond the hype: large language models propagate race-based medicine</p>
      </button>
    </h3>
    <div id="flush-collapse10.1101/2023.07.03.23292192" class="accordion-collapse collapse" aria-labelledby="flush-heading10.1101/2023.07.03.23292192" data-bs-parent="#accordionFlushExample">
      <div class="accordion-body">
        <p class="author">Authors: Omiye, J. A.; Lester, J.; Spichak, S.; Rotemberg, V.; Daneshjou, R.</p>
        <p class="info">Score: 63.3, Published: 2023-07-05 </p>
        <p class="info">DOI: <a href='https://doi.org/10.1101/2023.07.03.23292192' target='https://doi.org/10.1101/2023.07.03.23292192'> 10.1101/2023.07.03.23292192</a></p>
        <p class="abstract">ImportanceLarge language models (LLMs) are being integrated into healthcare systems; but these models recapitulate harmful, race-based medicine.

ObjectiveThe objective of this study is to assess whether four commercially available large language models (LLMs) propagate harmful, inaccurate, race-based content when responding to eight different scenarios that historically included race-based medicine or widespread misconceptions around race.

Evidence ReviewQuestions were derived from discussion among 4 physician experts and prior work on race-based medical misconceptions of medical trainees.

FindingsWe assessed four large language models with eight different questions that were interrogated five times each with a total of forty responses per a model. All models had examples of perpetuating race-based medicine in their responses. Models were not always consistent in their responses when asked the same question repeatedly.

Conclusions and RelevanceLLMs are being proposed for use in the healthcare setting, with some models already connecting to electronic health record systems. However, this study shows that based on our findings, these LLMs could potentially cause harm by perpetuating debunked, racist concepts.</p>
      </div>
    </div>
  </div><div class="accordion-item">
    <h3 class="accordion-header" id="flush-heading10.1101/2023.06.21.23291717">
      <button class="accordion-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#flush-collapse10.1101/2023.06.21.23291717" aria-expanded="false" aria-controls="flush-collapse10.1101/2023.06.21.23291717">
        <p class="paperTitle">Machine learning in medicine using JavaScript: building web apps using TensorFlow.js for interpreting biomedical datasets</p>
      </button>
    </h3>
    <div id="flush-collapse10.1101/2023.06.21.23291717" class="accordion-collapse collapse" aria-labelledby="flush-heading10.1101/2023.06.21.23291717" data-bs-parent="#accordionFlushExample">
      <div class="accordion-body">
        <p class="author">Authors: Pires, J. G.</p>
        <p class="info">Score: 3.2, Published: 2023-07-09 </p>
        <p class="info">DOI: <a href='https://doi.org/10.1101/2023.06.21.23291717' target='https://doi.org/10.1101/2023.06.21.23291717'> 10.1101/2023.06.21.23291717</a></p>
        <p class="abstract">IntroductionContributions to medicine may come from different areas; and most areas are full of researchers wanting to support. Physists may help with theory, such as for nuclear medicine. Engineers with machineries, such as dialysis machine. Mathematicians with models, such as pharmacokinetics. And computer scientists with codes such as bioinformatics.

MethodWe have used TensorFlow.js for modeling using neural networks biomedical datasets from Kaggle. We have modeled three datasets: diabetes detection, surgery complications, and heart failure. We have used Angular coded in TypeScript for the implementation of the models. Using TensorFlow.js, we have built Multilayer Perceptrons (MPLs) for modelling our datasets. We have employed the training and the validation curves to make sure the model learnt, and we have used accuracy as a measure of goodness of each model.

Results and discussionWe have built a couple of examples using TensorFlow.js as machine learning platform. Even though python and R are dominant at the moment, JavaScript and derivatives are growing fast, offering basically the same performance, and some extra features associated with JavaScript. Kaggle, the public platform from where we downloaded our datasets, offers a huge amount of datasets for biomedical cases, thus, the reader can easily test what we have discussed, using the same codes, with minor chances, on any case they may be interested in. We were able to find 92% of accuracy for diabetes detection, 100% for surgery complications, and 70% for heart failure. The possibilities are unlimited, and we believe that it is a nice option for researchers aiming at web applications, especially, focused on medicine.

ResumoO_ST_ABSPalavras-ChaveC_ST_ABSCC BY-NC-ND 4.0 - This work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International License.</p>
      </div>
    </div>
  </div>
</div>









<script src="/js/bundle.min.js" defer></script>



  </div>

  <footer class="post-footer">
    <ul class="post-tags">
    </ul>
  </footer>
</article>
    </main>
    
<footer class="footer">
    <span>&copy; 2023 <a href="https://trxiv.yorks0n.com">TRxiv2</a></span>
    <span>
        · Made by Yorkson
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
</body>

</html>
